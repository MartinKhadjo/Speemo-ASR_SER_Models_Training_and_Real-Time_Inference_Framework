<!-- Speemo-ASR and SER Training and Inference Framework for Audiofile-based and Real-Time Inference. Martin Khadjavian © -->

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Speemo - AI-based Speech and Emotion Recognition System for Audio Files and Real-Time Inference</title>
    <link rel="stylesheet" href="static/style.css">
    <!-- Socket.IO client (CDN, with SRI) -->
    <script src="https://cdn.socket.io/4.8.1/socket.io.min.js"
            integrity="sha384-mkQ3/7FUtcGyoppY6bz/PORYoGqOl7/aSUMn2ymDOJcapfS6PHqxhRTMh1RR0Q6+"
            crossorigin="MartinKhadjavian"></script>
</head>
<body>
    <header>
        <div class="logo">
            <h2>Speemo - AI-based Speech and Emotion Recognition System for Audio-File based and Real-Time Inference</h2>
        </div>
    </header>

    <main>
        <!-- =========================== TRAINING SECTION =========================== -->
        <section class="form-container" id="trainingSection">
            <h2>Set Training Hyperparameters</h2>
            <form action="/train" method="POST" id="trainForm">

                <!-- ===== ASR HYPERPARAMETERS ===== -->
                <h3>ASR Model</h3>

                <label for="asr_learning_rate">ASR Learning Rate (0.1 to 0.000001):</label>
                <input type="number"
                    id="asr_learning_rate"
                    name="asr_learning_rate"
                    step="0.000001"
                    min="0.000001"
                    max="0.1"
                    placeholder="e.g., 0.001"
                    required />

                <label for="asr_batch_size">ASR Batch Size:</label>
                <input type="number"
                    id="asr_batch_size"
                    name="asr_batch_size"
                    min="1"
                    placeholder="e.g., 32"
                    required />

                <label for="asr_epochs">ASR Number of Epochs:</label>
                <input type="number"
                    id="asr_epochs"
                    name="asr_epochs"
                    min="1"
                    placeholder="e.g., 10"
                    required />

                <label for="asr_patience">ASR Early Stopping Patience:</label>
                <input type="number"
                    id="asr_patience"
                    name="asr_patience"
                    min="1"
                    placeholder="e.g., 5"
                    required />

                <label for="asr_lang">ASR Language:</label>
                <select id="asr_lang" name="asr_lang" required>
                    <option value="en">English</option>
                    <option value="de">German</option>
                </select>

                <!-- LoRA for ASR -->
                <div style="margin-top: 12px;">
                  <label>
                    <input type="checkbox" name="use_lora_asr" id="use_lora_asr">
                    Use LoRA for ASR fine-tuning
                  </label>
                </div>

                <div id="lora_asr_params" style="margin-left: 20px; margin-top: 6px; display: none;">
                  <div>
                    <label>LoRA rank r:
                      <input type="number" name="lora_r" value="8" min="1">
                    </label>
                  </div>
                  <div>
                    <label>LoRA alpha:
                      <input type="number" name="lora_alpha" value="32" min="1">
                    </label>
                  </div>
                  <div>
                    <label>LoRA dropout:
                      <input type="number" step="0.01" name="lora_dropout" value="0.1" min="0" max="1">
                    </label>
                  </div>
                  <div>
                    <label>LoRA target modules:
                      <input type="text" name="lora_targets"
                             value="q_proj,k_proj,v_proj,out_proj,intermediate_dense,output_dense">
                    </label>
                  </div>
                </div>

                <!-- ===== SER HYPERPARAMETERS ===== -->
                <h3>SER Model</h3>

                <label for="ser_learning_rate">SER Learning Rate (0.1 to 0.000001):</label>
                <input type="number"
                    id="ser_learning_rate"
                    name="ser_learning_rate"
                    step="0.000001"
                    min="0.000001"
                    max="0.1"
                    placeholder="e.g., 0.001"
                    required />

                <label for="ser_batch_size">SER Batch Size:</label>
                <input type="number"
                    id="ser_batch_size"
                    name="ser_batch_size"
                    min="1"
                    placeholder="e.g., 32"
                    required />

                <label for="ser_epochs">SER Number of Epochs:</label>
                <input type="number"
                    id="ser_epochs"
                    name="ser_epochs"
                    min="1"
                    placeholder="e.g., 10"
                    required />

                <label for="ser_dropout">SER Dropout:</label>
                <input type="number"
                    id="ser_dropout"
                    name="ser_dropout"
                    step="0.05"
                    min="0.0"
                    max="0.9"
                    placeholder="e.g., 0.5"
                    required />

                <label for="ser_patience">SER Early Stopping Patience:</label>
                <input type="number"
                    id="ser_patience"
                    name="ser_patience"
                    min="1"
                    placeholder="e.g., 5"
                    required />

                <label for="ser_lang">SER Language:</label>
                <select id="ser_lang" name="ser_lang" required>
                    <option value="en">English</option>
                    <option value="de">German</option>
                </select>

                 <!-- ===== DEVICE SELECTION ===== -->
                <div class="form-row">
                  <label for="device">Device</label>
                  <select id="device" name="device">
                    <option value="cuda">GPU (if available)</option>
                    <option value="cpu">CPU</option>
                  </select>
                </div>

                <!-- ===== PREPROCESSING OPTIONS ===== -->
                <h3>Preprocessing</h3>

                <label for="skip_preprocessing">
                    <input type="checkbox" id="skip_preprocessing" name="skip_preprocessing" value="on">
                    Skip All Preprocessing (expert only)
                </label>
                <br>
                <label for="skip_splitting">
                    <input type="checkbox" id="skip_splitting" name="skip_splitting" value="on">
                    Skip Data Splitting
                </label>
                <br>
                <label for="skip_preprocessing_asr">
                    <input type="checkbox" id="skip_preprocessing_asr" name="skip_preprocessing_asr" value="on">
                    Skip ASR Preprocessing
                </label>
                <br>
                <label for="skip_preprocessing_emotion">
                    <input type="checkbox" id="skip_preprocessing_emotion" name="skip_preprocessing_emotion" value="on">
                    Skip Emotion Preprocessing
                </label>
                <br>

                <!-- ===== CHECKPOINT HANDLING ===== -->
                <label for="existing_checkpoint">Choose Existing Checkpoint:</label>
                <select id="existing_checkpoint" name="existing_checkpoint">
                    <option value="">— start a new run —</option>
                    {% for cp in checkpoints %}
                        <option value="{{ cp }}">{{ cp }}</option>
                    {% endfor %}
                </select>
                <br>

                <label for="checkpoint_name">Or Enter New Checkpoint Name:</label>
                <input
                    type="text"
                    id="checkpoint_name"
                    name="checkpoint_name"
                    placeholder="e.g., my_experiment" />

                <button type="submit">Start Training</button>

            </form>

            <!-- NEW: Button to go back to inference once training is complete -->
            <div id="postTraining" style="display:none; text-align:center; margin-top:20px;">
                <p>Training completed successfully.</p>
                <button onclick="window.location.href='/'">Go to Inference</button>
            </div>
        </section>

        <!-- =========================== TRAINING LOGS & STATUS SECTION =========================== -->
        <section class="logs-container">
            <h2>Training Logs</h2>
            <div id="logs">
                <p>Logs will be displayed here as training progresses.</p>
            </div>
        </section>

        <section class="status-container">
            <h2>Training Status</h2>
            <p id="status">Waiting for training to start...</p>
        </section>

        <!-- =========================== INFERENCE SECTION =========================== -->
        <section class="inference-container" style="margin-top: 30px;">
            <h2>Inference</h2>
            <!-- Model selector -->
            <label for="model_choice_inference">Select Trained Model:</label>
            <select id="model_choice_inference" name="model_choice">
                {% for cp in checkpoints %}
                <option value="{{ cp }}">{{ cp }}</option>
                {% endfor %}
            </select>
            <button id="loadModelInference">Load Selected Checkpoint</button>

            <!-- LM note (KenLM optional) -->
            <p class="help" style="margin:6px 0 14px;color:#555;">
              ASR decoding: <strong>greedy</strong> by default. If a KenLM file exists at
              <code>models/lm/4gram.arpa</code>, the server will use beam search (tunable via env:
              <code>SPEEMO_ASR_BEAM</code>, <code>SPEEMO_ASR_LM_ALPHA</code>, <code>SPEEMO_ASR_LM_BETA</code>).
              If no LM is present, it automatically falls back to greedy (no action needed).
            </p>
            <p id="modelLoadStatus" style="color: green; font-weight: bold;"></p>

            <h3>File-Based Inference</h3>
            <form id="inference-form">
                <label for="inferenceFile">Select an Audio File:</label><br><br>
                <input type="file"
                       id="inferenceFile"
                       name="file"
                       accept="audio/*"
                       required />
                <!-- NEW: Sentence-wise (VAD) segmentation option for uploaded file inference -->
                <label>
                  <input type="checkbox" id="sentencewise" name="sentencewise" value="on">
                  Sentence-wise (VAD) segmentation
                </label>
                <br>
                <button type="submit">Infer</button>
            </form>
            <h3>File-Based Inference Results (JSON)</h3>
            <pre id="inferenceResult" style="background-color: #f9f9f9; padding: 10px;"></pre>

            <h3>Real-Time Streaming Inference</h3>
            <!-- Streaming model selector -->
            <label for="model_choice_streaming">Select Trained Model:</label>
            <select id="model_choice_streaming" name="model_choice">
                {% for cp in checkpoints %}
                <option value="{{ cp }}">{{ cp }}</option>
                {% endfor %}
            </select>
            <button id="loadModelStreaming">Load Selected Checkpoint</button>
            <button id="startStreaming" disabled>Start Streaming</button>
            <button id="stopStreaming" disabled>Stop Streaming</button>
            <h3>Real-Time Inference Results (JSON)</h3>
            <div id="streamingResults" style="background-color: #f9f9f9; padding: 10px; max-height:300px; overflow-y:auto;"></div>
            <button id="downloadStreaming" disabled>Download Streaming Results</button>

            <!-- 5c) Download metrics UI -->
            <button id="downloadMetrics" style="margin-top:10px;">Download Last Run Metrics</button>
            <pre id="metricsPreview" style="background:#f9f9f9;padding:10px;"></pre>
        </section>
    </main>

    <footer>
        <p>&copy; Speemo - ASR and SER Training and Inference Framework for Audiofile-based and Real-Time Inference | Martin Khadjavian </p>
    </footer>

    <script>
        // =========================== SOCKET.IO TRAINING LOGS HANDLER ===========================
        const socket = io({ transports: ["websocket","polling"] });

        let streaming = false;
        let streamingInterval = null;
        let mediaRecorderRef = null;
        let streamRef = null;
        let streamingResults = [];

        const startButton = document.getElementById("startStreaming");
        const stopButton = document.getElementById("stopStreaming");
        const downloadButton = document.getElementById("downloadStreaming");

        // reference to logs + status for reuse
        const logsDiv = document.getElementById("logs");
        const statusEl = document.getElementById("status");
        const trainForm = document.getElementById("trainForm");

        // =========================== SHOW "TRAINING STARTING" ON CLICK ===========================
        if (trainForm) {
            trainForm.addEventListener("submit", () => {
                // Update training status immediately
                if (statusEl) {
                    statusEl.textContent = "Training starting...";
                }
                // Clear old logs and add a UI marker
                if (logsDiv) {
                    logsDiv.innerHTML = "";
                    const p = document.createElement("p");
                    p.textContent = "[UI] Training starting...";
                    logsDiv.appendChild(p);
                }
            });
        }

        // =========================== MODEL LOAD HELPER (explicit) ===========================
        async function loadCheckpoint(baseName) {
            if (!baseName) {
                alert("Select a checkpoint first.");
                return;
            }
            const fd = new FormData();
            fd.append("existing_checkpoint", baseName);

            // These are only used if backend decides to create a new checkpoint.
            // For existing checkpoints they are harmless.
            const asrLang = document.getElementById("asr_lang")?.value || "en";
            const serLang = document.getElementById("ser_lang")?.value || "en";
            fd.append("asr_lang", asrLang);
            fd.append("ser_lang", serLang);

            const statusElLoad = document.getElementById("modelLoadStatus");
            statusElLoad.style.color = "black";
            statusElLoad.textContent = "Loading checkpoint '" + baseName + "' ...";

            try {
                const resp = await fetch("/load_checkpoint", { method: "POST", body: fd });
                const data = await resp.json().catch(() => ({}));
                if (resp.ok) {
                    statusElLoad.style.color = "green";
                    statusElLoad.textContent = data.message || `Loaded checkpoint: ${baseName}`;
                    // Enable streaming start button once model is loaded
                    startButton.disabled = false;
                } else {
                    statusElLoad.style.color = "red";
                    statusElLoad.textContent = data.error || `Failed to load checkpoint: ${baseName}`;
                }
            } catch (err) {
                statusElLoad.style.color = "red";
                statusElLoad.textContent = "Error loading checkpoint: " + err.message;
            }
        }

        // =========================== TRAINING LOGS ===========================
        socket.on("training_logs", (data) => {
            const logDiv = document.getElementById("logs");
            const p = document.createElement("p");
            p.textContent = data.log;
            logDiv.appendChild(p);
            logDiv.scrollTop = logDiv.scrollHeight;
            if (data.log.includes("Model trained") || data.log.includes("Training completed successfully")) {
                document.getElementById("trainForm").style.display = "none";
                document.getElementById("postTraining").style.display = "block";
            }
        });

        // =========================== REAL-TIME RESULTS ===========================
        socket.on("asr_emotion_result", (data) => {
            streamingResults.push(data);
            const p = document.createElement("p");
            p.textContent = JSON.stringify(data);
            const pane = document.getElementById("streamingResults");
            pane.appendChild(p);
            pane.scrollTop = pane.scrollHeight;
            document.getElementById("downloadStreaming").disabled = false;
        });

        // =========================== POLLING TRAINING STATUS ===========================
        async function pollTrainingStatus() {
            try {
                const response = await fetch("/train_status");
                const data = await response.json();
                document.getElementById("status").textContent = data.status;
                setTimeout(pollTrainingStatus, 5000);
            } catch (err) {
                console.error("Error polling training status:", err);
                setTimeout(pollTrainingStatus, 5000);
            }
        }
        pollTrainingStatus();

        // Infer button reference for UI feedback
        const inferButton = document.querySelector("#inference-form button[type='submit']");

        // =========================== FILE-BASED INFERENCE HANDLER ===========================
        document.getElementById("inference-form").addEventListener("submit", async (e) => {
            e.preventDefault();
            const fileInput = document.getElementById("inferenceFile");
            if (!fileInput.files[0]) {
                alert("Please select an audio file.");
                return;
            }
            const modelChoice = document.getElementById("model_choice_inference").value;
            if (!modelChoice) {
                alert("Select and load a checkpoint first.");
                return;
            }

            // UI: show "Inferring..." and log it
            const infResultEl = document.getElementById("inferenceResult");
            if (infResultEl) {
                infResultEl.textContent = "Inferring...";
            }
            if (logsDiv) {
                const p = document.createElement("p");
                p.textContent = `[UI] Starting file-based inference for "${fileInput.files[0].name}"...`;
                logsDiv.appendChild(p);
                logsDiv.scrollTop = logsDiv.scrollHeight;
            }
            if (inferButton) {
                inferButton.disabled = true;
            }

            const formData = new FormData();
            formData.append("file", fileInput.files[0]);
            formData.append("model_choice", modelChoice);
            const sentencewise = document.getElementById("sentencewise")?.checked;
            if (sentencewise) {
                formData.append("sentencewise", "on");
            }
            const inferenceURL = "/process_audio_inference";
            try {
                const response = await fetch(inferenceURL, {
                    method: "POST",
                    body: formData,
                });
                if (!response.ok) {
                    throw new Error(`Server error: ${response.status}`);
                }
                const resultData = await response.json();
                infResultEl.textContent = JSON.stringify(resultData, null, 2);

                // Log completion
                if (logsDiv) {
                    const pDone = document.createElement("p");
                    pDone.textContent = "[UI] File-based inference finished.";
                    logsDiv.appendChild(pDone);
                    logsDiv.scrollTop = logsDiv.scrollHeight;
                }

                const blob = new Blob(
                    [JSON.stringify(resultData, null, 2)],
                    { type: "application/json" }
                );
                const url = URL.createObjectURL(blob);
                const link = document.createElement("a");
                link.href = url;
                link.download = "inference_result.json";
                document.body.appendChild(link);
                link.click();
                document.body.removeChild(link);
                URL.revokeObjectURL(url);
            } catch (err) {
                console.error("Inference error:", err);
                infResultEl.textContent = "Error: " + err.message;
                if (logsDiv) {
                    const pErr = document.createElement("p");
                    pErr.textContent = "[UI] Inference error: " + err.message;
                    logsDiv.appendChild(pErr);
                    logsDiv.scrollTop = logsDiv.scrollHeight;
                }
            } finally {
                if (inferButton) {
                    inferButton.disabled = false;
                }
            }
        });

        // =========================== REAL-TIME STREAMING (MIC) ===========================
        async function startRealTimeStreaming() {
            if (streaming) return;
            streaming = true;
            streamingResults = [];
            startButton.disabled = true;
            stopButton.disabled = false;
            downloadButton.disabled = true;

            const modelChoice = document.getElementById("model_choice_streaming").value;
            if (!modelChoice) {
                alert("Please select and load a checkpoint for streaming.");
                streaming = false;
                startButton.disabled = false;
                stopButton.disabled = true;
                return;
            }

            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                streamRef = stream;
                const mediaRecorder = new MediaRecorder(stream);
                mediaRecorderRef = mediaRecorder;
                let audioChunks = [];

                mediaRecorder.ondataavailable = (event) => {
                    if (!streaming) return;
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
                };

                mediaRecorder.onstop = async () => {
                    if (!streaming || audioChunks.length === 0) return;
                    const blob = new Blob(audioChunks, { type: "audio/webm" });
                    const arrayBuffer = await blob.arrayBuffer();
                    const audioBytes = new Uint8Array(arrayBuffer);

                    const mime = blob.type || "audio/webm";
                    let fmt = "webm";
                    if (mime.includes("ogg")) fmt = "ogg";
                    else if (mime.includes("wav")) fmt = "wav";
                    else if (mime.includes("mpeg")) fmt = "mp3";
                    else if (mime.includes("mp4") || mime.includes("m4a") || mime.includes("aac")) fmt = "m4a";

                    socket.emit("unity_audio_chunk", {
                        audio: audioBytes.buffer,
                        model_choice: modelChoice,
                        meta: { format: fmt }
                    });
                    audioChunks = [];
                };

                mediaRecorder.start();
                streamingInterval = setInterval(() => {
                    if (!streaming) return;
                    if (mediaRecorder.state !== "inactive") {
                        mediaRecorder.stop();
                        mediaRecorder.start();
                    }
                }, 500);
            } catch (err) {
                console.error("Error accessing microphone:", err);
                alert("Microphone access error: " + err.message);
                streaming = false;
                startButton.disabled = false;
                stopButton.disabled = true;
            }
        }

        function stopRealTimeStreaming() {
            streaming = false;
            startButton.disabled = false;
            stopButton.disabled = true;
            downloadButton.disabled = streamingResults.length === 0;
            clearInterval(streamingInterval);
            try {
                if (mediaRecorderRef && mediaRecorderRef.state !== "inactive") {
                    mediaRecorderRef.stop();
                }
            } catch (e) {
                console.warn("MediaRecorder stop issue:", e);
            }
            if (streamRef) {
                streamRef.getTracks().forEach(t => t.stop());
                streamRef = null;
            }
        }

        startButton.addEventListener("click", startRealTimeStreaming);
        stopButton.addEventListener("click", stopRealTimeStreaming);
        downloadButton.addEventListener("click", () => {
            const jsonString = JSON.stringify(streamingResults, null, 2);
            const blob = new Blob([jsonString], { type: "application/json" });
            const url = URL.createObjectURL(blob);
            const link = document.createElement("a");
            link.href = url;
            link.download = "streaming_results.json";
            document.body.appendChild(link);
            link.click();
            document.body.removeChild(link);
            URL.revokeObjectURL(url);
        });

        // =========================== POPULATE CHECKPOINT NAME ===========================
        document.getElementById("existing_checkpoint").addEventListener("change", function () {
            const sel = this.value;
            if (sel) {
                document.getElementById("checkpoint_name").value = sel;
            }
        });

        // =========================== MASTER SKIP: 'Skip All Preprocessing' ===========================
        function syncSkipPreprocessingChildren() {
            const master = document.getElementById("skip_preprocessing");
            const ids = ["skip_splitting", "skip_preprocessing_asr", "skip_preprocessing_emotion"];
            ids.forEach(id => {
                const el = document.getElementById(id);
                if (el) el.checked = master.checked;
            });
        }
        document.getElementById("skip_preprocessing").addEventListener("change", syncSkipPreprocessingChildren);
        document.addEventListener("DOMContentLoaded", () => {
            syncSkipPreprocessingChildren();
        });

        // =========================== DOWNLOAD METRICS HANDLER ===========================
        document.getElementById("downloadMetrics").addEventListener("click", async () => {
          const m = document.getElementById("model_choice_inference")?.value;
          if (!m) return alert("Select a model first.");
          const resp = await fetch(`/last_metrics?model_choice=${encodeURIComponent(m)}`);
          const text = await resp.text();
          if (!resp.ok) {
            alert("No metrics yet for this model.");
            return;
          }
          document.getElementById("metricsPreview").textContent = text;
          const blob = new Blob([text], {type: "application/json"});
          const url = URL.createObjectURL(blob);
          const a = document.createElement("a");
          a.href = url;
          a.download = `${m}_metrics.json`;
          document.body.appendChild(a);
          a.click();
          document.body.removeChild(a);
          URL.revokeObjectURL(url);
        });

        // =========================== LoRA PARAMS TOGGLE ===========================
        const useLoraCheckbox = document.getElementById('use_lora_asr');
        const loraParamsBlock = document.getElementById('lora_asr_params');
        if (useLoraCheckbox) {
          useLoraCheckbox.addEventListener('change', function () {
            loraParamsBlock.style.display = this.checked ? 'block' : 'none';
          });
        }

        // =========================== EXPLICIT LOAD BUTTONS ===========================
        document.getElementById("loadModelInference").addEventListener("click", () => {
            const base = document.getElementById("model_choice_inference").value;
            loadCheckpoint(base);
        });

        document.getElementById("loadModelStreaming").addEventListener("click", () => {
            const base = document.getElementById("model_choice_streaming").value;
            loadCheckpoint(base);
        });
    </script>

</body>
</html>
