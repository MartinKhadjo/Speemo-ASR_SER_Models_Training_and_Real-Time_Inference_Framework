[DIST] MASTER_ADDR=w23g0011 MASTER_PORT=29500 NNODES=1 GPUS_PER_NODE=1
[PRE] Skipping all preprocessing (skip_preprocessing=on or all per-step toggles are 'on')
[TRAIN][ASR] Starting ASR phase ...
[Setup] Using device: cuda
[Setup] no_cuda flag set to: False
[ASR] Loading model + processor‚Ä¶
[ASR] Starting from pretrained: models/pretrained/en
trainable params: 589,824 || all params: 94,986,144 || trainable%: 0.6210
[ASR] Trainable parameters: 589824 / 94986144
üõ†Ô∏è  Debug collator output shapes: {'input_values': torch.Size([4, 75264]), 'attention_mask': torch.Size([4, 75264]), 'labels': torch.Size([4, 93])}
[ASR] Starting training with HuggingFace Trainer‚Ä¶
w23g0011:279891:279891 [0] NCCL INFO Bootstrap : Using ib0:134.61.46.240<0>
w23g0011:279891:279891 [0] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation
w23g0011:279891:279891 [0] NCCL INFO cudaDriverVersion 12080
NCCL version 2.20.5+cuda12.4
w23g0011:279891:280830 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib0:134.61.46.240<0>
w23g0011:279891:280830 [0] NCCL INFO Using non-device net plugin version 0
w23g0011:279891:280830 [0] NCCL INFO Using network IB
w23g0011:279891:280830 [0] NCCL INFO DMA-BUF is available on GPU device 0
w23g0011:279891:280830 [0] NCCL INFO comm 0x55872766c580 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 9d000 commId 0xed37cc95bd4413ff - Init START
w23g0011:279891:280830 [0] NCCL INFO Setting affinity for GPU 0 to 3a0000,00000000
w23g0011:279891:280830 [0] NCCL INFO comm 0x55872766c580 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
w23g0011:279891:280830 [0] NCCL INFO Channel 00/32 :    0
w23g0011:279891:280830 [0] NCCL INFO Channel 01/32 :    0
w23g0011:279891:280830 [0] NCCL INFO Channel 02/32 :    0
w23g0011:279891:280830 [0] NCCL INFO Channel 03/32 :    0
w23g0011:279891:280830 [0] NCCL INFO Channel 04/32 :    0
w23g0011:279891:280830 [0] NCCL INFO Channel 05/32 :    0
w23g0011:279891:280830 [0] NCCL INFO Channel 06/32 :    0
w23g0011:279891:280830 [0] NCCL INFO Channel 07/32 :    0
w23g0011:279891:280830 [0] NCCL INFO Channel 08/32 :    0
w23g0011:279891:280830 [0] NCCL INFO Channel 09/32 :    0
w23g0011:279891:280830 [0] NCCL INFO Channel 10/32 :    0
w23g0011:279891:280830 [0] NCCL INFO Channel 11/32 :    0
w23g0011:279891:280830 [0] NCCL INFO Channel 12/32 :    0
w23g0011:279891:280830 [0] NCCL INFO Channel 13/32 :    0
w23g0011:279891:280830 [0] NCCL INFO Channel 14/32 :    0
w23g0011:279891:280830 [0] NCCL INFO Channel 15/32 :    0
w23g0011:279891:280830 [0] NCCL INFO Channel 16/32 :    0
w23g0011:279891:280830 [0] NCCL INFO Channel 17/32 :    0
w23g0011:279891:280830 [0] NCCL INFO Channel 18/32 :    0
w23g0011:279891:280830 [0] NCCL INFO Channel 19/32 :    0
w23g0011:279891:280830 [0] NCCL INFO Channel 20/32 :    0
w23g0011:279891:280830 [0] NCCL INFO Channel 21/32 :    0
w23g0011:279891:280830 [0] NCCL INFO Channel 22/32 :    0
w23g0011:279891:280830 [0] NCCL INFO Channel 23/32 :    0
w23g0011:279891:280830 [0] NCCL INFO Channel 24/32 :    0
w23g0011:279891:280830 [0] NCCL INFO Channel 25/32 :    0
w23g0011:279891:280830 [0] NCCL INFO Channel 26/32 :    0
w23g0011:279891:280830 [0] NCCL INFO Channel 27/32 :    0
w23g0011:279891:280830 [0] NCCL INFO Channel 28/32 :    0
w23g0011:279891:280830 [0] NCCL INFO Channel 29/32 :    0
w23g0011:279891:280830 [0] NCCL INFO Channel 30/32 :    0
w23g0011:279891:280830 [0] NCCL INFO Channel 31/32 :    0
w23g0011:279891:280830 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
w23g0011:279891:280830 [0] NCCL INFO P2P Chunksize set to 131072
w23g0011:279891:280830 [0] NCCL INFO Connected all rings
w23g0011:279891:280830 [0] NCCL INFO Connected all trees
w23g0011:279891:280830 [0] NCCL INFO 32 coll channels, 0 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
w23g0011:279891:280830 [0] NCCL INFO comm 0x55872766c580 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 9d000 commId 0xed37cc95bd4413ff - Init COMPLETE
{'loss': 2.7201, 'grad_norm': 3.8582847118377686, 'learning_rate': 0.0, 'epoch': 0.0}
{'loss': 2.2387, 'grad_norm': 5.3111677169799805, 'learning_rate': 9.800000000000001e-06, 'epoch': 0.2}
{'loss': 1.8147, 'grad_norm': 6.5194621086120605, 'learning_rate': 1.9800000000000004e-05, 'epoch': 0.4}
{'loss': 1.3294, 'grad_norm': 2.2675914764404297, 'learning_rate': 2.98e-05, 'epoch': 0.6}
{'loss': 1.1943, 'grad_norm': 12.375502586364746, 'learning_rate': 3.9800000000000005e-05, 'epoch': 0.8}
{'loss': 1.1025, 'grad_norm': 1.6624270677566528, 'learning_rate': 4.97e-05, 'epoch': 1.0}
{'eval_loss': 0.8026665449142456, 'eval_wer': 0.40054064131245337, 'eval_runtime': 1539.2938, 'eval_samples_per_second': 5.197, 'eval_steps_per_second': 5.197, 'epoch': 1.0}
{'loss': 1.0152, 'grad_norm': 4.734342575073242, 'learning_rate': 5.97e-05, 'epoch': 1.2}
{'loss': 0.969, 'grad_norm': 1.8589081764221191, 'learning_rate': 6.97e-05, 'epoch': 1.4}
{'loss': 1.005, 'grad_norm': 2.1580770015716553, 'learning_rate': 7.970000000000001e-05, 'epoch': 1.6}
{'loss': 0.9552, 'grad_norm': 2.147376298904419, 'learning_rate': 8.970000000000001e-05, 'epoch': 1.8}
{'loss': 0.9376, 'grad_norm': 3.8105974197387695, 'learning_rate': 9.970000000000001e-05, 'epoch': 2.0}
{'eval_loss': 0.7190805673599243, 'eval_wer': 0.3461169702780441, 'eval_runtime': 1548.2565, 'eval_samples_per_second': 5.167, 'eval_steps_per_second': 5.167, 'epoch': 2.0}
{'loss': 0.8977, 'grad_norm': 2.029362201690674, 'learning_rate': 0.0001, 'epoch': 2.2}
{'loss': 0.8835, 'grad_norm': 3.2382876873016357, 'learning_rate': 0.0001, 'epoch': 2.4}
{'loss': 0.8875, 'grad_norm': 2.1686198711395264, 'learning_rate': 0.0001, 'epoch': 2.6}
{'loss': 0.8741, 'grad_norm': 1.9309760332107544, 'learning_rate': 0.0001, 'epoch': 2.8}
{'loss': 0.8945, 'grad_norm': 2.119471549987793, 'learning_rate': 0.0001, 'epoch': 3.0}
{'eval_loss': 0.6623930335044861, 'eval_wer': 0.3288590604026846, 'eval_runtime': 1520.0869, 'eval_samples_per_second': 5.263, 'eval_steps_per_second': 5.263, 'epoch': 3.0}
{'loss': 0.8589, 'grad_norm': 2.3794150352478027, 'learning_rate': 0.0001, 'epoch': 3.2}
{'loss': 0.8597, 'grad_norm': 4.517117500305176, 'learning_rate': 0.0001, 'epoch': 3.4}
{'loss': 0.8429, 'grad_norm': 2.507031202316284, 'learning_rate': 0.0001, 'epoch': 3.6}
{'loss': 0.8218, 'grad_norm': 2.0198419094085693, 'learning_rate': 0.0001, 'epoch': 3.8}
{'loss': 0.8073, 'grad_norm': 3.301455020904541, 'learning_rate': 0.0001, 'epoch': 4.0}
{'eval_loss': 0.6547346115112305, 'eval_wer': 0.3227202514115266, 'eval_runtime': 1518.3867, 'eval_samples_per_second': 5.269, 'eval_steps_per_second': 5.269, 'epoch': 4.0}
{'loss': 0.8154, 'grad_norm': 2.9874353408813477, 'learning_rate': 0.0001, 'epoch': 4.2}
{'loss': 0.8053, 'grad_norm': 2.3967018127441406, 'learning_rate': 0.0001, 'epoch': 4.4}
{'loss': 0.8237, 'grad_norm': 3.803037166595459, 'learning_rate': 0.0001, 'epoch': 4.6}
{'loss': 0.7921, 'grad_norm': 3.2846317291259766, 'learning_rate': 0.0001, 'epoch': 4.8}
{'loss': 0.8131, 'grad_norm': 1.7614599466323853, 'learning_rate': 0.0001, 'epoch': 5.0}
{'eval_loss': 0.6331836581230164, 'eval_wer': 0.3194178118674763, 'eval_runtime': 1520.9226, 'eval_samples_per_second': 5.26, 'eval_steps_per_second': 5.26, 'epoch': 5.0}
{'loss': 0.8164, 'grad_norm': 3.2198729515075684, 'learning_rate': 0.0001, 'epoch': 5.2}
{'loss': 0.7822, 'grad_norm': 2.298551082611084, 'learning_rate': 0.0001, 'epoch': 5.4}
{'loss': 0.7728, 'grad_norm': 1.9439260959625244, 'learning_rate': 0.0001, 'epoch': 5.6}
{'loss': 0.7885, 'grad_norm': 1.8157099485397339, 'learning_rate': 0.0001, 'epoch': 5.8}
{'loss': 0.7791, 'grad_norm': 8.18149471282959, 'learning_rate': 0.0001, 'epoch': 6.0}
{'eval_loss': 0.6243224143981934, 'eval_wer': 0.31471716203259825, 'eval_runtime': 1518.9133, 'eval_samples_per_second': 5.267, 'eval_steps_per_second': 5.267, 'epoch': 6.0}
{'loss': 0.7712, 'grad_norm': 2.1725263595581055, 'learning_rate': 0.0001, 'epoch': 6.2}
{'loss': 0.7792, 'grad_norm': 8.169183731079102, 'learning_rate': 0.0001, 'epoch': 6.4}
{'loss': 0.7333, 'grad_norm': 1.6960437297821045, 'learning_rate': 0.0001, 'epoch': 6.6}
{'loss': 0.7531, 'grad_norm': 3.477471113204956, 'learning_rate': 0.0001, 'epoch': 6.8}
{'loss': 0.7888, 'grad_norm': 3.972811460494995, 'learning_rate': 0.0001, 'epoch': 7.0}
{'eval_loss': 0.6260296702384949, 'eval_wer': 0.31354532864599977, 'eval_runtime': 1520.4338, 'eval_samples_per_second': 5.262, 'eval_steps_per_second': 5.262, 'epoch': 7.0}
{'loss': 0.7503, 'grad_norm': 1.9257627725601196, 'learning_rate': 0.0001, 'epoch': 7.2}
{'loss': 0.7341, 'grad_norm': 2.6817739009857178, 'learning_rate': 0.0001, 'epoch': 7.4}
{'loss': 0.7439, 'grad_norm': 1.6021268367767334, 'learning_rate': 0.0001, 'epoch': 7.6}
{'loss': 0.7417, 'grad_norm': 2.338212251663208, 'learning_rate': 0.0001, 'epoch': 7.8}
{'loss': 0.7534, 'grad_norm': 1.9048361778259277, 'learning_rate': 0.0001, 'epoch': 8.0}
{'eval_loss': 0.5973415374755859, 'eval_wer': 0.3139980824544583, 'eval_runtime': 1524.8922, 'eval_samples_per_second': 5.246, 'eval_steps_per_second': 5.246, 'epoch': 8.0}
{'loss': 0.7206, 'grad_norm': 2.0163984298706055, 'learning_rate': 0.0001, 'epoch': 8.2}
{'loss': 0.7136, 'grad_norm': 1.9996771812438965, 'learning_rate': 0.0001, 'epoch': 8.4}
{'loss': 0.7336, 'grad_norm': 2.3075201511383057, 'learning_rate': 0.0001, 'epoch': 8.6}
{'loss': 0.7351, 'grad_norm': 2.6155238151550293, 'learning_rate': 0.0001, 'epoch': 8.8}
{'loss': 0.7407, 'grad_norm': 2.070138454437256, 'learning_rate': 0.0001, 'epoch': 9.0}
{'eval_loss': 0.5981447696685791, 'eval_wer': 0.31109513156493024, 'eval_runtime': 1533.8275, 'eval_samples_per_second': 5.216, 'eval_steps_per_second': 5.216, 'epoch': 9.0}
{'loss': 0.7253, 'grad_norm': 3.6741607189178467, 'learning_rate': 0.0001, 'epoch': 9.2}
{'loss': 0.7113, 'grad_norm': 1.6099474430084229, 'learning_rate': 0.0001, 'epoch': 9.4}
{'loss': 0.7171, 'grad_norm': 2.755488634109497, 'learning_rate': 0.0001, 'epoch': 9.6}
{'loss': 0.7341, 'grad_norm': 2.1475534439086914, 'learning_rate': 0.0001, 'epoch': 9.8}
{'loss': 0.7173, 'grad_norm': 2.8085227012634277, 'learning_rate': 0.0001, 'epoch': 10.0}
{'eval_loss': 0.6270058751106262, 'eval_wer': 0.31028283796740175, 'eval_runtime': 1522.2853, 'eval_samples_per_second': 5.255, 'eval_steps_per_second': 5.255, 'epoch': 10.0}
{'loss': 0.7016, 'grad_norm': 2.992856502532959, 'learning_rate': 0.0001, 'epoch': 10.2}
{'loss': 0.7134, 'grad_norm': 1.421510934829712, 'learning_rate': 0.0001, 'epoch': 10.4}
{'loss': 0.6984, 'grad_norm': 2.1011602878570557, 'learning_rate': 0.0001, 'epoch': 10.6}
{'loss': 0.6956, 'grad_norm': 2.5309813022613525, 'learning_rate': 0.0001, 'epoch': 10.8}
{'loss': 0.7006, 'grad_norm': 2.5426523685455322, 'learning_rate': 0.0001, 'epoch': 11.0}
{'eval_loss': 0.6089497208595276, 'eval_wer': 0.3115345690849047, 'eval_runtime': 1551.0466, 'eval_samples_per_second': 5.158, 'eval_steps_per_second': 5.158, 'epoch': 11.0}
{'loss': 0.6913, 'grad_norm': 2.2276721000671387, 'learning_rate': 0.0001, 'epoch': 11.2}
{'loss': 0.6939, 'grad_norm': 2.1078741550445557, 'learning_rate': 0.0001, 'epoch': 11.4}
{'loss': 0.6943, 'grad_norm': 2.1904876232147217, 'learning_rate': 0.0001, 'epoch': 11.6}
{'loss': 0.6934, 'grad_norm': 1.5864635705947876, 'learning_rate': 0.0001, 'epoch': 11.8}
{'loss': 0.6942, 'grad_norm': 3.036820888519287, 'learning_rate': 0.0001, 'epoch': 12.0}
{'eval_loss': 0.6020058393478394, 'eval_wer': 0.307979120059657, 'eval_runtime': 1539.6963, 'eval_samples_per_second': 5.196, 'eval_steps_per_second': 5.196, 'epoch': 12.0}
{'loss': 0.6808, 'grad_norm': 3.640406608581543, 'learning_rate': 0.0001, 'epoch': 12.2}
{'loss': 0.7082, 'grad_norm': 2.542236804962158, 'learning_rate': 0.0001, 'epoch': 12.4}
{'loss': 0.6617, 'grad_norm': 3.0113041400909424, 'learning_rate': 0.0001, 'epoch': 12.6}
{'loss': 0.6946, 'grad_norm': 2.4041335582733154, 'learning_rate': 0.0001, 'epoch': 12.8}
{'loss': 0.6562, 'grad_norm': 2.576873540878296, 'learning_rate': 0.0001, 'epoch': 13.0}
{'eval_loss': 0.6026336550712585, 'eval_wer': 0.3065942260573133, 'eval_runtime': 1527.3859, 'eval_samples_per_second': 5.238, 'eval_steps_per_second': 5.238, 'epoch': 13.0}
{'loss': 0.6866, 'grad_norm': 2.1863136291503906, 'learning_rate': 0.0001, 'epoch': 13.2}
{'loss': 0.6728, 'grad_norm': 1.9988192319869995, 'learning_rate': 0.0001, 'epoch': 13.4}
{'loss': 0.6493, 'grad_norm': 2.5264105796813965, 'learning_rate': 0.0001, 'epoch': 13.6}
{'loss': 0.6777, 'grad_norm': 4.224176406860352, 'learning_rate': 0.0001, 'epoch': 13.8}
{'loss': 0.6579, 'grad_norm': 1.9882616996765137, 'learning_rate': 0.0001, 'epoch': 14.0}
