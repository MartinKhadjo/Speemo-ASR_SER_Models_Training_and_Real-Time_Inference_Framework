[DIST] MASTER_ADDR=w23g0007 MASTER_PORT=29500 NNODES=1 GPUS_PER_NODE=1
[PRE] Skipping all preprocessing (skip_preprocessing=on or all per-step toggles are 'on')
[TRAIN][ASR] Starting ASR phase ...
[Setup] Using device: cuda
[Setup] no_cuda flag set to: False
[ASR] Loading model + processor‚Ä¶
[ASR] Starting from pretrained: models/pretrained/en
üõ†Ô∏è  Debug collator output shapes: {'input_values': torch.Size([4, 75264]), 'attention_mask': torch.Size([4, 75264]), 'labels': torch.Size([4, 93])}
[ASR] Starting training with HuggingFace Trainer‚Ä¶
w23g0007:3293129:3293129 [0] NCCL INFO Bootstrap : Using ib0:134.61.46.236<0>
w23g0007:3293129:3293129 [0] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation
w23g0007:3293129:3293129 [0] NCCL INFO cudaDriverVersion 12080
NCCL version 2.20.5+cuda12.4
w23g0007:3293129:3293357 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib0:134.61.46.236<0>
w23g0007:3293129:3293357 [0] NCCL INFO Using non-device net plugin version 0
w23g0007:3293129:3293357 [0] NCCL INFO Using network IB
w23g0007:3293129:3293357 [0] NCCL INFO DMA-BUF is available on GPU device 0
w23g0007:3293129:3293357 [0] NCCL INFO comm 0x5610a9b09420 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId ad000 commId 0x9e6786e6d51fcde7 - Init START
w23g0007:3293129:3293357 [0] NCCL INFO Setting affinity for GPU 0 to f000,00000000,00000000
w23g0007:3293129:3293357 [0] NCCL INFO comm 0x5610a9b09420 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
w23g0007:3293129:3293357 [0] NCCL INFO Channel 00/32 :    0
w23g0007:3293129:3293357 [0] NCCL INFO Channel 01/32 :    0
w23g0007:3293129:3293357 [0] NCCL INFO Channel 02/32 :    0
w23g0007:3293129:3293357 [0] NCCL INFO Channel 03/32 :    0
w23g0007:3293129:3293357 [0] NCCL INFO Channel 04/32 :    0
w23g0007:3293129:3293357 [0] NCCL INFO Channel 05/32 :    0
w23g0007:3293129:3293357 [0] NCCL INFO Channel 06/32 :    0
w23g0007:3293129:3293357 [0] NCCL INFO Channel 07/32 :    0
w23g0007:3293129:3293357 [0] NCCL INFO Channel 08/32 :    0
w23g0007:3293129:3293357 [0] NCCL INFO Channel 09/32 :    0
w23g0007:3293129:3293357 [0] NCCL INFO Channel 10/32 :    0
w23g0007:3293129:3293357 [0] NCCL INFO Channel 11/32 :    0
w23g0007:3293129:3293357 [0] NCCL INFO Channel 12/32 :    0
w23g0007:3293129:3293357 [0] NCCL INFO Channel 13/32 :    0
w23g0007:3293129:3293357 [0] NCCL INFO Channel 14/32 :    0
w23g0007:3293129:3293357 [0] NCCL INFO Channel 15/32 :    0
w23g0007:3293129:3293357 [0] NCCL INFO Channel 16/32 :    0
w23g0007:3293129:3293357 [0] NCCL INFO Channel 17/32 :    0
w23g0007:3293129:3293357 [0] NCCL INFO Channel 18/32 :    0
w23g0007:3293129:3293357 [0] NCCL INFO Channel 19/32 :    0
w23g0007:3293129:3293357 [0] NCCL INFO Channel 20/32 :    0
w23g0007:3293129:3293357 [0] NCCL INFO Channel 21/32 :    0
w23g0007:3293129:3293357 [0] NCCL INFO Channel 22/32 :    0
w23g0007:3293129:3293357 [0] NCCL INFO Channel 23/32 :    0
w23g0007:3293129:3293357 [0] NCCL INFO Channel 24/32 :    0
w23g0007:3293129:3293357 [0] NCCL INFO Channel 25/32 :    0
w23g0007:3293129:3293357 [0] NCCL INFO Channel 26/32 :    0
w23g0007:3293129:3293357 [0] NCCL INFO Channel 27/32 :    0
w23g0007:3293129:3293357 [0] NCCL INFO Channel 28/32 :    0
w23g0007:3293129:3293357 [0] NCCL INFO Channel 29/32 :    0
w23g0007:3293129:3293357 [0] NCCL INFO Channel 30/32 :    0
w23g0007:3293129:3293357 [0] NCCL INFO Channel 31/32 :    0
w23g0007:3293129:3293357 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
w23g0007:3293129:3293357 [0] NCCL INFO P2P Chunksize set to 131072
w23g0007:3293129:3293357 [0] NCCL INFO Connected all rings
w23g0007:3293129:3293357 [0] NCCL INFO Connected all trees
w23g0007:3293129:3293357 [0] NCCL INFO 32 coll channels, 0 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
w23g0007:3293129:3293357 [0] NCCL INFO comm 0x5610a9b09420 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId ad000 commId 0x9e6786e6d51fcde7 - Init COMPLETE
{'loss': 2.1461, 'grad_norm': 1.8489323854446411, 'learning_rate': 0.0, 'epoch': 0.0}
{'loss': 1.6779, 'grad_norm': 3.2734897136688232, 'learning_rate': 2.475618904726182e-07, 'epoch': 0.03}
{'loss': 1.699, 'grad_norm': 1.8207148313522339, 'learning_rate': 4.951237809452364e-07, 'epoch': 0.05}
{'loss': 1.6549, 'grad_norm': 1.6733237504959106, 'learning_rate': 7.451862965741435e-07, 'epoch': 0.08}
{'loss': 1.5846, 'grad_norm': 1.0806654691696167, 'learning_rate': 9.952488122030508e-07, 'epoch': 0.1}
{'loss': 1.5587, 'grad_norm': 2.3565523624420166, 'learning_rate': 1.2453113278319582e-06, 'epoch': 0.13}
{'loss': 1.5472, 'grad_norm': 4.267153739929199, 'learning_rate': 1.4953738434608653e-06, 'epoch': 0.15}
{'loss': 1.58, 'grad_norm': 2.8188636302948, 'learning_rate': 1.7454363590897727e-06, 'epoch': 0.18}
{'loss': 1.6778, 'grad_norm': 1.8527666330337524, 'learning_rate': 1.99549887471868e-06, 'epoch': 0.2}
{'loss': 1.618, 'grad_norm': 1.6547588109970093, 'learning_rate': 2.245561390347587e-06, 'epoch': 0.23}
{'loss': 1.6064, 'grad_norm': 3.79303240776062, 'learning_rate': 2.4956239059764944e-06, 'epoch': 0.25}
{'loss': 1.6473, 'grad_norm': 3.046384811401367, 'learning_rate': 2.745686421605401e-06, 'epoch': 0.28}
{'loss': 1.5174, 'grad_norm': 2.216230869293213, 'learning_rate': 2.995748937234309e-06, 'epoch': 0.3}
{'loss': 1.4913, 'grad_norm': 12.718974113464355, 'learning_rate': 3.2458114528632163e-06, 'epoch': 0.33}
{'loss': 1.438, 'grad_norm': 2.336254596710205, 'learning_rate': 3.4958739684921235e-06, 'epoch': 0.35}
{'loss': 1.3989, 'grad_norm': 3.0919270515441895, 'learning_rate': 3.743435858964741e-06, 'epoch': 0.38}
{'loss': 1.3964, 'grad_norm': 1.8446248769760132, 'learning_rate': 3.993498374593649e-06, 'epoch': 0.4}
{'loss': 1.2517, 'grad_norm': 6.467483997344971, 'learning_rate': 4.243560890222556e-06, 'epoch': 0.43}
{'loss': 1.2577, 'grad_norm': 2.9177680015563965, 'learning_rate': 4.4936234058514635e-06, 'epoch': 0.45}
{'loss': 1.3212, 'grad_norm': 3.3830997943878174, 'learning_rate': 4.74368592148037e-06, 'epoch': 0.48}
{'loss': 1.308, 'grad_norm': 2.860640525817871, 'learning_rate': 4.993748437109278e-06, 'epoch': 0.5}
{'loss': 1.2105, 'grad_norm': 4.3519287109375, 'learning_rate': 5.243810952738185e-06, 'epoch': 0.53}
{'loss': 1.2352, 'grad_norm': 3.802070140838623, 'learning_rate': 5.493873468367092e-06, 'epoch': 0.55}
{'loss': 1.1583, 'grad_norm': 5.323730945587158, 'learning_rate': 5.743935983996e-06, 'epoch': 0.58}
{'loss': 1.2395, 'grad_norm': 2.719892978668213, 'learning_rate': 5.991497874468618e-06, 'epoch': 0.6}
{'loss': 1.1842, 'grad_norm': 2.4590702056884766, 'learning_rate': 6.241560390097525e-06, 'epoch': 0.63}
{'loss': 1.2263, 'grad_norm': 2.6369259357452393, 'learning_rate': 6.491622905726433e-06, 'epoch': 0.65}
{'loss': 1.1847, 'grad_norm': 6.012161731719971, 'learning_rate': 6.741685421355339e-06, 'epoch': 0.68}
{'loss': 1.2209, 'grad_norm': 3.587700128555298, 'learning_rate': 6.991747936984247e-06, 'epoch': 0.7}
{'loss': 1.1815, 'grad_norm': 2.4049391746520996, 'learning_rate': 7.241810452613154e-06, 'epoch': 0.73}
{'loss': 1.1144, 'grad_norm': 8.928733825683594, 'learning_rate': 7.491872968242061e-06, 'epoch': 0.75}
{'loss': 1.14, 'grad_norm': 4.970244407653809, 'learning_rate': 7.741935483870968e-06, 'epoch': 0.78}
{'loss': 1.1072, 'grad_norm': 3.5760552883148193, 'learning_rate': 7.991997999499875e-06, 'epoch': 0.8}
{'loss': 1.1751, 'grad_norm': 3.584552049636841, 'learning_rate': 8.242060515128783e-06, 'epoch': 0.83}
{'loss': 1.1434, 'grad_norm': 3.1521413326263428, 'learning_rate': 8.49212303075769e-06, 'epoch': 0.85}
{'loss': 1.0642, 'grad_norm': 3.434298276901245, 'learning_rate': 8.742185546386598e-06, 'epoch': 0.88}
{'loss': 1.0946, 'grad_norm': 6.219893455505371, 'learning_rate': 8.992248062015505e-06, 'epoch': 0.9}
{'loss': 1.0561, 'grad_norm': 3.307431221008301, 'learning_rate': 9.242310577644412e-06, 'epoch': 0.93}
{'loss': 1.1431, 'grad_norm': 22.684846878051758, 'learning_rate': 9.492373093273319e-06, 'epoch': 0.95}
{'loss': 0.9785, 'grad_norm': 7.491842269897461, 'learning_rate': 9.742435608902227e-06, 'epoch': 0.98}
{'eval_loss': 0.8322638869285583, 'eval_wer': 0.40532118887823587, 'eval_runtime': 1498.4951, 'eval_samples_per_second': 5.339, 'eval_steps_per_second': 5.339, 'epoch': 1.0}
{'loss': 1.0036, 'grad_norm': 3.7788307666778564, 'learning_rate': 9.992498124531134e-06, 'epoch': 1.0}
{'loss': 1.0762, 'grad_norm': 3.254613161087036, 'learning_rate': 1e-05, 'epoch': 1.03}
{'loss': 0.9055, 'grad_norm': 7.334254741668701, 'learning_rate': 1e-05, 'epoch': 1.05}
{'loss': 1.0542, 'grad_norm': 6.484233856201172, 'learning_rate': 1e-05, 'epoch': 1.08}
{'loss': 1.0421, 'grad_norm': 1.8506085872650146, 'learning_rate': 1e-05, 'epoch': 1.1}
{'loss': 0.9919, 'grad_norm': 5.602329730987549, 'learning_rate': 1e-05, 'epoch': 1.13}
{'loss': 1.0584, 'grad_norm': 4.780178070068359, 'learning_rate': 1e-05, 'epoch': 1.15}
{'loss': 0.9451, 'grad_norm': 2.881150245666504, 'learning_rate': 1e-05, 'epoch': 1.18}
{'loss': 0.9951, 'grad_norm': 4.5626540184021, 'learning_rate': 1e-05, 'epoch': 1.2}
{'loss': 1.0027, 'grad_norm': 3.1445388793945312, 'learning_rate': 1e-05, 'epoch': 1.23}
{'loss': 0.9474, 'grad_norm': 4.846230506896973, 'learning_rate': 1e-05, 'epoch': 1.25}
{'loss': 1.0077, 'grad_norm': 6.518960952758789, 'learning_rate': 1e-05, 'epoch': 1.28}
{'loss': 0.9242, 'grad_norm': 3.051331043243408, 'learning_rate': 1e-05, 'epoch': 1.3}
{'loss': 1.0257, 'grad_norm': 6.151115417480469, 'learning_rate': 1e-05, 'epoch': 1.33}
{'loss': 0.92, 'grad_norm': 3.964043617248535, 'learning_rate': 1e-05, 'epoch': 1.35}
{'loss': 0.9789, 'grad_norm': 24.24240493774414, 'learning_rate': 1e-05, 'epoch': 1.38}
{'loss': 0.9974, 'grad_norm': 23.592609405517578, 'learning_rate': 1e-05, 'epoch': 1.4}
{'loss': 0.9501, 'grad_norm': 2.217971086502075, 'learning_rate': 1e-05, 'epoch': 1.43}
{'loss': 0.99, 'grad_norm': 3.8324410915374756, 'learning_rate': 1e-05, 'epoch': 1.45}
{'loss': 1.0116, 'grad_norm': 1.1363296508789062, 'learning_rate': 1e-05, 'epoch': 1.48}
{'loss': 0.9513, 'grad_norm': 6.753012657165527, 'learning_rate': 1e-05, 'epoch': 1.5}
{'loss': 0.9793, 'grad_norm': 2.360961437225342, 'learning_rate': 1e-05, 'epoch': 1.53}
{'loss': 0.8899, 'grad_norm': 5.561803817749023, 'learning_rate': 1e-05, 'epoch': 1.55}
{'loss': 1.3022, 'grad_norm': 4.761374473571777, 'learning_rate': 1e-05, 'epoch': 1.58}
{'loss': 0.9605, 'grad_norm': 2.9667763710021973, 'learning_rate': 1e-05, 'epoch': 1.6}
{'loss': 0.8894, 'grad_norm': 6.526737689971924, 'learning_rate': 1e-05, 'epoch': 1.63}
{'loss': 0.998, 'grad_norm': 7.185362339019775, 'learning_rate': 1e-05, 'epoch': 1.65}
{'loss': 0.9844, 'grad_norm': 6.786447048187256, 'learning_rate': 1e-05, 'epoch': 1.68}
{'loss': 0.9382, 'grad_norm': 5.287883758544922, 'learning_rate': 1e-05, 'epoch': 1.7}
{'loss': 1.0324, 'grad_norm': 3.7285590171813965, 'learning_rate': 1e-05, 'epoch': 1.73}
{'loss': 0.9745, 'grad_norm': 2.809072732925415, 'learning_rate': 1e-05, 'epoch': 1.75}
{'loss': 1.008, 'grad_norm': 9.398682594299316, 'learning_rate': 1e-05, 'epoch': 1.78}
{'loss': 0.9103, 'grad_norm': 12.479990005493164, 'learning_rate': 1e-05, 'epoch': 1.8}
{'loss': 0.9334, 'grad_norm': 7.545639991760254, 'learning_rate': 1e-05, 'epoch': 1.83}
{'loss': 1.0361, 'grad_norm': 5.299198150634766, 'learning_rate': 1e-05, 'epoch': 1.85}
{'loss': 0.8898, 'grad_norm': 7.124513149261475, 'learning_rate': 1e-05, 'epoch': 1.88}
{'loss': 1.052, 'grad_norm': 3.1713335514068604, 'learning_rate': 1e-05, 'epoch': 1.9}
{'loss': 0.9701, 'grad_norm': 3.0511934757232666, 'learning_rate': 1e-05, 'epoch': 1.93}
{'loss': 0.974, 'grad_norm': 6.311560153961182, 'learning_rate': 1e-05, 'epoch': 1.95}
{'loss': 0.9221, 'grad_norm': 10.377215385437012, 'learning_rate': 1e-05, 'epoch': 1.98}
{'eval_loss': 0.752135694026947, 'eval_wer': 0.37671780121444554, 'eval_runtime': 1490.2783, 'eval_samples_per_second': 5.368, 'eval_steps_per_second': 5.368, 'epoch': 2.0}
{'loss': 0.9444, 'grad_norm': 26.457151412963867, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.9404, 'grad_norm': 4.826290607452393, 'learning_rate': 1e-05, 'epoch': 2.03}
{'loss': 0.9136, 'grad_norm': 8.38232421875, 'learning_rate': 1e-05, 'epoch': 2.05}
{'loss': 0.8686, 'grad_norm': 8.955825805664062, 'learning_rate': 1e-05, 'epoch': 2.08}
{'loss': 0.881, 'grad_norm': 5.59974479675293, 'learning_rate': 1e-05, 'epoch': 2.1}
{'loss': 0.9143, 'grad_norm': 4.777184009552002, 'learning_rate': 1e-05, 'epoch': 2.13}
{'loss': 0.9508, 'grad_norm': 12.401928901672363, 'learning_rate': 1e-05, 'epoch': 2.15}
{'loss': 0.9477, 'grad_norm': 3.290175676345825, 'learning_rate': 1e-05, 'epoch': 2.18}
{'loss': 0.8923, 'grad_norm': 5.2882771492004395, 'learning_rate': 1e-05, 'epoch': 2.2}
{'loss': 0.8741, 'grad_norm': 2.7975926399230957, 'learning_rate': 1e-05, 'epoch': 2.23}
{'loss': 0.9072, 'grad_norm': 1.746854543685913, 'learning_rate': 1e-05, 'epoch': 2.25}
{'loss': 0.9176, 'grad_norm': 6.530455589294434, 'learning_rate': 1e-05, 'epoch': 2.28}
{'loss': 0.9313, 'grad_norm': 4.051130771636963, 'learning_rate': 1e-05, 'epoch': 2.3}
{'loss': 0.8995, 'grad_norm': 2.440307855606079, 'learning_rate': 1e-05, 'epoch': 2.33}
{'loss': 0.9756, 'grad_norm': 6.826476097106934, 'learning_rate': 1e-05, 'epoch': 2.35}
{'loss': 0.909, 'grad_norm': 4.556924343109131, 'learning_rate': 1e-05, 'epoch': 2.38}
{'loss': 0.9314, 'grad_norm': 9.172891616821289, 'learning_rate': 1e-05, 'epoch': 2.4}
{'loss': 0.997, 'grad_norm': 8.217081069946289, 'learning_rate': 1e-05, 'epoch': 2.43}
{'loss': 0.8849, 'grad_norm': 5.5341644287109375, 'learning_rate': 1e-05, 'epoch': 2.45}
{'loss': 0.8499, 'grad_norm': 7.689745903015137, 'learning_rate': 1e-05, 'epoch': 2.48}
{'loss': 0.9712, 'grad_norm': 4.47851037979126, 'learning_rate': 1e-05, 'epoch': 2.5}
{'loss': 0.9251, 'grad_norm': 9.432374954223633, 'learning_rate': 1e-05, 'epoch': 2.53}
{'loss': 0.9233, 'grad_norm': 7.692285537719727, 'learning_rate': 1e-05, 'epoch': 2.55}
{'loss': 0.9441, 'grad_norm': 6.174470901489258, 'learning_rate': 1e-05, 'epoch': 2.58}
{'loss': 0.9593, 'grad_norm': 7.104216575622559, 'learning_rate': 1e-05, 'epoch': 2.6}
{'loss': 0.9315, 'grad_norm': 3.4944095611572266, 'learning_rate': 1e-05, 'epoch': 2.63}
{'loss': 0.963, 'grad_norm': 3.4685027599334717, 'learning_rate': 1e-05, 'epoch': 2.65}
{'loss': 0.861, 'grad_norm': 2.47688627243042, 'learning_rate': 1e-05, 'epoch': 2.68}
{'loss': 0.91, 'grad_norm': 10.565193176269531, 'learning_rate': 1e-05, 'epoch': 2.7}
{'loss': 0.8656, 'grad_norm': 4.332239627838135, 'learning_rate': 1e-05, 'epoch': 2.73}
{'loss': 0.9549, 'grad_norm': 3.1163878440856934, 'learning_rate': 1e-05, 'epoch': 2.75}
{'loss': 0.921, 'grad_norm': 4.7505998611450195, 'learning_rate': 1e-05, 'epoch': 2.78}
{'loss': 0.8779, 'grad_norm': 2.730180025100708, 'learning_rate': 1e-05, 'epoch': 2.8}
{'loss': 0.885, 'grad_norm': 5.683791160583496, 'learning_rate': 1e-05, 'epoch': 2.83}
{'loss': 0.9227, 'grad_norm': 9.101398468017578, 'learning_rate': 1e-05, 'epoch': 2.85}
{'loss': 0.9265, 'grad_norm': 6.170858860015869, 'learning_rate': 1e-05, 'epoch': 2.88}
{'loss': 1.0097, 'grad_norm': 9.628496170043945, 'learning_rate': 1e-05, 'epoch': 2.9}
{'loss': 0.8621, 'grad_norm': 7.031095027923584, 'learning_rate': 1e-05, 'epoch': 2.93}
{'loss': 0.9722, 'grad_norm': 5.692385196685791, 'learning_rate': 1e-05, 'epoch': 2.95}
{'loss': 0.9945, 'grad_norm': 3.713817596435547, 'learning_rate': 1e-05, 'epoch': 2.98}
{'eval_loss': 0.7195464968681335, 'eval_wer': 0.3564637264301694, 'eval_runtime': 1489.5391, 'eval_samples_per_second': 5.371, 'eval_steps_per_second': 5.371, 'epoch': 3.0}
{'loss': 0.9319, 'grad_norm': 17.796825408935547, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.8373, 'grad_norm': 2.9135372638702393, 'learning_rate': 1e-05, 'epoch': 3.03}
{'loss': 0.8669, 'grad_norm': 4.984325885772705, 'learning_rate': 1e-05, 'epoch': 3.05}
{'loss': 0.8513, 'grad_norm': 6.086994647979736, 'learning_rate': 1e-05, 'epoch': 3.08}
{'loss': 0.9058, 'grad_norm': 4.779886245727539, 'learning_rate': 1e-05, 'epoch': 3.1}
{'loss': 0.9332, 'grad_norm': 7.036649227142334, 'learning_rate': 1e-05, 'epoch': 3.13}
{'loss': 0.9838, 'grad_norm': 4.955379009246826, 'learning_rate': 1e-05, 'epoch': 3.15}
{'loss': 0.9365, 'grad_norm': 6.910635471343994, 'learning_rate': 1e-05, 'epoch': 3.18}
{'loss': 0.9245, 'grad_norm': 6.0972700119018555, 'learning_rate': 1e-05, 'epoch': 3.2}
{'loss': 0.9394, 'grad_norm': 5.297918796539307, 'learning_rate': 1e-05, 'epoch': 3.23}
{'loss': 0.9017, 'grad_norm': 5.044760704040527, 'learning_rate': 1e-05, 'epoch': 3.25}
{'loss': 0.9788, 'grad_norm': 6.645961761474609, 'learning_rate': 1e-05, 'epoch': 3.28}
{'loss': 0.8381, 'grad_norm': 6.126536846160889, 'learning_rate': 1e-05, 'epoch': 3.3}
{'loss': 0.7864, 'grad_norm': 8.120494842529297, 'learning_rate': 1e-05, 'epoch': 3.33}
{'loss': 0.9007, 'grad_norm': 4.1562395095825195, 'learning_rate': 1e-05, 'epoch': 3.35}
{'loss': 0.9515, 'grad_norm': 2.1077170372009277, 'learning_rate': 1e-05, 'epoch': 3.38}
{'loss': 0.9202, 'grad_norm': 6.466986656188965, 'learning_rate': 1e-05, 'epoch': 3.4}
{'loss': 0.944, 'grad_norm': 21.05134391784668, 'learning_rate': 1e-05, 'epoch': 3.43}
{'loss': 0.8773, 'grad_norm': 5.503549575805664, 'learning_rate': 1e-05, 'epoch': 3.45}
{'loss': 0.9447, 'grad_norm': 4.9956464767456055, 'learning_rate': 1e-05, 'epoch': 3.48}
{'loss': 0.9359, 'grad_norm': 11.218683242797852, 'learning_rate': 1e-05, 'epoch': 3.5}
{'loss': 0.7929, 'grad_norm': 5.678702354431152, 'learning_rate': 1e-05, 'epoch': 3.53}
{'loss': 0.8978, 'grad_norm': 3.6657087802886963, 'learning_rate': 1e-05, 'epoch': 3.55}
{'loss': 0.9809, 'grad_norm': 6.280261039733887, 'learning_rate': 1e-05, 'epoch': 3.58}
{'loss': 0.8515, 'grad_norm': 28.621219635009766, 'learning_rate': 1e-05, 'epoch': 3.6}
{'loss': 0.8882, 'grad_norm': 5.55597448348999, 'learning_rate': 1e-05, 'epoch': 3.63}
{'loss': 0.9497, 'grad_norm': 10.15564250946045, 'learning_rate': 1e-05, 'epoch': 3.65}
{'loss': 0.8391, 'grad_norm': 2.947120189666748, 'learning_rate': 1e-05, 'epoch': 3.68}
{'loss': 0.8649, 'grad_norm': 10.006505012512207, 'learning_rate': 1e-05, 'epoch': 3.7}
{'loss': 0.892, 'grad_norm': 7.549897193908691, 'learning_rate': 1e-05, 'epoch': 3.73}
{'loss': 0.8423, 'grad_norm': 5.736753463745117, 'learning_rate': 1e-05, 'epoch': 3.75}
{'loss': 0.9392, 'grad_norm': 3.2357821464538574, 'learning_rate': 1e-05, 'epoch': 3.78}
{'loss': 0.8613, 'grad_norm': 4.523707866668701, 'learning_rate': 1e-05, 'epoch': 3.8}
{'loss': 0.8219, 'grad_norm': 4.742392063140869, 'learning_rate': 1e-05, 'epoch': 3.83}
{'loss': 0.8794, 'grad_norm': 5.342672348022461, 'learning_rate': 1e-05, 'epoch': 3.85}
{'loss': 0.8977, 'grad_norm': 6.7719268798828125, 'learning_rate': 1e-05, 'epoch': 3.88}
{'loss': 0.8743, 'grad_norm': 8.111210823059082, 'learning_rate': 1e-05, 'epoch': 3.9}
{'loss': 0.88, 'grad_norm': 7.737978935241699, 'learning_rate': 1e-05, 'epoch': 3.93}
{'loss': 0.9048, 'grad_norm': 5.688933849334717, 'learning_rate': 1e-05, 'epoch': 3.95}
{'loss': 0.8339, 'grad_norm': 6.7952704429626465, 'learning_rate': 1e-05, 'epoch': 3.98}
{'eval_loss': 0.7116580605506897, 'eval_wer': 0.3475817620112922, 'eval_runtime': 1508.1456, 'eval_samples_per_second': 5.305, 'eval_steps_per_second': 5.305, 'epoch': 4.0}
{'loss': 0.8107, 'grad_norm': 7.248085975646973, 'learning_rate': 1e-05, 'epoch': 4.0}
{'loss': 0.8629, 'grad_norm': 16.097206115722656, 'learning_rate': 1e-05, 'epoch': 4.03}
{'loss': 0.9615, 'grad_norm': 5.48506498336792, 'learning_rate': 1e-05, 'epoch': 4.05}
{'loss': 0.9144, 'grad_norm': 2.986680269241333, 'learning_rate': 1e-05, 'epoch': 4.08}
{'loss': 0.8691, 'grad_norm': 5.554034233093262, 'learning_rate': 1e-05, 'epoch': 4.1}
{'loss': 0.8439, 'grad_norm': 5.019359111785889, 'learning_rate': 1e-05, 'epoch': 4.13}
{'loss': 0.8201, 'grad_norm': 8.937435150146484, 'learning_rate': 1e-05, 'epoch': 4.15}
{'loss': 0.8821, 'grad_norm': 3.768371820449829, 'learning_rate': 1e-05, 'epoch': 4.18}
{'loss': 0.8455, 'grad_norm': 7.132458209991455, 'learning_rate': 1e-05, 'epoch': 4.2}
{'loss': 0.825, 'grad_norm': 4.61334753036499, 'learning_rate': 1e-05, 'epoch': 4.23}
{'loss': 0.8824, 'grad_norm': 4.392333507537842, 'learning_rate': 1e-05, 'epoch': 4.25}
{'loss': 0.8847, 'grad_norm': 3.7206006050109863, 'learning_rate': 1e-05, 'epoch': 4.28}
{'loss': 0.8428, 'grad_norm': 4.451046943664551, 'learning_rate': 1e-05, 'epoch': 4.3}
{'loss': 0.8973, 'grad_norm': 5.975369930267334, 'learning_rate': 1e-05, 'epoch': 4.33}
{'loss': 0.897, 'grad_norm': 7.540464878082275, 'learning_rate': 1e-05, 'epoch': 4.35}
{'loss': 0.8846, 'grad_norm': 9.6061429977417, 'learning_rate': 1e-05, 'epoch': 4.38}
{'loss': 0.8274, 'grad_norm': 6.901559829711914, 'learning_rate': 1e-05, 'epoch': 4.4}
{'loss': 0.9591, 'grad_norm': 1.8022961616516113, 'learning_rate': 1e-05, 'epoch': 4.43}
{'loss': 0.9213, 'grad_norm': 5.416785717010498, 'learning_rate': 1e-05, 'epoch': 4.45}
{'loss': 0.8711, 'grad_norm': 7.016895771026611, 'learning_rate': 1e-05, 'epoch': 4.48}
{'loss': 0.7985, 'grad_norm': 6.370134353637695, 'learning_rate': 1e-05, 'epoch': 4.5}
{'loss': 0.9637, 'grad_norm': 8.015399932861328, 'learning_rate': 1e-05, 'epoch': 4.53}
{'loss': 0.8914, 'grad_norm': 7.576388835906982, 'learning_rate': 1e-05, 'epoch': 4.55}
{'loss': 0.9276, 'grad_norm': 15.376497268676758, 'learning_rate': 1e-05, 'epoch': 4.58}
{'loss': 0.8476, 'grad_norm': 8.633448600769043, 'learning_rate': 1e-05, 'epoch': 4.6}
{'loss': 0.858, 'grad_norm': 5.070263385772705, 'learning_rate': 1e-05, 'epoch': 4.63}
{'loss': 0.8345, 'grad_norm': 2.3953866958618164, 'learning_rate': 1e-05, 'epoch': 4.65}
{'loss': 0.8104, 'grad_norm': 9.019550323486328, 'learning_rate': 1e-05, 'epoch': 4.68}
{'loss': 0.8723, 'grad_norm': 7.39865255355835, 'learning_rate': 1e-05, 'epoch': 4.7}
{'loss': 0.8698, 'grad_norm': 10.280569076538086, 'learning_rate': 1e-05, 'epoch': 4.73}
{'loss': 0.8136, 'grad_norm': 4.86356258392334, 'learning_rate': 1e-05, 'epoch': 4.75}
{'loss': 0.8638, 'grad_norm': 10.032340049743652, 'learning_rate': 1e-05, 'epoch': 4.78}
{'loss': 0.8493, 'grad_norm': 8.028185844421387, 'learning_rate': 1e-05, 'epoch': 4.8}
{'loss': 0.8548, 'grad_norm': 7.529655933380127, 'learning_rate': 1e-05, 'epoch': 4.83}
{'loss': 0.8464, 'grad_norm': 4.935863018035889, 'learning_rate': 1e-05, 'epoch': 4.85}
{'loss': 0.9342, 'grad_norm': 3.0622496604919434, 'learning_rate': 1e-05, 'epoch': 4.88}
{'loss': 0.862, 'grad_norm': 7.03974723815918, 'learning_rate': 1e-05, 'epoch': 4.9}
{'loss': 0.9277, 'grad_norm': 3.5706140995025635, 'learning_rate': 1e-05, 'epoch': 4.93}
{'loss': 0.9008, 'grad_norm': 6.482694625854492, 'learning_rate': 1e-05, 'epoch': 4.95}
{'loss': 0.8479, 'grad_norm': 4.048055171966553, 'learning_rate': 1e-05, 'epoch': 4.98}
{'eval_loss': 0.7026692032814026, 'eval_wer': 0.3393389794396506, 'eval_runtime': 1502.5168, 'eval_samples_per_second': 5.324, 'eval_steps_per_second': 5.324, 'epoch': 5.0}
{'loss': 0.8835, 'grad_norm': 3.552902936935425, 'learning_rate': 1e-05, 'epoch': 5.0}
{'loss': 0.8517, 'grad_norm': 4.587337017059326, 'learning_rate': 1e-05, 'epoch': 5.03}
{'loss': 0.9612, 'grad_norm': 6.300290107727051, 'learning_rate': 1e-05, 'epoch': 5.05}
{'loss': 0.7975, 'grad_norm': 16.607202529907227, 'learning_rate': 1e-05, 'epoch': 5.08}
{'loss': 0.7923, 'grad_norm': 4.697154998779297, 'learning_rate': 1e-05, 'epoch': 5.1}
{'loss': 0.8938, 'grad_norm': 5.222207546234131, 'learning_rate': 1e-05, 'epoch': 5.13}
{'loss': 0.8602, 'grad_norm': 5.082021236419678, 'learning_rate': 1e-05, 'epoch': 5.15}
{'loss': 0.9154, 'grad_norm': 5.386605262756348, 'learning_rate': 1e-05, 'epoch': 5.18}
{'loss': 0.89, 'grad_norm': 4.837396621704102, 'learning_rate': 1e-05, 'epoch': 5.2}
{'loss': 0.8457, 'grad_norm': 1.86140775680542, 'learning_rate': 1e-05, 'epoch': 5.23}
{'loss': 0.9043, 'grad_norm': 11.808575630187988, 'learning_rate': 1e-05, 'epoch': 5.25}
{'loss': 0.9165, 'grad_norm': 8.077380180358887, 'learning_rate': 1e-05, 'epoch': 5.28}
{'loss': 0.8099, 'grad_norm': 4.091044902801514, 'learning_rate': 1e-05, 'epoch': 5.3}
{'loss': 0.8899, 'grad_norm': 4.518884658813477, 'learning_rate': 1e-05, 'epoch': 5.33}
{'loss': 0.8412, 'grad_norm': 8.475379943847656, 'learning_rate': 1e-05, 'epoch': 5.35}
{'loss': 0.798, 'grad_norm': 2.9651753902435303, 'learning_rate': 1e-05, 'epoch': 5.38}
{'loss': 0.8146, 'grad_norm': 5.044071197509766, 'learning_rate': 1e-05, 'epoch': 5.4}
{'loss': 0.922, 'grad_norm': 6.4017133712768555, 'learning_rate': 1e-05, 'epoch': 5.43}
{'loss': 0.8314, 'grad_norm': 4.770590305328369, 'learning_rate': 1e-05, 'epoch': 5.45}
{'loss': 0.8465, 'grad_norm': 9.17354965209961, 'learning_rate': 1e-05, 'epoch': 5.48}
{'loss': 0.96, 'grad_norm': 4.428863048553467, 'learning_rate': 1e-05, 'epoch': 5.5}
{'loss': 0.8108, 'grad_norm': 14.773353576660156, 'learning_rate': 1e-05, 'epoch': 5.53}
{'loss': 0.8386, 'grad_norm': 6.564393520355225, 'learning_rate': 1e-05, 'epoch': 5.55}
{'loss': 0.7861, 'grad_norm': 4.167477130889893, 'learning_rate': 1e-05, 'epoch': 5.58}
{'loss': 0.7727, 'grad_norm': 20.109790802001953, 'learning_rate': 1e-05, 'epoch': 5.6}
{'loss': 0.7562, 'grad_norm': 6.995738983154297, 'learning_rate': 1e-05, 'epoch': 5.63}
{'loss': 0.9234, 'grad_norm': 4.797413349151611, 'learning_rate': 1e-05, 'epoch': 5.65}
{'loss': 0.763, 'grad_norm': 7.597928047180176, 'learning_rate': 1e-05, 'epoch': 5.68}
{'loss': 0.8805, 'grad_norm': 7.086014270782471, 'learning_rate': 1e-05, 'epoch': 5.7}
{'loss': 0.857, 'grad_norm': 8.072832107543945, 'learning_rate': 1e-05, 'epoch': 5.73}
{'loss': 1.0208, 'grad_norm': 5.98117733001709, 'learning_rate': 1e-05, 'epoch': 5.75}
{'loss': 0.9004, 'grad_norm': 3.0368857383728027, 'learning_rate': 1e-05, 'epoch': 5.78}
{'loss': 0.8944, 'grad_norm': 32.25516891479492, 'learning_rate': 1e-05, 'epoch': 5.8}
{'loss': 0.7982, 'grad_norm': 4.594274997711182, 'learning_rate': 1e-05, 'epoch': 5.83}
{'loss': 0.949, 'grad_norm': 5.0658159255981445, 'learning_rate': 1e-05, 'epoch': 5.85}
{'loss': 0.85, 'grad_norm': 7.507091999053955, 'learning_rate': 1e-05, 'epoch': 5.88}
{'loss': 0.8278, 'grad_norm': 4.806437969207764, 'learning_rate': 1e-05, 'epoch': 5.9}
{'loss': 0.916, 'grad_norm': 11.549972534179688, 'learning_rate': 1e-05, 'epoch': 5.93}
{'loss': 0.8261, 'grad_norm': 5.756239891052246, 'learning_rate': 1e-05, 'epoch': 5.95}
{'loss': 0.8198, 'grad_norm': 7.373832702636719, 'learning_rate': 1e-05, 'epoch': 5.98}
{'eval_loss': 0.6953119039535522, 'eval_wer': 0.3344652178544796, 'eval_runtime': 1503.7138, 'eval_samples_per_second': 5.32, 'eval_steps_per_second': 5.32, 'epoch': 6.0}
{'loss': 0.8156, 'grad_norm': 3.8143463134765625, 'learning_rate': 1e-05, 'epoch': 6.0}
{'loss': 0.85, 'grad_norm': 11.694826126098633, 'learning_rate': 1e-05, 'epoch': 6.03}
{'loss': 0.8645, 'grad_norm': 23.16582489013672, 'learning_rate': 1e-05, 'epoch': 6.05}
{'loss': 0.8511, 'grad_norm': 5.380365371704102, 'learning_rate': 1e-05, 'epoch': 6.08}
{'loss': 0.8493, 'grad_norm': 20.597993850708008, 'learning_rate': 1e-05, 'epoch': 6.1}
{'loss': 0.8652, 'grad_norm': 2.3806796073913574, 'learning_rate': 1e-05, 'epoch': 6.13}
{'loss': 0.7925, 'grad_norm': 23.41730308532715, 'learning_rate': 1e-05, 'epoch': 6.15}
{'loss': 0.8845, 'grad_norm': 12.972478866577148, 'learning_rate': 1e-05, 'epoch': 6.18}
{'loss': 0.9196, 'grad_norm': 14.140157699584961, 'learning_rate': 1e-05, 'epoch': 6.2}
{'loss': 0.8115, 'grad_norm': 6.543856143951416, 'learning_rate': 1e-05, 'epoch': 6.23}
{'loss': 0.7929, 'grad_norm': 8.85952377319336, 'learning_rate': 1e-05, 'epoch': 6.25}
{'loss': 0.9144, 'grad_norm': 4.284360408782959, 'learning_rate': 1e-05, 'epoch': 6.28}
{'loss': 0.8198, 'grad_norm': 18.007080078125, 'learning_rate': 1e-05, 'epoch': 6.3}
{'loss': 0.8841, 'grad_norm': 16.027301788330078, 'learning_rate': 1e-05, 'epoch': 6.33}
{'loss': 0.8778, 'grad_norm': 3.7073583602905273, 'learning_rate': 1e-05, 'epoch': 6.35}
{'loss': 0.8366, 'grad_norm': 4.022513389587402, 'learning_rate': 1e-05, 'epoch': 6.38}
{'loss': 0.8607, 'grad_norm': 3.58721923828125, 'learning_rate': 1e-05, 'epoch': 6.4}
{'loss': 0.8553, 'grad_norm': 8.360228538513184, 'learning_rate': 1e-05, 'epoch': 6.43}
{'loss': 0.8314, 'grad_norm': 10.501614570617676, 'learning_rate': 1e-05, 'epoch': 6.45}
{'loss': 0.7856, 'grad_norm': 3.5877017974853516, 'learning_rate': 1e-05, 'epoch': 6.48}
{'loss': 0.7543, 'grad_norm': 9.158051490783691, 'learning_rate': 1e-05, 'epoch': 6.5}
{'loss': 0.8589, 'grad_norm': 8.982905387878418, 'learning_rate': 1e-05, 'epoch': 6.53}
{'loss': 0.8677, 'grad_norm': 22.552194595336914, 'learning_rate': 1e-05, 'epoch': 6.55}
{'loss': 0.7907, 'grad_norm': 8.73953628540039, 'learning_rate': 1e-05, 'epoch': 6.58}
{'loss': 0.7996, 'grad_norm': 13.308638572692871, 'learning_rate': 1e-05, 'epoch': 6.6}
{'loss': 0.7917, 'grad_norm': 5.579674243927002, 'learning_rate': 1e-05, 'epoch': 6.63}
{'loss': 0.8764, 'grad_norm': 12.653128623962402, 'learning_rate': 1e-05, 'epoch': 6.65}
{'loss': 0.8782, 'grad_norm': 3.247445821762085, 'learning_rate': 1e-05, 'epoch': 6.68}
{'loss': 0.8013, 'grad_norm': 3.5388758182525635, 'learning_rate': 1e-05, 'epoch': 6.7}
{'loss': 0.7901, 'grad_norm': 4.348455905914307, 'learning_rate': 1e-05, 'epoch': 6.73}
{'loss': 0.8463, 'grad_norm': 4.572870254516602, 'learning_rate': 1e-05, 'epoch': 6.75}
{'loss': 0.8225, 'grad_norm': 13.754352569580078, 'learning_rate': 1e-05, 'epoch': 6.78}
{'loss': 0.8602, 'grad_norm': 10.337457656860352, 'learning_rate': 1e-05, 'epoch': 6.8}
{'loss': 0.7999, 'grad_norm': 4.73769998550415, 'learning_rate': 1e-05, 'epoch': 6.83}
{'loss': 0.8304, 'grad_norm': 6.760536193847656, 'learning_rate': 1e-05, 'epoch': 6.85}
{'loss': 1.0319, 'grad_norm': 6.243292331695557, 'learning_rate': 1e-05, 'epoch': 6.88}
{'loss': 0.8145, 'grad_norm': 8.651053428649902, 'learning_rate': 1e-05, 'epoch': 6.9}
{'loss': 0.8586, 'grad_norm': 10.868600845336914, 'learning_rate': 1e-05, 'epoch': 6.93}
{'loss': 0.8908, 'grad_norm': 9.073333740234375, 'learning_rate': 1e-05, 'epoch': 6.95}
{'loss': 0.8772, 'grad_norm': 3.8091156482696533, 'learning_rate': 1e-05, 'epoch': 6.98}
{'eval_loss': 0.6882299780845642, 'eval_wer': 0.3328406306594226, 'eval_runtime': 1494.3178, 'eval_samples_per_second': 5.354, 'eval_steps_per_second': 5.354, 'epoch': 7.0}
{'loss': 0.9147, 'grad_norm': 3.4799180030822754, 'learning_rate': 1e-05, 'epoch': 7.0}
{'loss': 0.7414, 'grad_norm': 9.705634117126465, 'learning_rate': 1e-05, 'epoch': 7.03}
{'loss': 0.8236, 'grad_norm': 3.6599931716918945, 'learning_rate': 1e-05, 'epoch': 7.05}
{'loss': 0.8566, 'grad_norm': 2.4843740463256836, 'learning_rate': 1e-05, 'epoch': 7.08}
{'loss': 0.91, 'grad_norm': 7.421451091766357, 'learning_rate': 1e-05, 'epoch': 7.1}
{'loss': 0.8476, 'grad_norm': 7.0605902671813965, 'learning_rate': 1e-05, 'epoch': 7.13}
{'loss': 0.8917, 'grad_norm': 6.826325416564941, 'learning_rate': 1e-05, 'epoch': 7.15}
{'loss': 0.8191, 'grad_norm': 7.272345066070557, 'learning_rate': 1e-05, 'epoch': 7.18}
{'loss': 0.8527, 'grad_norm': 3.2866597175598145, 'learning_rate': 1e-05, 'epoch': 7.2}
{'loss': 0.8084, 'grad_norm': 5.005442142486572, 'learning_rate': 1e-05, 'epoch': 7.23}
{'loss': 0.8004, 'grad_norm': 4.96540641784668, 'learning_rate': 1e-05, 'epoch': 7.25}
{'loss': 0.8381, 'grad_norm': 6.113725185394287, 'learning_rate': 1e-05, 'epoch': 7.28}
{'loss': 0.8112, 'grad_norm': 5.632248878479004, 'learning_rate': 1e-05, 'epoch': 7.3}
{'loss': 0.8539, 'grad_norm': 54.839962005615234, 'learning_rate': 1e-05, 'epoch': 7.33}
{'loss': 0.8816, 'grad_norm': 5.330682277679443, 'learning_rate': 1e-05, 'epoch': 7.35}
{'loss': 0.7562, 'grad_norm': 4.80144739151001, 'learning_rate': 1e-05, 'epoch': 7.38}
{'loss': 0.884, 'grad_norm': 6.425121784210205, 'learning_rate': 1e-05, 'epoch': 7.4}
{'loss': 0.9007, 'grad_norm': 5.512142181396484, 'learning_rate': 1e-05, 'epoch': 7.43}
{'loss': 0.8037, 'grad_norm': 2.7986397743225098, 'learning_rate': 1e-05, 'epoch': 7.45}
{'loss': 0.7956, 'grad_norm': 6.206148147583008, 'learning_rate': 1e-05, 'epoch': 7.48}
{'loss': 0.8673, 'grad_norm': 4.896996974945068, 'learning_rate': 1e-05, 'epoch': 7.5}
{'loss': 0.7802, 'grad_norm': 9.086644172668457, 'learning_rate': 1e-05, 'epoch': 7.53}
{'loss': 0.8649, 'grad_norm': 7.9419379234313965, 'learning_rate': 1e-05, 'epoch': 7.55}
{'loss': 0.8466, 'grad_norm': 9.966391563415527, 'learning_rate': 1e-05, 'epoch': 7.58}
{'loss': 0.811, 'grad_norm': 7.503092288970947, 'learning_rate': 1e-05, 'epoch': 7.6}
{'loss': 0.7898, 'grad_norm': 5.8663010597229, 'learning_rate': 1e-05, 'epoch': 7.63}
{'loss': 0.7843, 'grad_norm': 9.781872749328613, 'learning_rate': 1e-05, 'epoch': 7.65}
{'loss': 0.8464, 'grad_norm': 4.223000526428223, 'learning_rate': 1e-05, 'epoch': 7.68}
{'loss': 0.859, 'grad_norm': 9.31113052368164, 'learning_rate': 1e-05, 'epoch': 7.7}
{'loss': 0.8052, 'grad_norm': 30.43548011779785, 'learning_rate': 1e-05, 'epoch': 7.73}
{'loss': 0.7964, 'grad_norm': 9.715333938598633, 'learning_rate': 1e-05, 'epoch': 7.75}
{'loss': 0.8863, 'grad_norm': 4.685787677764893, 'learning_rate': 1e-05, 'epoch': 7.78}
{'loss': 0.8839, 'grad_norm': 3.3896493911743164, 'learning_rate': 1e-05, 'epoch': 7.8}
{'loss': 0.9222, 'grad_norm': 5.3748779296875, 'learning_rate': 1e-05, 'epoch': 7.83}
{'loss': 0.8423, 'grad_norm': 7.930082321166992, 'learning_rate': 1e-05, 'epoch': 7.85}
{'loss': 0.8805, 'grad_norm': 3.762568235397339, 'learning_rate': 1e-05, 'epoch': 7.88}
{'loss': 0.849, 'grad_norm': 10.159656524658203, 'learning_rate': 1e-05, 'epoch': 7.9}
{'loss': 0.8622, 'grad_norm': 4.54751443862915, 'learning_rate': 1e-05, 'epoch': 7.93}
{'loss': 0.85, 'grad_norm': 5.209029197692871, 'learning_rate': 1e-05, 'epoch': 7.95}
{'loss': 0.8037, 'grad_norm': 6.107827663421631, 'learning_rate': 1e-05, 'epoch': 7.98}
{'eval_loss': 0.6785554885864258, 'eval_wer': 0.32952487482688825, 'eval_runtime': 1490.0164, 'eval_samples_per_second': 5.369, 'eval_steps_per_second': 5.369, 'epoch': 8.0}
{'loss': 0.903, 'grad_norm': 6.654337406158447, 'learning_rate': 1e-05, 'epoch': 8.0}
{'loss': 0.8132, 'grad_norm': 10.095635414123535, 'learning_rate': 1e-05, 'epoch': 8.03}
{'loss': 0.8206, 'grad_norm': 2.7130038738250732, 'learning_rate': 1e-05, 'epoch': 8.05}
{'loss': 0.784, 'grad_norm': 7.436645030975342, 'learning_rate': 1e-05, 'epoch': 8.08}
{'loss': 0.8087, 'grad_norm': 8.624720573425293, 'learning_rate': 1e-05, 'epoch': 8.1}
{'loss': 0.8042, 'grad_norm': 10.73009204864502, 'learning_rate': 1e-05, 'epoch': 8.13}
{'loss': 0.8785, 'grad_norm': 4.050257205963135, 'learning_rate': 1e-05, 'epoch': 8.15}
{'loss': 0.8781, 'grad_norm': 10.597979545593262, 'learning_rate': 1e-05, 'epoch': 8.18}
{'loss': 0.7944, 'grad_norm': 4.716248989105225, 'learning_rate': 1e-05, 'epoch': 8.2}
{'loss': 0.7671, 'grad_norm': 12.289054870605469, 'learning_rate': 1e-05, 'epoch': 8.23}
{'loss': 0.8521, 'grad_norm': 2.185460090637207, 'learning_rate': 1e-05, 'epoch': 8.25}
{'loss': 0.8093, 'grad_norm': 6.209237098693848, 'learning_rate': 1e-05, 'epoch': 8.28}
{'loss': 0.8858, 'grad_norm': 10.194343566894531, 'learning_rate': 1e-05, 'epoch': 8.3}
{'loss': 0.8117, 'grad_norm': 2.337339401245117, 'learning_rate': 1e-05, 'epoch': 8.33}
{'loss': 0.7834, 'grad_norm': 12.225750923156738, 'learning_rate': 1e-05, 'epoch': 8.35}
{'loss': 0.8785, 'grad_norm': 6.261240005493164, 'learning_rate': 1e-05, 'epoch': 8.38}
{'loss': 0.8576, 'grad_norm': 9.061027526855469, 'learning_rate': 1e-05, 'epoch': 8.4}
{'loss': 0.8241, 'grad_norm': 10.910572052001953, 'learning_rate': 1e-05, 'epoch': 8.43}
{'loss': 0.8571, 'grad_norm': 21.107397079467773, 'learning_rate': 1e-05, 'epoch': 8.45}
{'loss': 0.8608, 'grad_norm': 7.229866981506348, 'learning_rate': 1e-05, 'epoch': 8.48}
{'loss': 0.801, 'grad_norm': 7.323206901550293, 'learning_rate': 1e-05, 'epoch': 8.5}
{'loss': 0.807, 'grad_norm': 27.841571807861328, 'learning_rate': 1e-05, 'epoch': 8.53}
{'loss': 0.8632, 'grad_norm': 9.046533584594727, 'learning_rate': 1e-05, 'epoch': 8.55}
{'loss': 0.7824, 'grad_norm': 4.833434104919434, 'learning_rate': 1e-05, 'epoch': 8.58}
{'loss': 0.8208, 'grad_norm': 12.16146469116211, 'learning_rate': 1e-05, 'epoch': 8.6}
{'loss': 0.8513, 'grad_norm': 4.067899227142334, 'learning_rate': 1e-05, 'epoch': 8.63}
{'loss': 0.8445, 'grad_norm': 4.680266857147217, 'learning_rate': 1e-05, 'epoch': 8.65}
{'loss': 0.7898, 'grad_norm': 3.7625091075897217, 'learning_rate': 1e-05, 'epoch': 8.68}
{'loss': 0.784, 'grad_norm': 4.975710391998291, 'learning_rate': 1e-05, 'epoch': 8.7}
{'loss': 0.8326, 'grad_norm': 5.533115386962891, 'learning_rate': 1e-05, 'epoch': 8.73}
{'loss': 0.8192, 'grad_norm': 10.429085731506348, 'learning_rate': 1e-05, 'epoch': 8.75}
{'loss': 0.861, 'grad_norm': 5.0424580574035645, 'learning_rate': 1e-05, 'epoch': 8.78}
{'loss': 0.9042, 'grad_norm': 8.58197021484375, 'learning_rate': 1e-05, 'epoch': 8.8}
{'loss': 0.8411, 'grad_norm': 5.373364448547363, 'learning_rate': 1e-05, 'epoch': 8.83}
{'loss': 0.8619, 'grad_norm': 12.05793285369873, 'learning_rate': 1e-05, 'epoch': 8.85}
{'loss': 0.8866, 'grad_norm': 7.686501502990723, 'learning_rate': 1e-05, 'epoch': 8.88}
{'loss': 0.8575, 'grad_norm': 8.509515762329102, 'learning_rate': 1e-05, 'epoch': 8.9}
{'loss': 0.8749, 'grad_norm': 4.61025333404541, 'learning_rate': 1e-05, 'epoch': 8.93}
{'loss': 0.7869, 'grad_norm': 3.7250518798828125, 'learning_rate': 1e-05, 'epoch': 8.95}
{'loss': 0.798, 'grad_norm': 7.210013389587402, 'learning_rate': 1e-05, 'epoch': 8.98}
{'eval_loss': 0.671745777130127, 'eval_wer': 0.3279269202087994, 'eval_runtime': 1494.7169, 'eval_samples_per_second': 5.352, 'eval_steps_per_second': 5.352, 'epoch': 9.0}
{'loss': 0.7847, 'grad_norm': 9.657892227172852, 'learning_rate': 1e-05, 'epoch': 9.0}
{'loss': 0.804, 'grad_norm': 5.2089738845825195, 'learning_rate': 1e-05, 'epoch': 9.03}
{'loss': 0.8131, 'grad_norm': 15.105902671813965, 'learning_rate': 1e-05, 'epoch': 9.05}
{'loss': 0.8475, 'grad_norm': 6.8529863357543945, 'learning_rate': 1e-05, 'epoch': 9.08}
{'loss': 0.8254, 'grad_norm': 4.378721237182617, 'learning_rate': 1e-05, 'epoch': 9.1}
{'loss': 0.8196, 'grad_norm': 39.48478317260742, 'learning_rate': 1e-05, 'epoch': 9.13}
{'loss': 0.7835, 'grad_norm': 5.743866443634033, 'learning_rate': 1e-05, 'epoch': 9.15}
{'loss': 0.9201, 'grad_norm': 3.411182165145874, 'learning_rate': 1e-05, 'epoch': 9.18}
{'loss': 0.7483, 'grad_norm': 4.879155158996582, 'learning_rate': 1e-05, 'epoch': 9.2}
{'loss': 0.7306, 'grad_norm': 6.520720481872559, 'learning_rate': 1e-05, 'epoch': 9.23}
{'loss': 0.8095, 'grad_norm': 8.615391731262207, 'learning_rate': 1e-05, 'epoch': 9.25}
{'loss': 0.7804, 'grad_norm': 5.239351749420166, 'learning_rate': 1e-05, 'epoch': 9.28}
{'loss': 0.7997, 'grad_norm': 14.511232376098633, 'learning_rate': 1e-05, 'epoch': 9.3}
{'loss': 0.8579, 'grad_norm': 7.200083255767822, 'learning_rate': 1e-05, 'epoch': 9.33}
{'loss': 0.9032, 'grad_norm': 10.623608589172363, 'learning_rate': 1e-05, 'epoch': 9.35}
{'loss': 0.7748, 'grad_norm': 4.083415985107422, 'learning_rate': 1e-05, 'epoch': 9.38}
{'loss': 0.8096, 'grad_norm': 9.735021591186523, 'learning_rate': 1e-05, 'epoch': 9.4}
{'loss': 0.7915, 'grad_norm': 6.673443794250488, 'learning_rate': 1e-05, 'epoch': 9.43}
{'loss': 0.8102, 'grad_norm': 2.8422327041625977, 'learning_rate': 1e-05, 'epoch': 9.45}
{'loss': 0.7903, 'grad_norm': 3.293914556503296, 'learning_rate': 1e-05, 'epoch': 9.48}
{'loss': 0.7783, 'grad_norm': 8.584202766418457, 'learning_rate': 1e-05, 'epoch': 9.5}
{'loss': 0.8225, 'grad_norm': 4.936783313751221, 'learning_rate': 1e-05, 'epoch': 9.53}
{'loss': 0.8857, 'grad_norm': 11.149934768676758, 'learning_rate': 1e-05, 'epoch': 9.55}
{'loss': 0.8342, 'grad_norm': 4.557994365692139, 'learning_rate': 1e-05, 'epoch': 9.58}
{'loss': 0.7987, 'grad_norm': 5.041965007781982, 'learning_rate': 1e-05, 'epoch': 9.6}
{'loss': 0.8336, 'grad_norm': 6.5187788009643555, 'learning_rate': 1e-05, 'epoch': 9.63}
{'loss': 0.8014, 'grad_norm': 8.176554679870605, 'learning_rate': 1e-05, 'epoch': 9.65}
{'loss': 0.8392, 'grad_norm': 7.97355318069458, 'learning_rate': 1e-05, 'epoch': 9.68}
{'loss': 0.8396, 'grad_norm': 4.743381500244141, 'learning_rate': 1e-05, 'epoch': 9.7}
{'loss': 0.8693, 'grad_norm': 9.906792640686035, 'learning_rate': 1e-05, 'epoch': 9.73}
{'loss': 0.8538, 'grad_norm': 6.145262718200684, 'learning_rate': 1e-05, 'epoch': 9.75}
{'loss': 0.8256, 'grad_norm': 9.735427856445312, 'learning_rate': 1e-05, 'epoch': 9.78}
{'loss': 0.8108, 'grad_norm': 5.8489179611206055, 'learning_rate': 1e-05, 'epoch': 9.8}
{'loss': 0.8351, 'grad_norm': 36.3984260559082, 'learning_rate': 1e-05, 'epoch': 9.83}
{'loss': 0.8707, 'grad_norm': 9.218544960021973, 'learning_rate': 1e-05, 'epoch': 9.85}
{'loss': 0.8354, 'grad_norm': 4.3603901863098145, 'learning_rate': 1e-05, 'epoch': 9.88}
{'loss': 0.8164, 'grad_norm': 8.697582244873047, 'learning_rate': 1e-05, 'epoch': 9.9}
{'loss': 0.8255, 'grad_norm': 8.761919975280762, 'learning_rate': 1e-05, 'epoch': 9.93}
{'loss': 0.8141, 'grad_norm': 38.93204879760742, 'learning_rate': 1e-05, 'epoch': 9.95}
{'loss': 0.8214, 'grad_norm': 6.141056537628174, 'learning_rate': 1e-05, 'epoch': 9.98}
{'eval_loss': 0.6768790483474731, 'eval_wer': 0.3266086076488761, 'eval_runtime': 1492.7617, 'eval_samples_per_second': 5.359, 'eval_steps_per_second': 5.359, 'epoch': 10.0}
{'train_runtime': 18144.2548, 'train_samples_per_second': 17.632, 'train_steps_per_second': 2.204, 'train_loss': 0.9196739047966948, 'epoch': 10.0}
[ASR][Trainer Eval] {'eval_loss': 0.6768790483474731, 'eval_wer': 0.3266086076488761, 'eval_runtime': 1506.4629, 'eval_samples_per_second': 5.31, 'eval_steps_per_second': 5.31, 'epoch': 10.0}
[SER] Skipped (phase != 'all'/'ser').
w23g0007:3293129:3293956 [0] NCCL INFO [Service thread] Connection closed by localRank 0
w23g0007:3293129:3610002 [0] NCCL INFO comm 0x5610a9b09420 rank 0 nranks 1 cudaDev 0 busId ad000 - Abort COMPLETE
[TRAIN][SER] Starting SER phase ...
[Setup] Using device: cuda
[Setup] no_cuda flag set to: False
[ASR] Skipped (phase != 'all'/'asr').
[SER] Loading model + extractor‚Ä¶
[SER] Starting from pretrained: models/pretrained/en
[SER] truncating to 102719 frames (~6.42s)
[SER] class counts: {4: 6792, 7: 1408, 3: 5556, 5: 6384, 0: 6044, 2: 4140, 1: 3500, 6: 768}
[SER] class weights: [0.7154202461242676, 1.2354285717010498, 1.0444444417953491, 0.7782577276229858, 0.6366313099861145, 0.677318274974823, 5.630208492279053, 3.0710227489471436]
[SER] Sanity loss (1 batch): 2.0881845951080322
[SER] Starting training with HuggingFace Trainer‚Ä¶
w23g0007:3610149:3610149 [0] NCCL INFO Bootstrap : Using ib0:134.61.46.236<0>
w23g0007:3610149:3610149 [0] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation
w23g0007:3610149:3610149 [0] NCCL INFO cudaDriverVersion 12080
NCCL version 2.20.5+cuda12.4
w23g0007:3610149:3622249 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib0:134.61.46.236<0>
w23g0007:3610149:3622249 [0] NCCL INFO Using non-device net plugin version 0
w23g0007:3610149:3622249 [0] NCCL INFO Using network IB
w23g0007:3610149:3622249 [0] NCCL INFO DMA-BUF is available on GPU device 0
w23g0007:3610149:3622249 [0] NCCL INFO comm 0x5564e28f80e0 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId ad000 commId 0x5c2ee2ed18be9908 - Init START
w23g0007:3610149:3622249 [0] NCCL INFO Setting affinity for GPU 0 to f000,00000000,00000000
w23g0007:3610149:3622249 [0] NCCL INFO comm 0x5564e28f80e0 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
w23g0007:3610149:3622249 [0] NCCL INFO Channel 00/32 :    0
w23g0007:3610149:3622249 [0] NCCL INFO Channel 01/32 :    0
w23g0007:3610149:3622249 [0] NCCL INFO Channel 02/32 :    0
w23g0007:3610149:3622249 [0] NCCL INFO Channel 03/32 :    0
w23g0007:3610149:3622249 [0] NCCL INFO Channel 04/32 :    0
w23g0007:3610149:3622249 [0] NCCL INFO Channel 05/32 :    0
w23g0007:3610149:3622249 [0] NCCL INFO Channel 06/32 :    0
w23g0007:3610149:3622249 [0] NCCL INFO Channel 07/32 :    0
w23g0007:3610149:3622249 [0] NCCL INFO Channel 08/32 :    0
w23g0007:3610149:3622249 [0] NCCL INFO Channel 09/32 :    0
w23g0007:3610149:3622249 [0] NCCL INFO Channel 10/32 :    0
w23g0007:3610149:3622249 [0] NCCL INFO Channel 11/32 :    0
w23g0007:3610149:3622249 [0] NCCL INFO Channel 12/32 :    0
w23g0007:3610149:3622249 [0] NCCL INFO Channel 13/32 :    0
w23g0007:3610149:3622249 [0] NCCL INFO Channel 14/32 :    0
w23g0007:3610149:3622249 [0] NCCL INFO Channel 15/32 :    0
w23g0007:3610149:3622249 [0] NCCL INFO Channel 16/32 :    0
w23g0007:3610149:3622249 [0] NCCL INFO Channel 17/32 :    0
w23g0007:3610149:3622249 [0] NCCL INFO Channel 18/32 :    0
w23g0007:3610149:3622249 [0] NCCL INFO Channel 19/32 :    0
w23g0007:3610149:3622249 [0] NCCL INFO Channel 20/32 :    0
w23g0007:3610149:3622249 [0] NCCL INFO Channel 21/32 :    0
w23g0007:3610149:3622249 [0] NCCL INFO Channel 22/32 :    0
w23g0007:3610149:3622249 [0] NCCL INFO Channel 23/32 :    0
w23g0007:3610149:3622249 [0] NCCL INFO Channel 24/32 :    0
w23g0007:3610149:3622249 [0] NCCL INFO Channel 25/32 :    0
w23g0007:3610149:3622249 [0] NCCL INFO Channel 26/32 :    0
w23g0007:3610149:3622249 [0] NCCL INFO Channel 27/32 :    0
w23g0007:3610149:3622249 [0] NCCL INFO Channel 28/32 :    0
w23g0007:3610149:3622249 [0] NCCL INFO Channel 29/32 :    0
w23g0007:3610149:3622249 [0] NCCL INFO Channel 30/32 :    0
w23g0007:3610149:3622249 [0] NCCL INFO Channel 31/32 :    0
w23g0007:3610149:3622249 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
w23g0007:3610149:3622249 [0] NCCL INFO P2P Chunksize set to 131072
w23g0007:3610149:3622249 [0] NCCL INFO Connected all rings
w23g0007:3610149:3622249 [0] NCCL INFO Connected all trees
w23g0007:3610149:3622249 [0] NCCL INFO 32 coll channels, 0 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
w23g0007:3610149:3622249 [0] NCCL INFO comm 0x5564e28f80e0 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId ad000 commId 0x5c2ee2ed18be9908 - Init COMPLETE
{'loss': 2.0818, 'grad_norm': 0.4119419753551483, 'learning_rate': 9.942708333333334e-06, 'epoch': 0.06}
{'loss': 2.0835, 'grad_norm': 0.23156888782978058, 'learning_rate': 9.884837962962964e-06, 'epoch': 0.12}
{'loss': 2.0823, 'grad_norm': 0.2504578232765198, 'learning_rate': 9.826967592592594e-06, 'epoch': 0.17}
{'loss': 2.0844, 'grad_norm': 0.31943726539611816, 'learning_rate': 9.769097222222224e-06, 'epoch': 0.23}
{'loss': 2.0817, 'grad_norm': 0.3901475667953491, 'learning_rate': 9.711226851851852e-06, 'epoch': 0.29}
{'loss': 2.0777, 'grad_norm': 0.3976721167564392, 'learning_rate': 9.653356481481482e-06, 'epoch': 0.35}
{'loss': 2.0789, 'grad_norm': 0.48948657512664795, 'learning_rate': 9.595486111111112e-06, 'epoch': 0.41}
{'loss': 2.076, 'grad_norm': 0.8275313377380371, 'learning_rate': 9.53761574074074e-06, 'epoch': 0.46}
{'loss': 2.0741, 'grad_norm': 1.693951964378357, 'learning_rate': 9.479745370370372e-06, 'epoch': 0.52}
{'loss': 2.0709, 'grad_norm': 0.8344434499740601, 'learning_rate': 9.421875e-06, 'epoch': 0.58}
{'loss': 2.0656, 'grad_norm': 0.7825599908828735, 'learning_rate': 9.36400462962963e-06, 'epoch': 0.64}
{'loss': 2.0707, 'grad_norm': 1.108103632926941, 'learning_rate': 9.30613425925926e-06, 'epoch': 0.69}
{'loss': 2.0687, 'grad_norm': 0.7024454474449158, 'learning_rate': 9.24826388888889e-06, 'epoch': 0.75}
{'loss': 2.0572, 'grad_norm': 0.9347624778747559, 'learning_rate': 9.190393518518519e-06, 'epoch': 0.81}
{'loss': 2.0678, 'grad_norm': 2.7940001487731934, 'learning_rate': 9.132523148148149e-06, 'epoch': 0.87}
{'loss': 2.0628, 'grad_norm': 0.8837460875511169, 'learning_rate': 9.074652777777779e-06, 'epoch': 0.93}
{'loss': 2.0604, 'grad_norm': 1.356898546218872, 'learning_rate': 9.016782407407408e-06, 'epoch': 0.98}
w23g0007:3610149:3622254 [0] NCCL INFO [Service thread] Connection closed by localRank 0
w23g0007:3610149:3624492 [0] NCCL INFO comm 0x5564e28f80e0 rank 0 nranks 1 cudaDev 0 busId ad000 - Abort COMPLETE
