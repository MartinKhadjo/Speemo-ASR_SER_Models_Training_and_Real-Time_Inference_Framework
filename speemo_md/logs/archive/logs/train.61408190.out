[DIST] MASTER_ADDR=w23g0010 MASTER_PORT=29500 NNODES=1 GPUS_PER_NODE=1
[PRE] Skipping all preprocessing (skip_preprocessing=on or all per-step toggles are 'on')
[TRAIN][ASR] Starting ASR phase ...
[Setup] Using device: cuda
[Setup] no_cuda flag set to: False
[ASR] Loading model + processor‚Ä¶
[ASR] Starting from pretrained: models/pretrained/en
trainable params: 589,824 || all params: 94,986,144 || trainable%: 0.6210
[ASR] Trainable parameters: 589824 / 94986144
üõ†Ô∏è  Debug collator output shapes: {'input_values': torch.Size([4, 75264]), 'attention_mask': torch.Size([4, 75264]), 'labels': torch.Size([4, 93])}
[ASR] Starting training with HuggingFace Trainer‚Ä¶
w23g0010:1842118:1842118 [0] NCCL INFO Bootstrap : Using ib0:134.61.46.239<0>
w23g0010:1842118:1842118 [0] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation
w23g0010:1842118:1842118 [0] NCCL INFO cudaDriverVersion 12080
NCCL version 2.20.5+cuda12.4
w23g0010:1842118:1842976 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib0:134.61.46.239<0>
w23g0010:1842118:1842976 [0] NCCL INFO Using non-device net plugin version 0
w23g0010:1842118:1842976 [0] NCCL INFO Using network IB
w23g0010:1842118:1842976 [0] NCCL INFO DMA-BUF is available on GPU device 0
w23g0010:1842118:1842976 [0] NCCL INFO comm 0x55b6b8ec9c40 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 9d000 commId 0xf808072667ccc82a - Init START
w23g0010:1842118:1842976 [0] NCCL INFO comm 0x55b6b8ec9c40 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
w23g0010:1842118:1842976 [0] NCCL INFO Channel 00/32 :    0
w23g0010:1842118:1842976 [0] NCCL INFO Channel 01/32 :    0
w23g0010:1842118:1842976 [0] NCCL INFO Channel 02/32 :    0
w23g0010:1842118:1842976 [0] NCCL INFO Channel 03/32 :    0
w23g0010:1842118:1842976 [0] NCCL INFO Channel 04/32 :    0
w23g0010:1842118:1842976 [0] NCCL INFO Channel 05/32 :    0
w23g0010:1842118:1842976 [0] NCCL INFO Channel 06/32 :    0
w23g0010:1842118:1842976 [0] NCCL INFO Channel 07/32 :    0
w23g0010:1842118:1842976 [0] NCCL INFO Channel 08/32 :    0
w23g0010:1842118:1842976 [0] NCCL INFO Channel 09/32 :    0
w23g0010:1842118:1842976 [0] NCCL INFO Channel 10/32 :    0
w23g0010:1842118:1842976 [0] NCCL INFO Channel 11/32 :    0
w23g0010:1842118:1842976 [0] NCCL INFO Channel 12/32 :    0
w23g0010:1842118:1842976 [0] NCCL INFO Channel 13/32 :    0
w23g0010:1842118:1842976 [0] NCCL INFO Channel 14/32 :    0
w23g0010:1842118:1842976 [0] NCCL INFO Channel 15/32 :    0
w23g0010:1842118:1842976 [0] NCCL INFO Channel 16/32 :    0
w23g0010:1842118:1842976 [0] NCCL INFO Channel 17/32 :    0
w23g0010:1842118:1842976 [0] NCCL INFO Channel 18/32 :    0
w23g0010:1842118:1842976 [0] NCCL INFO Channel 19/32 :    0
w23g0010:1842118:1842976 [0] NCCL INFO Channel 20/32 :    0
w23g0010:1842118:1842976 [0] NCCL INFO Channel 21/32 :    0
w23g0010:1842118:1842976 [0] NCCL INFO Channel 22/32 :    0
w23g0010:1842118:1842976 [0] NCCL INFO Channel 23/32 :    0
w23g0010:1842118:1842976 [0] NCCL INFO Channel 24/32 :    0
w23g0010:1842118:1842976 [0] NCCL INFO Channel 25/32 :    0
w23g0010:1842118:1842976 [0] NCCL INFO Channel 26/32 :    0
w23g0010:1842118:1842976 [0] NCCL INFO Channel 27/32 :    0
w23g0010:1842118:1842976 [0] NCCL INFO Channel 28/32 :    0
w23g0010:1842118:1842976 [0] NCCL INFO Channel 29/32 :    0
w23g0010:1842118:1842976 [0] NCCL INFO Channel 30/32 :    0
w23g0010:1842118:1842976 [0] NCCL INFO Channel 31/32 :    0
w23g0010:1842118:1842976 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
w23g0010:1842118:1842976 [0] NCCL INFO P2P Chunksize set to 131072
w23g0010:1842118:1842976 [0] NCCL INFO Connected all rings
w23g0010:1842118:1842976 [0] NCCL INFO Connected all trees
w23g0010:1842118:1842976 [0] NCCL INFO 32 coll channels, 0 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
w23g0010:1842118:1842976 [0] NCCL INFO comm 0x55b6b8ec9c40 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 9d000 commId 0xf808072667ccc82a - Init COMPLETE
{'loss': 2.1461, 'grad_norm': 3.2200586795806885, 'learning_rate': 0.0, 'epoch': 0.0}
{'loss': 1.6774, 'grad_norm': 4.778740882873535, 'learning_rate': 1.2125e-06, 'epoch': 0.03}
{'loss': 1.6881, 'grad_norm': 4.311569690704346, 'learning_rate': 2.4500000000000003e-06, 'epoch': 0.05}
{'loss': 1.614, 'grad_norm': 2.4944779872894287, 'learning_rate': 3.7e-06, 'epoch': 0.08}
{'loss': 1.4859, 'grad_norm': 2.2555787563323975, 'learning_rate': 4.95e-06, 'epoch': 0.1}
{'loss': 1.3793, 'grad_norm': 2.1826329231262207, 'learning_rate': 6.200000000000001e-06, 'epoch': 0.13}
{'loss': 1.3106, 'grad_norm': 4.032018661499023, 'learning_rate': 7.450000000000001e-06, 'epoch': 0.15}
{'loss': 1.2937, 'grad_norm': 7.3900322914123535, 'learning_rate': 8.700000000000001e-06, 'epoch': 0.18}
{'loss': 1.3227, 'grad_norm': 2.437304973602295, 'learning_rate': 9.950000000000001e-06, 'epoch': 0.2}
{'loss': 1.2678, 'grad_norm': 2.3736886978149414, 'learning_rate': 1e-05, 'epoch': 0.23}
{'loss': 1.2374, 'grad_norm': 6.182939052581787, 'learning_rate': 1e-05, 'epoch': 0.25}
{'loss': 1.2704, 'grad_norm': 4.173415660858154, 'learning_rate': 1e-05, 'epoch': 0.28}
{'loss': 1.1639, 'grad_norm': 4.388641834259033, 'learning_rate': 1e-05, 'epoch': 0.3}
{'loss': 1.1636, 'grad_norm': 12.902645111083984, 'learning_rate': 1e-05, 'epoch': 0.33}
{'loss': 1.1291, 'grad_norm': 3.8081722259521484, 'learning_rate': 1e-05, 'epoch': 0.35}
{'loss': 1.0969, 'grad_norm': 3.1339752674102783, 'learning_rate': 1e-05, 'epoch': 0.38}
{'loss': 1.1007, 'grad_norm': 2.782803773880005, 'learning_rate': 1e-05, 'epoch': 0.4}
{'loss': 0.9702, 'grad_norm': 31.918087005615234, 'learning_rate': 1e-05, 'epoch': 0.43}
{'loss': 0.9921, 'grad_norm': 4.752487659454346, 'learning_rate': 1e-05, 'epoch': 0.45}
{'loss': 1.051, 'grad_norm': 12.126567840576172, 'learning_rate': 1e-05, 'epoch': 0.48}
{'loss': 1.0655, 'grad_norm': 3.12737774848938, 'learning_rate': 1e-05, 'epoch': 0.5}
{'loss': 0.9519, 'grad_norm': 5.641994476318359, 'learning_rate': 1e-05, 'epoch': 0.53}
{'loss': 0.9992, 'grad_norm': 2.208554983139038, 'learning_rate': 1e-05, 'epoch': 0.55}
{'loss': 0.9431, 'grad_norm': 20.895488739013672, 'learning_rate': 1e-05, 'epoch': 0.58}
{'loss': 1.022, 'grad_norm': 7.244294166564941, 'learning_rate': 1e-05, 'epoch': 0.6}
{'loss': 0.9789, 'grad_norm': 4.528717994689941, 'learning_rate': 1e-05, 'epoch': 0.63}
{'loss': 1.0245, 'grad_norm': 3.2596707344055176, 'learning_rate': 1e-05, 'epoch': 0.65}
{'loss': 1.004, 'grad_norm': 6.296703815460205, 'learning_rate': 1e-05, 'epoch': 0.68}
{'loss': 1.0325, 'grad_norm': 8.282931327819824, 'learning_rate': 1e-05, 'epoch': 0.7}
{'loss': 1.0256, 'grad_norm': 7.625000476837158, 'learning_rate': 1e-05, 'epoch': 0.73}
{'loss': 0.9682, 'grad_norm': 12.284621238708496, 'learning_rate': 1e-05, 'epoch': 0.75}
{'loss': 0.9678, 'grad_norm': 8.50190544128418, 'learning_rate': 1e-05, 'epoch': 0.78}
{'loss': 0.9598, 'grad_norm': 2.261909008026123, 'learning_rate': 1e-05, 'epoch': 0.8}
{'loss': 1.0529, 'grad_norm': 6.712103843688965, 'learning_rate': 1e-05, 'epoch': 0.83}
{'loss': 1.0095, 'grad_norm': 4.451291084289551, 'learning_rate': 1e-05, 'epoch': 0.85}
{'loss': 0.9457, 'grad_norm': 4.112574100494385, 'learning_rate': 1e-05, 'epoch': 0.88}
{'loss': 0.9846, 'grad_norm': 4.998129367828369, 'learning_rate': 1e-05, 'epoch': 0.9}
{'loss': 0.94, 'grad_norm': 12.802362442016602, 'learning_rate': 1e-05, 'epoch': 0.93}
{'loss': 1.0283, 'grad_norm': 4.3026533126831055, 'learning_rate': 1e-05, 'epoch': 0.95}
{'loss': 0.8823, 'grad_norm': 20.031761169433594, 'learning_rate': 1e-05, 'epoch': 0.98}
{'eval_loss': 0.7638464570045471, 'eval_wer': 0.3816714605305209, 'eval_runtime': 1488.4192, 'eval_samples_per_second': 5.375, 'eval_steps_per_second': 5.375, 'epoch': 1.0}
{'loss': 0.9037, 'grad_norm': 6.195712089538574, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 0.9682, 'grad_norm': 10.195097923278809, 'learning_rate': 1e-05, 'epoch': 1.03}
{'loss': 0.8167, 'grad_norm': 7.050370216369629, 'learning_rate': 1e-05, 'epoch': 1.05}
{'loss': 0.9607, 'grad_norm': 5.796463966369629, 'learning_rate': 1e-05, 'epoch': 1.08}
{'loss': 0.9478, 'grad_norm': 2.883117198944092, 'learning_rate': 1e-05, 'epoch': 1.1}
{'loss': 0.9041, 'grad_norm': 4.7887349128723145, 'learning_rate': 1e-05, 'epoch': 1.13}
{'loss': 0.9588, 'grad_norm': 7.764673233032227, 'learning_rate': 1e-05, 'epoch': 1.15}
{'loss': 0.8681, 'grad_norm': 3.132967472076416, 'learning_rate': 1e-05, 'epoch': 1.18}
{'loss': 0.9149, 'grad_norm': 11.218497276306152, 'learning_rate': 1e-05, 'epoch': 1.2}
{'loss': 0.9291, 'grad_norm': 4.182774066925049, 'learning_rate': 1e-05, 'epoch': 1.23}
{'loss': 0.8667, 'grad_norm': 7.465905666351318, 'learning_rate': 1e-05, 'epoch': 1.25}
{'loss': 0.9205, 'grad_norm': 4.799648761749268, 'learning_rate': 1e-05, 'epoch': 1.28}
{'loss': 0.8546, 'grad_norm': 7.611217021942139, 'learning_rate': 1e-05, 'epoch': 1.3}
{'loss': 0.946, 'grad_norm': 15.645315170288086, 'learning_rate': 1e-05, 'epoch': 1.33}
{'loss': 0.8429, 'grad_norm': 3.510366916656494, 'learning_rate': 1e-05, 'epoch': 1.35}
{'loss': 0.909, 'grad_norm': 23.376916885375977, 'learning_rate': 1e-05, 'epoch': 1.38}
{'loss': 0.9344, 'grad_norm': 21.838647842407227, 'learning_rate': 1e-05, 'epoch': 1.4}
{'loss': 0.8819, 'grad_norm': 2.950946807861328, 'learning_rate': 1e-05, 'epoch': 1.43}
{'loss': 0.9205, 'grad_norm': 4.671786308288574, 'learning_rate': 1e-05, 'epoch': 1.45}
{'loss': 0.9507, 'grad_norm': 2.729905366897583, 'learning_rate': 1e-05, 'epoch': 1.48}
{'loss': 0.8941, 'grad_norm': 12.835104942321777, 'learning_rate': 1e-05, 'epoch': 1.5}
{'loss': 0.9077, 'grad_norm': 3.5378994941711426, 'learning_rate': 1e-05, 'epoch': 1.53}
{'loss': 0.8279, 'grad_norm': 4.641030311584473, 'learning_rate': 1e-05, 'epoch': 1.55}
{'loss': 1.2377, 'grad_norm': 7.10990047454834, 'learning_rate': 1e-05, 'epoch': 1.58}
{'loss': 0.9004, 'grad_norm': 5.2769694328308105, 'learning_rate': 1e-05, 'epoch': 1.6}
{'loss': 0.8183, 'grad_norm': 6.177350997924805, 'learning_rate': 1e-05, 'epoch': 1.63}
{'loss': 0.9356, 'grad_norm': 7.630335330963135, 'learning_rate': 1e-05, 'epoch': 1.65}
{'loss': 0.9298, 'grad_norm': 7.793472766876221, 'learning_rate': 1e-05, 'epoch': 1.68}
{'loss': 0.8767, 'grad_norm': 8.305113792419434, 'learning_rate': 1e-05, 'epoch': 1.7}
{'loss': 0.9612, 'grad_norm': 5.849898815155029, 'learning_rate': 1e-05, 'epoch': 1.73}
{'loss': 0.91, 'grad_norm': 2.212400436401367, 'learning_rate': 1e-05, 'epoch': 1.75}
{'loss': 0.9477, 'grad_norm': 12.832094192504883, 'learning_rate': 1e-05, 'epoch': 1.78}
{'loss': 0.8469, 'grad_norm': 9.291036605834961, 'learning_rate': 1e-05, 'epoch': 1.8}
{'loss': 0.8744, 'grad_norm': 11.681207656860352, 'learning_rate': 1e-05, 'epoch': 1.83}
{'loss': 0.9788, 'grad_norm': 5.233709812164307, 'learning_rate': 1e-05, 'epoch': 1.85}
{'loss': 0.8231, 'grad_norm': 7.268716335296631, 'learning_rate': 1e-05, 'epoch': 1.88}
{'loss': 1.0021, 'grad_norm': 2.888918161392212, 'learning_rate': 1e-05, 'epoch': 1.9}
{'loss': 0.9225, 'grad_norm': 3.677511215209961, 'learning_rate': 1e-05, 'epoch': 1.93}
{'loss': 0.9131, 'grad_norm': 10.90190601348877, 'learning_rate': 1e-05, 'epoch': 1.95}
{'loss': 0.8644, 'grad_norm': 16.974620819091797, 'learning_rate': 1e-05, 'epoch': 1.98}
{'eval_loss': 0.7161917090415955, 'eval_wer': 0.3494194098220944, 'eval_runtime': 1480.1178, 'eval_samples_per_second': 5.405, 'eval_steps_per_second': 5.405, 'epoch': 2.0}
{'train_runtime': 3859.6362, 'train_samples_per_second': 16.578, 'train_steps_per_second': 2.072, 'train_loss': 1.0180236022750806, 'epoch': 2.0}
[ASR][Trainer Eval] {'eval_loss': 0.7161917090415955, 'eval_wer': 0.3494194098220944, 'eval_runtime': 1504.6359, 'eval_samples_per_second': 5.317, 'eval_steps_per_second': 5.317, 'epoch': 2.0}
[SER] Skipped (phase != 'all'/'ser').
w23g0010:1842118:1842979 [0] NCCL INFO [Service thread] Connection closed by localRank 0
w23g0010:1842118:1939468 [0] NCCL INFO comm 0x55b6b8ec9c40 rank 0 nranks 1 cudaDev 0 busId 9d000 - Abort COMPLETE
[TRAIN][SER] Starting SER phase ...
[Setup] Using device: cuda
[Setup] no_cuda flag set to: False
[ASR] Skipped (phase != 'all'/'asr').
[SER] Loading model + extractor‚Ä¶
[SER] Starting from pretrained: models/pretrained/en
trainable params: 1,327,104 || all params: 96,295,560 || trainable%: 1.3782
[SER] Trainable parameters: 1327104 / 96295560
[SER] tensors requiring grad: 144
[SER] truncating to 102719 frames (~6.42s)
[SER] class counts: {4: 6792, 7: 1408, 3: 5556, 5: 6384, 0: 6044, 2: 4140, 1: 3500, 6: 768}
[SER] class weights: [0.7154202461242676, 1.2354285717010498, 1.0444444417953491, 0.7782577276229858, 0.6366313099861145, 0.677318274974823, 5.630208492279053, 3.0710227489471436]
[SER] Sanity loss (1 batch): 2.067472219467163
[SER] Starting training with HuggingFace Trainer‚Ä¶
w23g0010:1939604:1939604 [0] NCCL INFO Bootstrap : Using ib0:134.61.46.239<0>
w23g0010:1939604:1939604 [0] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation
w23g0010:1939604:1939604 [0] NCCL INFO cudaDriverVersion 12080
NCCL version 2.20.5+cuda12.4
w23g0010:1939604:1951411 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib0:134.61.46.239<0>
w23g0010:1939604:1951411 [0] NCCL INFO Using non-device net plugin version 0
w23g0010:1939604:1951411 [0] NCCL INFO Using network IB
w23g0010:1939604:1951411 [0] NCCL INFO DMA-BUF is available on GPU device 0
w23g0010:1939604:1951411 [0] NCCL INFO comm 0x55cca7fce080 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 9d000 commId 0xb8f1e821b63b01dd - Init START
w23g0010:1939604:1951411 [0] NCCL INFO comm 0x55cca7fce080 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
w23g0010:1939604:1951411 [0] NCCL INFO Channel 00/32 :    0
w23g0010:1939604:1951411 [0] NCCL INFO Channel 01/32 :    0
w23g0010:1939604:1951411 [0] NCCL INFO Channel 02/32 :    0
w23g0010:1939604:1951411 [0] NCCL INFO Channel 03/32 :    0
w23g0010:1939604:1951411 [0] NCCL INFO Channel 04/32 :    0
w23g0010:1939604:1951411 [0] NCCL INFO Channel 05/32 :    0
w23g0010:1939604:1951411 [0] NCCL INFO Channel 06/32 :    0
w23g0010:1939604:1951411 [0] NCCL INFO Channel 07/32 :    0
w23g0010:1939604:1951411 [0] NCCL INFO Channel 08/32 :    0
w23g0010:1939604:1951411 [0] NCCL INFO Channel 09/32 :    0
w23g0010:1939604:1951411 [0] NCCL INFO Channel 10/32 :    0
w23g0010:1939604:1951411 [0] NCCL INFO Channel 11/32 :    0
w23g0010:1939604:1951411 [0] NCCL INFO Channel 12/32 :    0
w23g0010:1939604:1951411 [0] NCCL INFO Channel 13/32 :    0
w23g0010:1939604:1951411 [0] NCCL INFO Channel 14/32 :    0
w23g0010:1939604:1951411 [0] NCCL INFO Channel 15/32 :    0
w23g0010:1939604:1951411 [0] NCCL INFO Channel 16/32 :    0
w23g0010:1939604:1951411 [0] NCCL INFO Channel 17/32 :    0
w23g0010:1939604:1951411 [0] NCCL INFO Channel 18/32 :    0
w23g0010:1939604:1951411 [0] NCCL INFO Channel 19/32 :    0
w23g0010:1939604:1951411 [0] NCCL INFO Channel 20/32 :    0
w23g0010:1939604:1951411 [0] NCCL INFO Channel 21/32 :    0
w23g0010:1939604:1951411 [0] NCCL INFO Channel 22/32 :    0
w23g0010:1939604:1951411 [0] NCCL INFO Channel 23/32 :    0
w23g0010:1939604:1951411 [0] NCCL INFO Channel 24/32 :    0
w23g0010:1939604:1951411 [0] NCCL INFO Channel 25/32 :    0
w23g0010:1939604:1951411 [0] NCCL INFO Channel 26/32 :    0
w23g0010:1939604:1951411 [0] NCCL INFO Channel 27/32 :    0
w23g0010:1939604:1951411 [0] NCCL INFO Channel 28/32 :    0
w23g0010:1939604:1951411 [0] NCCL INFO Channel 29/32 :    0
w23g0010:1939604:1951411 [0] NCCL INFO Channel 30/32 :    0
w23g0010:1939604:1951411 [0] NCCL INFO Channel 31/32 :    0
w23g0010:1939604:1951411 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
w23g0010:1939604:1951411 [0] NCCL INFO P2P Chunksize set to 131072
w23g0010:1939604:1951411 [0] NCCL INFO Connected all rings
w23g0010:1939604:1951411 [0] NCCL INFO Connected all trees
w23g0010:1939604:1951411 [0] NCCL INFO 32 coll channels, 0 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
w23g0010:1939604:1951411 [0] NCCL INFO comm 0x55cca7fce080 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 9d000 commId 0xb8f1e821b63b01dd - Init COMPLETE
{'loss': 2.0838, 'grad_norm': 0.09577042609453201, 'learning_rate': 2.861271676300578e-05, 'epoch': 0.06}
{'loss': 2.0819, 'grad_norm': 0.3580920994281769, 'learning_rate': 5.7514450867052025e-05, 'epoch': 0.12}
{'loss': 2.0598, 'grad_norm': 0.3853437900543213, 'learning_rate': 8.641618497109827e-05, 'epoch': 0.17}
{'loss': 2.0072, 'grad_norm': 0.5754395127296448, 'learning_rate': 9.829581993569133e-05, 'epoch': 0.23}
{'loss': 1.9882, 'grad_norm': 1.0430878400802612, 'learning_rate': 9.508038585209004e-05, 'epoch': 0.29}
{'loss': 1.9581, 'grad_norm': 0.5575498342514038, 'learning_rate': 9.186495176848876e-05, 'epoch': 0.35}
{'loss': 1.946, 'grad_norm': 0.7489146590232849, 'learning_rate': 8.864951768488747e-05, 'epoch': 0.41}
{'loss': 1.9226, 'grad_norm': 1.1306774616241455, 'learning_rate': 8.543408360128618e-05, 'epoch': 0.46}
{'loss': 1.9132, 'grad_norm': 1.1141831874847412, 'learning_rate': 8.221864951768488e-05, 'epoch': 0.52}
{'loss': 1.8797, 'grad_norm': 1.0331729650497437, 'learning_rate': 7.90032154340836e-05, 'epoch': 0.58}
{'loss': 1.8689, 'grad_norm': 1.486301302909851, 'learning_rate': 7.578778135048232e-05, 'epoch': 0.64}
{'loss': 1.8453, 'grad_norm': 1.4499845504760742, 'learning_rate': 7.257234726688103e-05, 'epoch': 0.69}
{'loss': 1.8588, 'grad_norm': 1.8488800525665283, 'learning_rate': 6.935691318327974e-05, 'epoch': 0.75}
{'loss': 1.8438, 'grad_norm': 1.8945995569229126, 'learning_rate': 6.614147909967846e-05, 'epoch': 0.81}
{'loss': 1.8319, 'grad_norm': 1.6392087936401367, 'learning_rate': 6.292604501607717e-05, 'epoch': 0.87}
{'loss': 1.8143, 'grad_norm': 1.0098776817321777, 'learning_rate': 5.971061093247588e-05, 'epoch': 0.93}
{'loss': 1.8274, 'grad_norm': 1.1889910697937012, 'learning_rate': 5.6495176848874595e-05, 'epoch': 0.98}
{'eval_loss': 1.7583105564117432, 'eval_accuracy': 0.3606156501726122, 'eval_f1': 0.27390563074532287, 'eval_runtime': 84.2675, 'eval_samples_per_second': 82.499, 'eval_steps_per_second': 82.499, 'epoch': 1.0}
{'loss': 1.8328, 'grad_norm': 1.7482023239135742, 'learning_rate': 5.327974276527331e-05, 'epoch': 1.04}
{'loss': 1.8263, 'grad_norm': 1.329149842262268, 'learning_rate': 5.006430868167202e-05, 'epoch': 1.1}
{'loss': 1.7962, 'grad_norm': 4.039010047912598, 'learning_rate': 4.684887459807074e-05, 'epoch': 1.16}
{'loss': 1.8312, 'grad_norm': 1.3259079456329346, 'learning_rate': 4.363344051446945e-05, 'epoch': 1.22}
{'loss': 1.7877, 'grad_norm': 17.680028915405273, 'learning_rate': 4.041800643086817e-05, 'epoch': 1.27}
{'loss': 1.7952, 'grad_norm': 1.1547178030014038, 'learning_rate': 3.7202572347266885e-05, 'epoch': 1.33}
{'loss': 1.793, 'grad_norm': 3.8312954902648926, 'learning_rate': 3.39871382636656e-05, 'epoch': 1.39}
{'loss': 1.7758, 'grad_norm': 1.8160040378570557, 'learning_rate': 3.077170418006431e-05, 'epoch': 1.45}
{'loss': 1.791, 'grad_norm': 3.2940165996551514, 'learning_rate': 2.7556270096463023e-05, 'epoch': 1.5}
{'loss': 1.7777, 'grad_norm': 2.719041585922241, 'learning_rate': 2.4340836012861735e-05, 'epoch': 1.56}
{'loss': 1.7796, 'grad_norm': 2.6281630992889404, 'learning_rate': 2.112540192926045e-05, 'epoch': 1.62}
{'loss': 1.7802, 'grad_norm': 1.5572149753570557, 'learning_rate': 1.7909967845659164e-05, 'epoch': 1.68}
{'loss': 1.7842, 'grad_norm': 2.346977949142456, 'learning_rate': 1.469453376205788e-05, 'epoch': 1.74}
{'loss': 1.7534, 'grad_norm': 2.8219733238220215, 'learning_rate': 1.1479099678456593e-05, 'epoch': 1.79}
{'loss': 1.7977, 'grad_norm': 1.9835543632507324, 'learning_rate': 8.263665594855306e-06, 'epoch': 1.85}
{'loss': 1.7766, 'grad_norm': 3.7210700511932373, 'learning_rate': 5.048231511254019e-06, 'epoch': 1.91}
{'loss': 1.7708, 'grad_norm': 2.4465882778167725, 'learning_rate': 1.8327974276527333e-06, 'epoch': 1.97}
{'eval_loss': 1.7185139656066895, 'eval_accuracy': 0.39384349827387805, 'eval_f1': 0.33420216704869066, 'eval_runtime': 84.2833, 'eval_samples_per_second': 82.484, 'eval_steps_per_second': 82.484, 'epoch': 2.0}
{'train_runtime': 621.2686, 'train_samples_per_second': 88.979, 'train_steps_per_second': 5.563, 'train_loss': 1.85671392193547, 'epoch': 2.0}
[SER][Trainer Eval] {'eval_loss': 1.7185139656066895, 'eval_accuracy': 0.39384349827387805, 'eval_f1': 0.33420216704869066, 'eval_runtime': 71.3712, 'eval_samples_per_second': 97.406, 'eval_steps_per_second': 97.406, 'epoch': 2.0}
w23g0010:1939604:1951414 [0] NCCL INFO [Service thread] Connection closed by localRank 0
w23g0010:1939604:1963128 [0] NCCL INFO comm 0x55cca7fce080 rank 0 nranks 1 cudaDev 0 busId 9d000 - Abort COMPLETE
