[DIST] MASTER_ADDR=n23g0002 MASTER_PORT=29500 NNODES=1 GPUS_PER_NODE=1
[PRE] Skipping all preprocessing (skip_preprocessing=on or all per-step toggles are 'on')
[TRAIN][ASR] Starting ASR phase ...
[Setup] Using device: cuda
[Setup] no_cuda flag set to: False
[ASR] Loading model + processor‚Ä¶
[ASR] Starting from pretrained: models/pretrained/en
trainable params: 589,824 || all params: 94,986,144 || trainable%: 0.6210
[ASR] Trainable parameters: 589824 / 94986144
üõ†Ô∏è  Debug collator output shapes: {'input_values': torch.Size([4, 75264]), 'attention_mask': torch.Size([4, 75264]), 'labels': torch.Size([4, 93])}
[ASR] Starting training with HuggingFace Trainer‚Ä¶
n23g0002:3816499:3816499 [0] NCCL INFO Bootstrap : Using ib0:134.61.46.190<0>
n23g0002:3816499:3816499 [0] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation
n23g0002:3816499:3816499 [0] NCCL INFO cudaDriverVersion 12080
NCCL version 2.20.5+cuda12.4
n23g0002:3816499:3817359 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib0:134.61.46.190<0>
n23g0002:3816499:3817359 [0] NCCL INFO Using non-device net plugin version 0
n23g0002:3816499:3817359 [0] NCCL INFO Using network IB
n23g0002:3816499:3817359 [0] NCCL INFO DMA-BUF is available on GPU device 0
n23g0002:3816499:3817359 [0] NCCL INFO comm 0x555cda341e30 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId ad000 commId 0x501ab6d72cd1dfa4 - Init START
n23g0002:3816499:3817359 [0] NCCL INFO comm 0x555cda341e30 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
n23g0002:3816499:3817359 [0] NCCL INFO Channel 00/32 :    0
n23g0002:3816499:3817359 [0] NCCL INFO Channel 01/32 :    0
n23g0002:3816499:3817359 [0] NCCL INFO Channel 02/32 :    0
n23g0002:3816499:3817359 [0] NCCL INFO Channel 03/32 :    0
n23g0002:3816499:3817359 [0] NCCL INFO Channel 04/32 :    0
n23g0002:3816499:3817359 [0] NCCL INFO Channel 05/32 :    0
n23g0002:3816499:3817359 [0] NCCL INFO Channel 06/32 :    0
n23g0002:3816499:3817359 [0] NCCL INFO Channel 07/32 :    0
n23g0002:3816499:3817359 [0] NCCL INFO Channel 08/32 :    0
n23g0002:3816499:3817359 [0] NCCL INFO Channel 09/32 :    0
n23g0002:3816499:3817359 [0] NCCL INFO Channel 10/32 :    0
n23g0002:3816499:3817359 [0] NCCL INFO Channel 11/32 :    0
n23g0002:3816499:3817359 [0] NCCL INFO Channel 12/32 :    0
n23g0002:3816499:3817359 [0] NCCL INFO Channel 13/32 :    0
n23g0002:3816499:3817359 [0] NCCL INFO Channel 14/32 :    0
n23g0002:3816499:3817359 [0] NCCL INFO Channel 15/32 :    0
n23g0002:3816499:3817359 [0] NCCL INFO Channel 16/32 :    0
n23g0002:3816499:3817359 [0] NCCL INFO Channel 17/32 :    0
n23g0002:3816499:3817359 [0] NCCL INFO Channel 18/32 :    0
n23g0002:3816499:3817359 [0] NCCL INFO Channel 19/32 :    0
n23g0002:3816499:3817359 [0] NCCL INFO Channel 20/32 :    0
n23g0002:3816499:3817359 [0] NCCL INFO Channel 21/32 :    0
n23g0002:3816499:3817359 [0] NCCL INFO Channel 22/32 :    0
n23g0002:3816499:3817359 [0] NCCL INFO Channel 23/32 :    0
n23g0002:3816499:3817359 [0] NCCL INFO Channel 24/32 :    0
n23g0002:3816499:3817359 [0] NCCL INFO Channel 25/32 :    0
n23g0002:3816499:3817359 [0] NCCL INFO Channel 26/32 :    0
n23g0002:3816499:3817359 [0] NCCL INFO Channel 27/32 :    0
n23g0002:3816499:3817359 [0] NCCL INFO Channel 28/32 :    0
n23g0002:3816499:3817359 [0] NCCL INFO Channel 29/32 :    0
n23g0002:3816499:3817359 [0] NCCL INFO Channel 30/32 :    0
n23g0002:3816499:3817359 [0] NCCL INFO Channel 31/32 :    0
n23g0002:3816499:3817359 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
n23g0002:3816499:3817359 [0] NCCL INFO P2P Chunksize set to 131072
n23g0002:3816499:3817359 [0] NCCL INFO Connected all rings
n23g0002:3816499:3817359 [0] NCCL INFO Connected all trees
n23g0002:3816499:3817359 [0] NCCL INFO 32 coll channels, 0 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
n23g0002:3816499:3817359 [0] NCCL INFO comm 0x555cda341e30 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId ad000 commId 0x501ab6d72cd1dfa4 - Init COMPLETE
{'loss': 2.1461, 'grad_norm': 2.901210308074951, 'learning_rate': 0.0, 'epoch': 0.0}
{'loss': 1.6784, 'grad_norm': 4.378085136413574, 'learning_rate': 2.4256064016004e-07, 'epoch': 0.03}
{'loss': 1.6986, 'grad_norm': 3.851980686187744, 'learning_rate': 4.926231557889473e-07, 'epoch': 0.05}
{'loss': 1.6531, 'grad_norm': 2.4031519889831543, 'learning_rate': 7.426856714178546e-07, 'epoch': 0.08}
{'loss': 1.5797, 'grad_norm': 1.7373837232589722, 'learning_rate': 9.927481870467618e-07, 'epoch': 0.1}
{'loss': 1.5491, 'grad_norm': 3.109706163406372, 'learning_rate': 1.2403100775193799e-06, 'epoch': 0.13}
{'loss': 1.5331, 'grad_norm': 5.144200325012207, 'learning_rate': 1.490372593148287e-06, 'epoch': 0.15}
{'loss': 1.5572, 'grad_norm': 4.644967555999756, 'learning_rate': 1.7404351087771944e-06, 'epoch': 0.18}
{'loss': 1.6414, 'grad_norm': 2.3887767791748047, 'learning_rate': 1.9904976244061016e-06, 'epoch': 0.2}
{'loss': 1.5741, 'grad_norm': 2.296644926071167, 'learning_rate': 2.2405601400350087e-06, 'epoch': 0.23}
{'loss': 1.5444, 'grad_norm': 3.656287908554077, 'learning_rate': 2.4906226556639163e-06, 'epoch': 0.25}
{'loss': 1.5716, 'grad_norm': 3.323596477508545, 'learning_rate': 2.7406851712928235e-06, 'epoch': 0.28}
{'loss': 1.4445, 'grad_norm': 2.8547379970550537, 'learning_rate': 2.9907476869217307e-06, 'epoch': 0.3}
{'loss': 1.4165, 'grad_norm': 9.39425277709961, 'learning_rate': 3.240810202550638e-06, 'epoch': 0.33}
{'loss': 1.3659, 'grad_norm': 2.724039316177368, 'learning_rate': 3.4908727181795454e-06, 'epoch': 0.35}
{'loss': 1.3301, 'grad_norm': 2.9335105419158936, 'learning_rate': 3.7409352338084526e-06, 'epoch': 0.38}
{'loss': 1.3295, 'grad_norm': 2.699341058731079, 'learning_rate': 3.99099774943736e-06, 'epoch': 0.4}
{'loss': 1.1866, 'grad_norm': 4.894783973693848, 'learning_rate': 4.241060265066267e-06, 'epoch': 0.43}
{'loss': 1.194, 'grad_norm': 3.4467833042144775, 'learning_rate': 4.491122780695174e-06, 'epoch': 0.45}
{'loss': 1.2587, 'grad_norm': 4.398746967315674, 'learning_rate': 4.741185296324081e-06, 'epoch': 0.48}
{'loss': 1.2505, 'grad_norm': 2.3397233486175537, 'learning_rate': 4.991247811952989e-06, 'epoch': 0.5}
{'loss': 1.1508, 'grad_norm': 4.8530073165893555, 'learning_rate': 5.2388097024256065e-06, 'epoch': 0.53}
{'loss': 1.1757, 'grad_norm': 4.591498374938965, 'learning_rate': 5.488872218054514e-06, 'epoch': 0.55}
{'loss': 1.1058, 'grad_norm': 3.104668617248535, 'learning_rate': 5.738934733683421e-06, 'epoch': 0.58}
{'loss': 1.1844, 'grad_norm': 3.2230963706970215, 'learning_rate': 5.986496624156039e-06, 'epoch': 0.6}
{'loss': 1.1294, 'grad_norm': 6.644415378570557, 'learning_rate': 6.236559139784947e-06, 'epoch': 0.63}
{'loss': 1.1692, 'grad_norm': 3.297017812728882, 'learning_rate': 6.486621655413854e-06, 'epoch': 0.65}
{'loss': 1.1236, 'grad_norm': 5.027950763702393, 'learning_rate': 6.736684171042761e-06, 'epoch': 0.68}
{'loss': 1.1688, 'grad_norm': 4.037020683288574, 'learning_rate': 6.986746686671668e-06, 'epoch': 0.7}
{'loss': 1.1335, 'grad_norm': 2.808053493499756, 'learning_rate': 7.236809202300576e-06, 'epoch': 0.73}
{'loss': 1.0669, 'grad_norm': 5.801913738250732, 'learning_rate': 7.486871717929482e-06, 'epoch': 0.75}
{'loss': 1.0796, 'grad_norm': 7.922361850738525, 'learning_rate': 7.73693423355839e-06, 'epoch': 0.78}
{'loss': 1.0562, 'grad_norm': 2.4107887744903564, 'learning_rate': 7.986996749187298e-06, 'epoch': 0.8}
{'loss': 1.131, 'grad_norm': 3.858052968978882, 'learning_rate': 8.237059264816205e-06, 'epoch': 0.83}
{'loss': 1.0919, 'grad_norm': 3.705667018890381, 'learning_rate': 8.487121780445112e-06, 'epoch': 0.85}
{'loss': 1.0192, 'grad_norm': 5.983622074127197, 'learning_rate': 8.737184296074019e-06, 'epoch': 0.88}
{'loss': 1.0559, 'grad_norm': 4.577014923095703, 'learning_rate': 8.987246811702927e-06, 'epoch': 0.9}
{'loss': 1.0126, 'grad_norm': 2.978219985961914, 'learning_rate': 9.237309327331834e-06, 'epoch': 0.93}
{'loss': 1.0989, 'grad_norm': 3.022665023803711, 'learning_rate': 9.48737184296074e-06, 'epoch': 0.95}
{'loss': 0.9405, 'grad_norm': 10.054338455200195, 'learning_rate': 9.737434358589647e-06, 'epoch': 0.98}
{'eval_loss': 0.8088533878326416, 'eval_wer': 0.4009401299669756, 'eval_runtime': 1512.5125, 'eval_samples_per_second': 5.289, 'eval_steps_per_second': 5.289, 'epoch': 1.0}
{'loss': 0.9587, 'grad_norm': 3.9074134826660156, 'learning_rate': 9.987496874218556e-06, 'epoch': 1.0}
{'loss': 1.0301, 'grad_norm': 3.7983438968658447, 'learning_rate': 1e-05, 'epoch': 1.03}
{'loss': 0.8636, 'grad_norm': 12.188901901245117, 'learning_rate': 1e-05, 'epoch': 1.05}
{'loss': 1.009, 'grad_norm': 4.670998573303223, 'learning_rate': 1e-05, 'epoch': 1.08}
{'loss': 0.997, 'grad_norm': 2.1629605293273926, 'learning_rate': 1e-05, 'epoch': 1.1}
{'loss': 0.9513, 'grad_norm': 5.081660270690918, 'learning_rate': 1e-05, 'epoch': 1.13}
{'loss': 1.0119, 'grad_norm': 6.43517541885376, 'learning_rate': 1e-05, 'epoch': 1.15}
{'loss': 0.9073, 'grad_norm': 2.780762195587158, 'learning_rate': 1e-05, 'epoch': 1.18}
{'loss': 0.9545, 'grad_norm': 5.472571849822998, 'learning_rate': 1e-05, 'epoch': 1.2}
{'loss': 0.9632, 'grad_norm': 3.5855159759521484, 'learning_rate': 1e-05, 'epoch': 1.23}
{'loss': 0.9042, 'grad_norm': 9.038901329040527, 'learning_rate': 1e-05, 'epoch': 1.25}
{'loss': 0.9584, 'grad_norm': 8.082786560058594, 'learning_rate': 1e-05, 'epoch': 1.28}
{'loss': 0.892, 'grad_norm': 3.3623902797698975, 'learning_rate': 1e-05, 'epoch': 1.3}
{'loss': 0.9811, 'grad_norm': 8.401394844055176, 'learning_rate': 1e-05, 'epoch': 1.33}
{'loss': 0.8784, 'grad_norm': 7.222149848937988, 'learning_rate': 1e-05, 'epoch': 1.35}
{'loss': 0.9404, 'grad_norm': 28.150257110595703, 'learning_rate': 1e-05, 'epoch': 1.38}
{'loss': 0.965, 'grad_norm': 24.58548927307129, 'learning_rate': 1e-05, 'epoch': 1.4}
{'loss': 0.9134, 'grad_norm': 2.772768020629883, 'learning_rate': 1e-05, 'epoch': 1.43}
{'loss': 0.9592, 'grad_norm': 4.015868186950684, 'learning_rate': 1e-05, 'epoch': 1.45}
{'loss': 0.9781, 'grad_norm': 1.305997371673584, 'learning_rate': 1e-05, 'epoch': 1.48}
{'loss': 0.9162, 'grad_norm': 8.489426612854004, 'learning_rate': 1e-05, 'epoch': 1.5}
{'loss': 0.9407, 'grad_norm': 2.776662826538086, 'learning_rate': 1e-05, 'epoch': 1.53}
{'loss': 0.8557, 'grad_norm': 4.082067966461182, 'learning_rate': 1e-05, 'epoch': 1.55}
{'loss': 1.2621, 'grad_norm': 7.678617000579834, 'learning_rate': 1e-05, 'epoch': 1.58}
{'loss': 0.9256, 'grad_norm': 4.3768310546875, 'learning_rate': 1e-05, 'epoch': 1.6}
{'loss': 0.8478, 'grad_norm': 7.266057968139648, 'learning_rate': 1e-05, 'epoch': 1.63}
{'loss': 0.9586, 'grad_norm': 9.687085151672363, 'learning_rate': 1e-05, 'epoch': 1.65}
{'loss': 0.9556, 'grad_norm': 12.211188316345215, 'learning_rate': 1e-05, 'epoch': 1.68}
{'loss': 0.9019, 'grad_norm': 4.652528762817383, 'learning_rate': 1e-05, 'epoch': 1.7}
{'loss': 0.9914, 'grad_norm': 7.289559364318848, 'learning_rate': 1e-05, 'epoch': 1.73}
{'loss': 0.9315, 'grad_norm': 2.746591091156006, 'learning_rate': 1e-05, 'epoch': 1.75}
{'loss': 0.9723, 'grad_norm': 10.345009803771973, 'learning_rate': 1e-05, 'epoch': 1.78}
{'loss': 0.8727, 'grad_norm': 9.329782485961914, 'learning_rate': 1e-05, 'epoch': 1.8}
{'loss': 0.8943, 'grad_norm': 7.568169116973877, 'learning_rate': 1e-05, 'epoch': 1.83}
{'loss': 0.9992, 'grad_norm': 4.912591457366943, 'learning_rate': 1e-05, 'epoch': 1.85}
{'loss': 0.8468, 'grad_norm': 7.806446552276611, 'learning_rate': 1e-05, 'epoch': 1.88}
{'loss': 1.0226, 'grad_norm': 3.5953807830810547, 'learning_rate': 1e-05, 'epoch': 1.9}
{'loss': 0.9411, 'grad_norm': 3.4276599884033203, 'learning_rate': 1e-05, 'epoch': 1.93}
{'loss': 0.9349, 'grad_norm': 7.427042007446289, 'learning_rate': 1e-05, 'epoch': 1.95}
{'loss': 0.8846, 'grad_norm': 11.365595817565918, 'learning_rate': 1e-05, 'epoch': 1.98}
{'eval_loss': 0.7332964539527893, 'eval_wer': 0.3587940769148823, 'eval_runtime': 1505.1626, 'eval_samples_per_second': 5.315, 'eval_steps_per_second': 5.315, 'epoch': 2.0}
{'loss': 0.8974, 'grad_norm': 29.332313537597656, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.909, 'grad_norm': 3.6524064540863037, 'learning_rate': 1e-05, 'epoch': 2.03}
{'loss': 0.8774, 'grad_norm': 5.393641471862793, 'learning_rate': 1e-05, 'epoch': 2.05}
{'loss': 0.837, 'grad_norm': 5.712169647216797, 'learning_rate': 1e-05, 'epoch': 2.08}
{'loss': 0.8446, 'grad_norm': 5.599977493286133, 'learning_rate': 1e-05, 'epoch': 2.1}
{'loss': 0.8776, 'grad_norm': 26.571897506713867, 'learning_rate': 1e-05, 'epoch': 2.13}
{'loss': 0.9145, 'grad_norm': 6.869882106781006, 'learning_rate': 1e-05, 'epoch': 2.15}
{'loss': 0.9148, 'grad_norm': 3.0596988201141357, 'learning_rate': 1e-05, 'epoch': 2.18}
{'loss': 0.8584, 'grad_norm': 6.983425140380859, 'learning_rate': 1e-05, 'epoch': 2.2}
{'loss': 0.8353, 'grad_norm': 2.8901102542877197, 'learning_rate': 1e-05, 'epoch': 2.23}
{'loss': 0.8676, 'grad_norm': 2.234708547592163, 'learning_rate': 1e-05, 'epoch': 2.25}
{'loss': 0.8802, 'grad_norm': 6.385138511657715, 'learning_rate': 1e-05, 'epoch': 2.28}
{'loss': 0.8965, 'grad_norm': 3.9131617546081543, 'learning_rate': 1e-05, 'epoch': 2.3}
{'loss': 0.8658, 'grad_norm': 1.8807936906814575, 'learning_rate': 1e-05, 'epoch': 2.33}
{'loss': 0.9393, 'grad_norm': 5.734562397003174, 'learning_rate': 1e-05, 'epoch': 2.35}
{'loss': 0.8679, 'grad_norm': 21.672210693359375, 'learning_rate': 1e-05, 'epoch': 2.38}
{'loss': 0.8932, 'grad_norm': 8.870942115783691, 'learning_rate': 1e-05, 'epoch': 2.4}
{'loss': 0.9618, 'grad_norm': 9.826595306396484, 'learning_rate': 1e-05, 'epoch': 2.43}
{'loss': 0.8536, 'grad_norm': 12.993246078491211, 'learning_rate': 1e-05, 'epoch': 2.45}
{'loss': 0.82, 'grad_norm': 4.3953118324279785, 'learning_rate': 1e-05, 'epoch': 2.48}
{'loss': 0.9314, 'grad_norm': 5.284197807312012, 'learning_rate': 1e-05, 'epoch': 2.5}
{'loss': 0.8827, 'grad_norm': 9.851277351379395, 'learning_rate': 1e-05, 'epoch': 2.53}
{'loss': 0.8925, 'grad_norm': 8.31216049194336, 'learning_rate': 1e-05, 'epoch': 2.55}
{'loss': 0.9105, 'grad_norm': 6.499915599822998, 'learning_rate': 1e-05, 'epoch': 2.58}
{'loss': 0.9188, 'grad_norm': 5.711598873138428, 'learning_rate': 1e-05, 'epoch': 2.6}
{'loss': 0.8882, 'grad_norm': 3.4055161476135254, 'learning_rate': 1e-05, 'epoch': 2.63}
{'loss': 0.9288, 'grad_norm': 4.176290035247803, 'learning_rate': 1e-05, 'epoch': 2.65}
{'loss': 0.8253, 'grad_norm': 3.235628843307495, 'learning_rate': 1e-05, 'epoch': 2.68}
{'loss': 0.8703, 'grad_norm': 12.005757331848145, 'learning_rate': 1e-05, 'epoch': 2.7}
{'loss': 0.8253, 'grad_norm': 5.265368461608887, 'learning_rate': 1e-05, 'epoch': 2.73}
{'loss': 0.92, 'grad_norm': 2.755018472671509, 'learning_rate': 1e-05, 'epoch': 2.75}
{'loss': 0.8885, 'grad_norm': 4.732458114624023, 'learning_rate': 1e-05, 'epoch': 2.78}
{'loss': 0.8466, 'grad_norm': 2.4041335582733154, 'learning_rate': 1e-05, 'epoch': 2.8}
{'loss': 0.8436, 'grad_norm': 4.67474889755249, 'learning_rate': 1e-05, 'epoch': 2.83}
{'loss': 0.8791, 'grad_norm': 6.469702243804932, 'learning_rate': 1e-05, 'epoch': 2.85}
{'loss': 0.8871, 'grad_norm': 8.565633773803711, 'learning_rate': 1e-05, 'epoch': 2.88}
{'loss': 0.9821, 'grad_norm': 10.813153266906738, 'learning_rate': 1e-05, 'epoch': 2.9}
{'loss': 0.8273, 'grad_norm': 13.004973411560059, 'learning_rate': 1e-05, 'epoch': 2.93}
{'loss': 0.9317, 'grad_norm': 5.63201379776001, 'learning_rate': 1e-05, 'epoch': 2.95}
{'loss': 0.9608, 'grad_norm': 4.615538597106934, 'learning_rate': 1e-05, 'epoch': 2.98}
{'eval_loss': 0.6985765099525452, 'eval_wer': 0.3416293810589113, 'eval_runtime': 1510.0075, 'eval_samples_per_second': 5.298, 'eval_steps_per_second': 5.298, 'epoch': 3.0}
{'loss': 0.903, 'grad_norm': 13.014877319335938, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.7995, 'grad_norm': 2.7843611240386963, 'learning_rate': 1e-05, 'epoch': 3.03}
{'loss': 0.8263, 'grad_norm': 3.1105549335479736, 'learning_rate': 1e-05, 'epoch': 3.05}
{'loss': 0.8171, 'grad_norm': 5.334942817687988, 'learning_rate': 1e-05, 'epoch': 3.08}
{'loss': 0.8695, 'grad_norm': 5.5452141761779785, 'learning_rate': 1e-05, 'epoch': 3.1}
{'loss': 0.89, 'grad_norm': 7.292316913604736, 'learning_rate': 1e-05, 'epoch': 3.13}
{'loss': 0.9431, 'grad_norm': 5.553826332092285, 'learning_rate': 1e-05, 'epoch': 3.15}
{'loss': 0.8943, 'grad_norm': 4.785948753356934, 'learning_rate': 1e-05, 'epoch': 3.18}
{'loss': 0.8845, 'grad_norm': 5.863814353942871, 'learning_rate': 1e-05, 'epoch': 3.2}
{'loss': 0.9029, 'grad_norm': 4.830633640289307, 'learning_rate': 1e-05, 'epoch': 3.23}
{'loss': 0.8742, 'grad_norm': 5.52962064743042, 'learning_rate': 1e-05, 'epoch': 3.25}
{'loss': 0.9391, 'grad_norm': 5.136034965515137, 'learning_rate': 1e-05, 'epoch': 3.28}
{'loss': 0.8095, 'grad_norm': 24.478965759277344, 'learning_rate': 1e-05, 'epoch': 3.3}
{'loss': 0.7489, 'grad_norm': 8.345349311828613, 'learning_rate': 1e-05, 'epoch': 3.33}
{'loss': 0.8618, 'grad_norm': 4.13482141494751, 'learning_rate': 1e-05, 'epoch': 3.35}
{'loss': 0.9167, 'grad_norm': 2.24662709236145, 'learning_rate': 1e-05, 'epoch': 3.38}
{'loss': 0.8814, 'grad_norm': 7.018519878387451, 'learning_rate': 1e-05, 'epoch': 3.4}
{'loss': 0.9084, 'grad_norm': 23.540136337280273, 'learning_rate': 1e-05, 'epoch': 3.43}
{'loss': 0.8419, 'grad_norm': 7.713634014129639, 'learning_rate': 1e-05, 'epoch': 3.45}
{'loss': 0.903, 'grad_norm': 6.4623260498046875, 'learning_rate': 1e-05, 'epoch': 3.48}
{'loss': 0.902, 'grad_norm': 8.097264289855957, 'learning_rate': 1e-05, 'epoch': 3.5}
{'loss': 0.7543, 'grad_norm': 6.100045204162598, 'learning_rate': 1e-05, 'epoch': 3.53}
{'loss': 0.8575, 'grad_norm': 3.812725305557251, 'learning_rate': 1e-05, 'epoch': 3.55}
{'loss': 0.9464, 'grad_norm': 5.196094036102295, 'learning_rate': 1e-05, 'epoch': 3.58}
{'loss': 0.811, 'grad_norm': 26.250905990600586, 'learning_rate': 1e-05, 'epoch': 3.6}
{'loss': 0.8471, 'grad_norm': 17.403724670410156, 'learning_rate': 1e-05, 'epoch': 3.63}
{'loss': 0.9092, 'grad_norm': 12.809587478637695, 'learning_rate': 1e-05, 'epoch': 3.65}
{'loss': 0.7999, 'grad_norm': 3.147568702697754, 'learning_rate': 1e-05, 'epoch': 3.68}
{'loss': 0.8278, 'grad_norm': 8.019674301147461, 'learning_rate': 1e-05, 'epoch': 3.7}
{'loss': 0.8503, 'grad_norm': 12.283101081848145, 'learning_rate': 1e-05, 'epoch': 3.73}
{'loss': 0.806, 'grad_norm': 4.625621795654297, 'learning_rate': 1e-05, 'epoch': 3.75}
{'loss': 0.8957, 'grad_norm': 3.2199432849884033, 'learning_rate': 1e-05, 'epoch': 3.78}
{'loss': 0.8222, 'grad_norm': 4.77829647064209, 'learning_rate': 1e-05, 'epoch': 3.8}
{'loss': 0.7869, 'grad_norm': 8.286413192749023, 'learning_rate': 1e-05, 'epoch': 3.83}
{'loss': 0.8435, 'grad_norm': 7.1211724281311035, 'learning_rate': 1e-05, 'epoch': 3.85}
{'loss': 0.8591, 'grad_norm': 7.52541971206665, 'learning_rate': 1e-05, 'epoch': 3.88}
{'loss': 0.8378, 'grad_norm': 7.169031143188477, 'learning_rate': 1e-05, 'epoch': 3.9}
{'loss': 0.8434, 'grad_norm': 9.57276725769043, 'learning_rate': 1e-05, 'epoch': 3.93}
{'loss': 0.8718, 'grad_norm': 6.196649551391602, 'learning_rate': 1e-05, 'epoch': 3.95}
{'loss': 0.7927, 'grad_norm': 5.746237277984619, 'learning_rate': 1e-05, 'epoch': 3.98}
{'eval_loss': 0.6917538642883301, 'eval_wer': 0.3339192500266326, 'eval_runtime': 1497.0334, 'eval_samples_per_second': 5.344, 'eval_steps_per_second': 5.344, 'epoch': 4.0}
{'loss': 0.7673, 'grad_norm': 6.1439056396484375, 'learning_rate': 1e-05, 'epoch': 4.0}
{'loss': 0.8176, 'grad_norm': 4.172843933105469, 'learning_rate': 1e-05, 'epoch': 4.03}
{'loss': 0.9257, 'grad_norm': 9.871294021606445, 'learning_rate': 1e-05, 'epoch': 4.05}
{'loss': 0.8804, 'grad_norm': 6.971874237060547, 'learning_rate': 1e-05, 'epoch': 4.08}
{'loss': 0.8346, 'grad_norm': 5.335736274719238, 'learning_rate': 1e-05, 'epoch': 4.1}
{'loss': 0.8096, 'grad_norm': 36.870140075683594, 'learning_rate': 1e-05, 'epoch': 4.13}
{'loss': 0.7861, 'grad_norm': 13.830099105834961, 'learning_rate': 1e-05, 'epoch': 4.15}
{'loss': 0.8486, 'grad_norm': 8.188611030578613, 'learning_rate': 1e-05, 'epoch': 4.18}
{'loss': 0.8056, 'grad_norm': 11.45302677154541, 'learning_rate': 1e-05, 'epoch': 4.2}
{'loss': 0.7926, 'grad_norm': 4.149225234985352, 'learning_rate': 1e-05, 'epoch': 4.23}
{'loss': 0.8359, 'grad_norm': 13.47354793548584, 'learning_rate': 1e-05, 'epoch': 4.25}
{'loss': 0.8505, 'grad_norm': 4.570085525512695, 'learning_rate': 1e-05, 'epoch': 4.28}
{'loss': 0.8027, 'grad_norm': 4.8177032470703125, 'learning_rate': 1e-05, 'epoch': 4.3}
{'loss': 0.8571, 'grad_norm': 5.68479585647583, 'learning_rate': 1e-05, 'epoch': 4.33}
{'loss': 0.8636, 'grad_norm': 5.357122898101807, 'learning_rate': 1e-05, 'epoch': 4.35}
{'loss': 0.8472, 'grad_norm': 6.980129241943359, 'learning_rate': 1e-05, 'epoch': 4.38}
{'loss': 0.7914, 'grad_norm': 6.44849157333374, 'learning_rate': 1e-05, 'epoch': 4.4}
{'loss': 0.9192, 'grad_norm': 2.3304290771484375, 'learning_rate': 1e-05, 'epoch': 4.43}
{'loss': 0.8809, 'grad_norm': 6.522716522216797, 'learning_rate': 1e-05, 'epoch': 4.45}
{'loss': 0.8241, 'grad_norm': 14.667988777160645, 'learning_rate': 1e-05, 'epoch': 4.48}
{'loss': 0.7603, 'grad_norm': 5.060471057891846, 'learning_rate': 1e-05, 'epoch': 4.5}
{'loss': 0.9198, 'grad_norm': 12.861700057983398, 'learning_rate': 1e-05, 'epoch': 4.53}
{'loss': 0.8503, 'grad_norm': 6.343802452087402, 'learning_rate': 1e-05, 'epoch': 4.55}
{'loss': 0.8878, 'grad_norm': 11.923386573791504, 'learning_rate': 1e-05, 'epoch': 4.58}
{'loss': 0.8079, 'grad_norm': 9.160072326660156, 'learning_rate': 1e-05, 'epoch': 4.6}
{'loss': 0.8185, 'grad_norm': 4.183590412139893, 'learning_rate': 1e-05, 'epoch': 4.63}
{'loss': 0.7967, 'grad_norm': 1.6400635242462158, 'learning_rate': 1e-05, 'epoch': 4.65}
{'loss': 0.7802, 'grad_norm': 9.670578956604004, 'learning_rate': 1e-05, 'epoch': 4.68}
{'loss': 0.8369, 'grad_norm': 7.6889753341674805, 'learning_rate': 1e-05, 'epoch': 4.7}
{'loss': 0.8291, 'grad_norm': 7.932472229003906, 'learning_rate': 1e-05, 'epoch': 4.73}
{'loss': 0.7744, 'grad_norm': 5.694344520568848, 'learning_rate': 1e-05, 'epoch': 4.75}
{'loss': 0.8204, 'grad_norm': 6.095939636230469, 'learning_rate': 1e-05, 'epoch': 4.78}
{'loss': 0.8126, 'grad_norm': 11.881796836853027, 'learning_rate': 1e-05, 'epoch': 4.8}
{'loss': 0.8192, 'grad_norm': 6.099485397338867, 'learning_rate': 1e-05, 'epoch': 4.83}
{'loss': 0.8121, 'grad_norm': 5.284846782684326, 'learning_rate': 1e-05, 'epoch': 4.85}
{'loss': 0.8955, 'grad_norm': 3.542020559310913, 'learning_rate': 1e-05, 'epoch': 4.88}
{'loss': 0.8279, 'grad_norm': 3.332853078842163, 'learning_rate': 1e-05, 'epoch': 4.9}
{'loss': 0.8937, 'grad_norm': 2.51774263381958, 'learning_rate': 1e-05, 'epoch': 4.93}
{'loss': 0.8574, 'grad_norm': 9.717177391052246, 'learning_rate': 1e-05, 'epoch': 4.95}
{'loss': 0.8097, 'grad_norm': 2.9249653816223145, 'learning_rate': 1e-05, 'epoch': 4.98}
{'eval_loss': 0.6797564029693604, 'eval_wer': 0.3300575263662512, 'eval_runtime': 1510.1995, 'eval_samples_per_second': 5.297, 'eval_steps_per_second': 5.297, 'epoch': 5.0}
{'loss': 0.8452, 'grad_norm': 4.965489864349365, 'learning_rate': 1e-05, 'epoch': 5.0}
{'loss': 0.8167, 'grad_norm': 6.25285530090332, 'learning_rate': 1e-05, 'epoch': 5.03}
{'loss': 0.9145, 'grad_norm': 6.034165382385254, 'learning_rate': 1e-05, 'epoch': 5.05}
{'loss': 0.7563, 'grad_norm': 8.392610549926758, 'learning_rate': 1e-05, 'epoch': 5.08}
{'loss': 0.7534, 'grad_norm': 3.7983341217041016, 'learning_rate': 1e-05, 'epoch': 5.1}
{'loss': 0.8517, 'grad_norm': 6.141210556030273, 'learning_rate': 1e-05, 'epoch': 5.13}
{'loss': 0.8206, 'grad_norm': 5.6314921379089355, 'learning_rate': 1e-05, 'epoch': 5.15}
{'loss': 0.8718, 'grad_norm': 7.847455024719238, 'learning_rate': 1e-05, 'epoch': 5.18}
{'loss': 0.8459, 'grad_norm': 4.794256687164307, 'learning_rate': 1e-05, 'epoch': 5.2}
{'loss': 0.8044, 'grad_norm': 1.9201021194458008, 'learning_rate': 1e-05, 'epoch': 5.23}
{'loss': 0.8645, 'grad_norm': 20.0024471282959, 'learning_rate': 1e-05, 'epoch': 5.25}
{'loss': 0.8732, 'grad_norm': 11.279437065124512, 'learning_rate': 1e-05, 'epoch': 5.28}
{'loss': 0.7734, 'grad_norm': 6.251976013183594, 'learning_rate': 1e-05, 'epoch': 5.3}
{'loss': 0.8512, 'grad_norm': 4.910239219665527, 'learning_rate': 1e-05, 'epoch': 5.33}
{'loss': 0.805, 'grad_norm': 6.755512237548828, 'learning_rate': 1e-05, 'epoch': 5.35}
{'loss': 0.7638, 'grad_norm': 7.486804485321045, 'learning_rate': 1e-05, 'epoch': 5.38}
{'loss': 0.7786, 'grad_norm': 5.510246276855469, 'learning_rate': 1e-05, 'epoch': 5.4}
{'loss': 0.8801, 'grad_norm': 8.577537536621094, 'learning_rate': 1e-05, 'epoch': 5.43}
{'loss': 0.7903, 'grad_norm': 7.780660629272461, 'learning_rate': 1e-05, 'epoch': 5.45}
{'loss': 0.8068, 'grad_norm': 8.709755897521973, 'learning_rate': 1e-05, 'epoch': 5.48}
{'loss': 0.9199, 'grad_norm': 5.875855922698975, 'learning_rate': 1e-05, 'epoch': 5.5}
{'loss': 0.7761, 'grad_norm': 7.895782470703125, 'learning_rate': 1e-05, 'epoch': 5.53}
{'loss': 0.7928, 'grad_norm': 10.02329158782959, 'learning_rate': 1e-05, 'epoch': 5.55}
{'loss': 0.7459, 'grad_norm': 4.672887325286865, 'learning_rate': 1e-05, 'epoch': 5.58}
{'loss': 0.7367, 'grad_norm': 23.158498764038086, 'learning_rate': 1e-05, 'epoch': 5.6}
{'loss': 0.7204, 'grad_norm': 5.17245626449585, 'learning_rate': 1e-05, 'epoch': 5.63}
{'loss': 0.8769, 'grad_norm': 6.945804119110107, 'learning_rate': 1e-05, 'epoch': 5.65}
{'loss': 0.7294, 'grad_norm': 8.006284713745117, 'learning_rate': 1e-05, 'epoch': 5.68}
{'loss': 0.841, 'grad_norm': 7.855495452880859, 'learning_rate': 1e-05, 'epoch': 5.7}
{'loss': 0.8201, 'grad_norm': 6.972522735595703, 'learning_rate': 1e-05, 'epoch': 5.73}
{'loss': 0.9795, 'grad_norm': 7.249660491943359, 'learning_rate': 1e-05, 'epoch': 5.75}
{'loss': 0.8559, 'grad_norm': 5.346981525421143, 'learning_rate': 1e-05, 'epoch': 5.78}
{'loss': 0.8642, 'grad_norm': inf, 'learning_rate': 1e-05, 'epoch': 5.8}
{'loss': 0.7673, 'grad_norm': 3.9674720764160156, 'learning_rate': 1e-05, 'epoch': 5.83}
{'loss': 0.8992, 'grad_norm': 6.860767364501953, 'learning_rate': 1e-05, 'epoch': 5.85}
{'loss': 0.8117, 'grad_norm': 9.983861923217773, 'learning_rate': 1e-05, 'epoch': 5.88}
{'loss': 0.7861, 'grad_norm': 9.490367889404297, 'learning_rate': 1e-05, 'epoch': 5.9}
{'loss': 0.8725, 'grad_norm': 8.204387664794922, 'learning_rate': 1e-05, 'epoch': 5.93}
{'loss': 0.7843, 'grad_norm': 5.441108703613281, 'learning_rate': 1e-05, 'epoch': 5.95}
{'loss': 0.783, 'grad_norm': 7.549819469451904, 'learning_rate': 1e-05, 'epoch': 5.98}
{'eval_loss': 0.6733279824256897, 'eval_wer': 0.32622243528283795, 'eval_runtime': 1511.5045, 'eval_samples_per_second': 5.293, 'eval_steps_per_second': 5.293, 'epoch': 6.0}
{'loss': 0.7768, 'grad_norm': 5.333193778991699, 'learning_rate': 1e-05, 'epoch': 6.0}
{'loss': 0.8219, 'grad_norm': 9.795702934265137, 'learning_rate': 1e-05, 'epoch': 6.03}
{'loss': 0.8254, 'grad_norm': 12.003573417663574, 'learning_rate': 1e-05, 'epoch': 6.05}
{'loss': 0.8117, 'grad_norm': 5.292212009429932, 'learning_rate': 1e-05, 'epoch': 6.08}
{'loss': 0.8083, 'grad_norm': 6.507730484008789, 'learning_rate': 1e-05, 'epoch': 6.1}
{'loss': 0.829, 'grad_norm': 2.12880802154541, 'learning_rate': 1e-05, 'epoch': 6.13}
{'loss': 0.7502, 'grad_norm': 19.209548950195312, 'learning_rate': 1e-05, 'epoch': 6.15}
{'loss': 0.8456, 'grad_norm': 8.863473892211914, 'learning_rate': 1e-05, 'epoch': 6.18}
{'loss': 0.8819, 'grad_norm': 7.351572513580322, 'learning_rate': 1e-05, 'epoch': 6.2}
{'loss': 0.7687, 'grad_norm': 5.7782182693481445, 'learning_rate': 1e-05, 'epoch': 6.23}
{'loss': 0.7555, 'grad_norm': 7.714659690856934, 'learning_rate': 1e-05, 'epoch': 6.25}
{'loss': 0.8729, 'grad_norm': 8.082050323486328, 'learning_rate': 1e-05, 'epoch': 6.28}
{'loss': 0.7866, 'grad_norm': 19.524709701538086, 'learning_rate': 1e-05, 'epoch': 6.3}
{'loss': 0.8452, 'grad_norm': 19.772422790527344, 'learning_rate': 1e-05, 'epoch': 6.33}
{'loss': 0.8352, 'grad_norm': 3.604750156402588, 'learning_rate': 1e-05, 'epoch': 6.35}
{'loss': 0.7866, 'grad_norm': 5.928703784942627, 'learning_rate': 1e-05, 'epoch': 6.38}
{'loss': 0.8231, 'grad_norm': 4.156232833862305, 'learning_rate': 1e-05, 'epoch': 6.4}
{'loss': 0.8112, 'grad_norm': 6.760221481323242, 'learning_rate': 1e-05, 'epoch': 6.43}
{'loss': 0.7922, 'grad_norm': 9.110177993774414, 'learning_rate': 1e-05, 'epoch': 6.45}
{'loss': 0.7476, 'grad_norm': 5.127090930938721, 'learning_rate': 1e-05, 'epoch': 6.48}
{'loss': 0.7154, 'grad_norm': 5.166577339172363, 'learning_rate': 1e-05, 'epoch': 6.5}
{'loss': 0.8109, 'grad_norm': 9.443381309509277, 'learning_rate': 1e-05, 'epoch': 6.53}
{'loss': 0.8237, 'grad_norm': 28.73354148864746, 'learning_rate': 1e-05, 'epoch': 6.55}
{'loss': 0.762, 'grad_norm': 17.915884017944336, 'learning_rate': 1e-05, 'epoch': 6.58}
{'loss': 0.7572, 'grad_norm': 5.075450420379639, 'learning_rate': 1e-05, 'epoch': 6.6}
{'loss': 0.7481, 'grad_norm': 5.1286773681640625, 'learning_rate': 1e-05, 'epoch': 6.63}
{'loss': 0.8311, 'grad_norm': 9.514775276184082, 'learning_rate': 1e-05, 'epoch': 6.65}
{'loss': 0.8306, 'grad_norm': 8.361628532409668, 'learning_rate': 1e-05, 'epoch': 6.68}
{'loss': 0.7618, 'grad_norm': 4.847629070281982, 'learning_rate': 1e-05, 'epoch': 6.7}
{'loss': 0.7485, 'grad_norm': 8.306504249572754, 'learning_rate': 1e-05, 'epoch': 6.73}
{'loss': 0.8076, 'grad_norm': 6.940940856933594, 'learning_rate': 1e-05, 'epoch': 6.75}
{'loss': 0.7815, 'grad_norm': 20.67973518371582, 'learning_rate': 1e-05, 'epoch': 6.78}
{'loss': 0.829, 'grad_norm': 8.34162425994873, 'learning_rate': 1e-05, 'epoch': 6.8}
{'loss': 0.755, 'grad_norm': 5.374801158905029, 'learning_rate': 1e-05, 'epoch': 6.83}
{'loss': 0.7929, 'grad_norm': 6.411041736602783, 'learning_rate': 1e-05, 'epoch': 6.85}
{'loss': 0.9908, 'grad_norm': 7.775216579437256, 'learning_rate': 1e-05, 'epoch': 6.88}
{'loss': 0.7797, 'grad_norm': 5.0523600578308105, 'learning_rate': 1e-05, 'epoch': 6.9}
{'loss': 0.8086, 'grad_norm': 11.540881156921387, 'learning_rate': 1e-05, 'epoch': 6.93}
{'loss': 0.8454, 'grad_norm': 6.355445384979248, 'learning_rate': 1e-05, 'epoch': 6.95}
{'loss': 0.8274, 'grad_norm': 4.738113880157471, 'learning_rate': 1e-05, 'epoch': 6.98}
{'eval_loss': 0.6670244336128235, 'eval_wer': 0.32459784808778097, 'eval_runtime': 1499.1714, 'eval_samples_per_second': 5.336, 'eval_steps_per_second': 5.336, 'epoch': 7.0}
{'loss': 0.8738, 'grad_norm': 3.3840107917785645, 'learning_rate': 1e-05, 'epoch': 7.0}
{'loss': 0.7037, 'grad_norm': 12.526901245117188, 'learning_rate': 1e-05, 'epoch': 7.03}
{'loss': 0.7835, 'grad_norm': 5.099891662597656, 'learning_rate': 1e-05, 'epoch': 7.05}
{'loss': 0.8183, 'grad_norm': 2.4550974369049072, 'learning_rate': 1e-05, 'epoch': 7.08}
{'loss': 0.8673, 'grad_norm': 6.259334564208984, 'learning_rate': 1e-05, 'epoch': 7.1}
{'loss': 0.809, 'grad_norm': 4.957773208618164, 'learning_rate': 1e-05, 'epoch': 7.13}
{'loss': 0.8442, 'grad_norm': 10.370320320129395, 'learning_rate': 1e-05, 'epoch': 7.15}
{'loss': 0.7779, 'grad_norm': 45.6270751953125, 'learning_rate': 1e-05, 'epoch': 7.18}
{'loss': 0.812, 'grad_norm': 2.808187484741211, 'learning_rate': 1e-05, 'epoch': 7.2}
{'loss': 0.7723, 'grad_norm': 5.677943706512451, 'learning_rate': 1e-05, 'epoch': 7.23}
{'loss': 0.7664, 'grad_norm': 5.585580825805664, 'learning_rate': 1e-05, 'epoch': 7.25}
{'loss': 0.8009, 'grad_norm': 6.307018756866455, 'learning_rate': 1e-05, 'epoch': 7.28}
{'loss': 0.7716, 'grad_norm': 7.112096309661865, 'learning_rate': 1e-05, 'epoch': 7.3}
{'loss': 0.8153, 'grad_norm': 5.854436874389648, 'learning_rate': 1e-05, 'epoch': 7.33}
{'loss': 0.8402, 'grad_norm': 5.655097484588623, 'learning_rate': 1e-05, 'epoch': 7.35}
{'loss': 0.7125, 'grad_norm': 5.935421943664551, 'learning_rate': 1e-05, 'epoch': 7.38}
{'loss': 0.8387, 'grad_norm': 6.281160831451416, 'learning_rate': 1e-05, 'epoch': 7.4}
{'loss': 0.8556, 'grad_norm': 5.83512020111084, 'learning_rate': 1e-05, 'epoch': 7.43}
{'loss': 0.7605, 'grad_norm': 3.3469791412353516, 'learning_rate': 1e-05, 'epoch': 7.45}
{'loss': 0.7526, 'grad_norm': 4.724814414978027, 'learning_rate': 1e-05, 'epoch': 7.48}
{'loss': 0.8286, 'grad_norm': 14.580925941467285, 'learning_rate': 1e-05, 'epoch': 7.5}
{'loss': 0.7443, 'grad_norm': 12.015874862670898, 'learning_rate': 1e-05, 'epoch': 7.53}
{'loss': 0.8244, 'grad_norm': 10.165340423583984, 'learning_rate': 1e-05, 'epoch': 7.55}
{'loss': 0.7983, 'grad_norm': 8.835436820983887, 'learning_rate': 1e-05, 'epoch': 7.58}
{'loss': 0.7667, 'grad_norm': 11.38309097290039, 'learning_rate': 1e-05, 'epoch': 7.6}
{'loss': 0.749, 'grad_norm': 7.1398725509643555, 'learning_rate': 1e-05, 'epoch': 7.63}
{'loss': 0.7374, 'grad_norm': 5.912690162658691, 'learning_rate': 1e-05, 'epoch': 7.65}
{'loss': 0.8046, 'grad_norm': 4.539579391479492, 'learning_rate': 1e-05, 'epoch': 7.68}
{'loss': 0.8276, 'grad_norm': 9.340696334838867, 'learning_rate': 1e-05, 'epoch': 7.7}
{'loss': 0.7644, 'grad_norm': 7.310265064239502, 'learning_rate': 1e-05, 'epoch': 7.73}
{'loss': 0.7595, 'grad_norm': 6.3492045402526855, 'learning_rate': 1e-05, 'epoch': 7.75}
{'loss': 0.838, 'grad_norm': 4.567686080932617, 'learning_rate': 1e-05, 'epoch': 7.78}
{'loss': 0.843, 'grad_norm': 4.297327518463135, 'learning_rate': 1e-05, 'epoch': 7.8}
{'loss': 0.8655, 'grad_norm': 8.01978588104248, 'learning_rate': 1e-05, 'epoch': 7.83}
{'loss': 0.8016, 'grad_norm': 7.93309211730957, 'learning_rate': 1e-05, 'epoch': 7.85}
{'loss': 0.8322, 'grad_norm': 3.386215925216675, 'learning_rate': 1e-05, 'epoch': 7.88}
{'loss': 0.8043, 'grad_norm': 9.07230281829834, 'learning_rate': 1e-05, 'epoch': 7.9}
{'loss': 0.813, 'grad_norm': 8.928791999816895, 'learning_rate': 1e-05, 'epoch': 7.93}
{'loss': 0.8062, 'grad_norm': 6.361561298370361, 'learning_rate': 1e-05, 'epoch': 7.95}
{'loss': 0.7671, 'grad_norm': 7.776446342468262, 'learning_rate': 1e-05, 'epoch': 7.98}
{'eval_loss': 0.6554244160652161, 'eval_wer': 0.32126877596676257, 'eval_runtime': 1496.9321, 'eval_samples_per_second': 5.344, 'eval_steps_per_second': 5.344, 'epoch': 8.0}
{'loss': 0.8595, 'grad_norm': 9.383138656616211, 'learning_rate': 1e-05, 'epoch': 8.0}
{'loss': 0.7724, 'grad_norm': 7.519474983215332, 'learning_rate': 1e-05, 'epoch': 8.03}
{'loss': 0.7802, 'grad_norm': 2.8398566246032715, 'learning_rate': 1e-05, 'epoch': 8.05}
{'loss': 0.7507, 'grad_norm': 7.2620320320129395, 'learning_rate': 1e-05, 'epoch': 8.08}
{'loss': 0.7635, 'grad_norm': 10.246879577636719, 'learning_rate': 1e-05, 'epoch': 8.1}
{'loss': 0.7642, 'grad_norm': 9.451974868774414, 'learning_rate': 1e-05, 'epoch': 8.13}
{'loss': 0.8232, 'grad_norm': 4.540338516235352, 'learning_rate': 1e-05, 'epoch': 8.15}
{'loss': 0.8417, 'grad_norm': 7.836170673370361, 'learning_rate': 1e-05, 'epoch': 8.18}
{'loss': 0.7506, 'grad_norm': 4.856947898864746, 'learning_rate': 1e-05, 'epoch': 8.2}
{'loss': 0.7283, 'grad_norm': 14.671890258789062, 'learning_rate': 1e-05, 'epoch': 8.23}
{'loss': 0.8126, 'grad_norm': 2.6119556427001953, 'learning_rate': 1e-05, 'epoch': 8.25}
{'loss': 0.7707, 'grad_norm': 6.034789085388184, 'learning_rate': 1e-05, 'epoch': 8.28}
{'loss': 0.8377, 'grad_norm': 7.615893840789795, 'learning_rate': 1e-05, 'epoch': 8.3}
{'loss': 0.7747, 'grad_norm': 2.824899911880493, 'learning_rate': 1e-05, 'epoch': 8.33}
{'loss': 0.7376, 'grad_norm': 8.181794166564941, 'learning_rate': 1e-05, 'epoch': 8.35}
{'loss': 0.8337, 'grad_norm': 5.093581199645996, 'learning_rate': 1e-05, 'epoch': 8.38}
{'loss': 0.8116, 'grad_norm': 30.014421463012695, 'learning_rate': 1e-05, 'epoch': 8.4}
{'loss': 0.782, 'grad_norm': 9.698492050170898, 'learning_rate': 1e-05, 'epoch': 8.43}
{'loss': 0.8148, 'grad_norm': 7.79881477355957, 'learning_rate': 1e-05, 'epoch': 8.45}
{'loss': 0.8131, 'grad_norm': 11.04390811920166, 'learning_rate': 1e-05, 'epoch': 8.48}
{'loss': 0.755, 'grad_norm': 6.405458450317383, 'learning_rate': 1e-05, 'epoch': 8.5}
{'loss': 0.7638, 'grad_norm': 27.774871826171875, 'learning_rate': 1e-05, 'epoch': 8.53}
{'loss': 0.8218, 'grad_norm': 7.545252799987793, 'learning_rate': 1e-05, 'epoch': 8.55}
{'loss': 0.7441, 'grad_norm': 4.043156147003174, 'learning_rate': 1e-05, 'epoch': 8.58}
{'loss': 0.7771, 'grad_norm': 10.863380432128906, 'learning_rate': 1e-05, 'epoch': 8.6}
{'loss': 0.8083, 'grad_norm': 6.712879180908203, 'learning_rate': 1e-05, 'epoch': 8.63}
{'loss': 0.8017, 'grad_norm': 5.552563190460205, 'learning_rate': 1e-05, 'epoch': 8.65}
{'loss': 0.7499, 'grad_norm': 5.1582255363464355, 'learning_rate': 1e-05, 'epoch': 8.68}
{'loss': 0.7486, 'grad_norm': 4.829563140869141, 'learning_rate': 1e-05, 'epoch': 8.7}
{'loss': 0.7856, 'grad_norm': 6.67438268661499, 'learning_rate': 1e-05, 'epoch': 8.73}
{'loss': 0.7877, 'grad_norm': 8.80881118774414, 'learning_rate': 1e-05, 'epoch': 8.75}
{'loss': 0.8198, 'grad_norm': 7.751294136047363, 'learning_rate': 1e-05, 'epoch': 8.78}
{'loss': 0.8608, 'grad_norm': 9.504813194274902, 'learning_rate': 1e-05, 'epoch': 8.8}
{'loss': 0.8052, 'grad_norm': 8.323271751403809, 'learning_rate': 1e-05, 'epoch': 8.83}
{'loss': 0.8212, 'grad_norm': 11.360245704650879, 'learning_rate': 1e-05, 'epoch': 8.85}
{'loss': 0.8524, 'grad_norm': 12.332881927490234, 'learning_rate': 1e-05, 'epoch': 8.88}
{'loss': 0.8062, 'grad_norm': 11.098873138427734, 'learning_rate': 1e-05, 'epoch': 8.9}
{'loss': 0.8343, 'grad_norm': 3.5710341930389404, 'learning_rate': 1e-05, 'epoch': 8.93}
{'loss': 0.7452, 'grad_norm': 3.2756898403167725, 'learning_rate': 1e-05, 'epoch': 8.95}
{'loss': 0.7529, 'grad_norm': 3.660662889480591, 'learning_rate': 1e-05, 'epoch': 8.98}
{'eval_loss': 0.6494365334510803, 'eval_wer': 0.3193112815596037, 'eval_runtime': 1494.8054, 'eval_samples_per_second': 5.352, 'eval_steps_per_second': 5.352, 'epoch': 9.0}
{'loss': 0.741, 'grad_norm': 9.963918685913086, 'learning_rate': 1e-05, 'epoch': 9.0}
{'loss': 0.7575, 'grad_norm': 5.3521342277526855, 'learning_rate': 1e-05, 'epoch': 9.03}
{'loss': 0.7712, 'grad_norm': 5.696120738983154, 'learning_rate': 1e-05, 'epoch': 9.05}
{'loss': 0.81, 'grad_norm': 6.687933921813965, 'learning_rate': 1e-05, 'epoch': 9.08}
{'loss': 0.7875, 'grad_norm': 6.532033920288086, 'learning_rate': 1e-05, 'epoch': 9.1}
{'loss': 0.7688, 'grad_norm': 22.95091438293457, 'learning_rate': 1e-05, 'epoch': 9.13}
{'loss': 0.7466, 'grad_norm': 5.508298873901367, 'learning_rate': 1e-05, 'epoch': 9.15}
{'loss': 0.8732, 'grad_norm': 4.305426120758057, 'learning_rate': 1e-05, 'epoch': 9.18}
{'loss': 0.7092, 'grad_norm': 6.292776107788086, 'learning_rate': 1e-05, 'epoch': 9.2}
{'loss': 0.6977, 'grad_norm': 4.916008472442627, 'learning_rate': 1e-05, 'epoch': 9.23}
{'loss': 0.7613, 'grad_norm': 7.314947605133057, 'learning_rate': 1e-05, 'epoch': 9.25}
{'loss': 0.742, 'grad_norm': 9.479952812194824, 'learning_rate': 1e-05, 'epoch': 9.28}
{'loss': 0.7607, 'grad_norm': 16.577667236328125, 'learning_rate': 1e-05, 'epoch': 9.3}
{'loss': 0.8039, 'grad_norm': 7.3569512367248535, 'learning_rate': 1e-05, 'epoch': 9.33}
{'loss': 0.8533, 'grad_norm': 12.41434383392334, 'learning_rate': 1e-05, 'epoch': 9.35}
{'loss': 0.7351, 'grad_norm': 4.454416751861572, 'learning_rate': 1e-05, 'epoch': 9.38}
{'loss': 0.7714, 'grad_norm': 9.310481071472168, 'learning_rate': 1e-05, 'epoch': 9.4}
{'loss': 0.7452, 'grad_norm': 5.168684959411621, 'learning_rate': 1e-05, 'epoch': 9.43}
{'loss': 0.7653, 'grad_norm': 3.5136115550994873, 'learning_rate': 1e-05, 'epoch': 9.45}
{'loss': 0.7494, 'grad_norm': 4.032932281494141, 'learning_rate': 1e-05, 'epoch': 9.48}
{'loss': 0.7387, 'grad_norm': 6.239902973175049, 'learning_rate': 1e-05, 'epoch': 9.5}
{'loss': 0.7835, 'grad_norm': 4.499138832092285, 'learning_rate': 1e-05, 'epoch': 9.53}
{'loss': 0.8328, 'grad_norm': 15.396510124206543, 'learning_rate': 1e-05, 'epoch': 9.55}
{'loss': 0.7923, 'grad_norm': 4.077426433563232, 'learning_rate': 1e-05, 'epoch': 9.58}
{'loss': 0.7539, 'grad_norm': 4.434985637664795, 'learning_rate': 1e-05, 'epoch': 9.6}
{'loss': 0.7866, 'grad_norm': 5.84529972076416, 'learning_rate': 1e-05, 'epoch': 9.63}
{'loss': 0.7518, 'grad_norm': 5.252582550048828, 'learning_rate': 1e-05, 'epoch': 9.65}
{'loss': 0.7896, 'grad_norm': 13.007280349731445, 'learning_rate': 1e-05, 'epoch': 9.68}
{'loss': 0.7973, 'grad_norm': 5.0865631103515625, 'learning_rate': 1e-05, 'epoch': 9.7}
{'loss': 0.8279, 'grad_norm': 17.387985229492188, 'learning_rate': 1e-05, 'epoch': 9.73}
{'loss': 0.8199, 'grad_norm': 7.487358570098877, 'learning_rate': 1e-05, 'epoch': 9.75}
{'loss': 0.7773, 'grad_norm': 7.116452693939209, 'learning_rate': 1e-05, 'epoch': 9.78}
{'loss': 0.766, 'grad_norm': 6.5860724449157715, 'learning_rate': 1e-05, 'epoch': 9.8}
{'loss': 0.7878, 'grad_norm': 5.436821460723877, 'learning_rate': 1e-05, 'epoch': 9.83}
{'loss': 0.8296, 'grad_norm': 10.908242225646973, 'learning_rate': 1e-05, 'epoch': 9.85}
{'loss': 0.79, 'grad_norm': 3.726179838180542, 'learning_rate': 1e-05, 'epoch': 9.88}
{'loss': 0.7748, 'grad_norm': 9.22131061553955, 'learning_rate': 1e-05, 'epoch': 9.9}
{'loss': 0.7751, 'grad_norm': 10.292887687683105, 'learning_rate': 1e-05, 'epoch': 9.93}
{'loss': 0.7733, 'grad_norm': 26.371536254882812, 'learning_rate': 1e-05, 'epoch': 9.95}
{'loss': 0.7773, 'grad_norm': 5.002995014190674, 'learning_rate': 1e-05, 'epoch': 9.98}
{'eval_loss': 0.6530643701553345, 'eval_wer': 0.3180329178651326, 'eval_runtime': 1502.0527, 'eval_samples_per_second': 5.326, 'eval_steps_per_second': 5.326, 'epoch': 10.0}
{'train_runtime': 19719.2894, 'train_samples_per_second': 16.224, 'train_steps_per_second': 2.028, 'train_loss': 0.8791525302513983, 'epoch': 10.0}
[ASR][Trainer Eval] {'eval_loss': 0.6530643701553345, 'eval_wer': 0.3180329178651326, 'eval_runtime': 1515.1554, 'eval_samples_per_second': 5.28, 'eval_steps_per_second': 5.28, 'epoch': 10.0}
[SER] Skipped (phase != 'all'/'ser').
n23g0002:3816499:3817362 [0] NCCL INFO [Service thread] Connection closed by localRank 0
n23g0002:3816499:4155476 [0] NCCL INFO comm 0x555cda341e30 rank 0 nranks 1 cudaDev 0 busId ad000 - Abort COMPLETE
[TRAIN][SER] Starting SER phase ...
[Setup] Using device: cuda
[Setup] no_cuda flag set to: False
[ASR] Skipped (phase != 'all'/'asr').
[SER] Loading model + extractor‚Ä¶
[SER] Starting from pretrained: models/pretrained/en
trainable params: 1,327,104 || all params: 96,295,560 || trainable%: 1.3782
[SER] Trainable parameters: 1327104 / 96295560
[SER] truncating to 102719 frames (~6.42s)
[SER] class counts: {4: 6792, 7: 1408, 3: 5556, 5: 6384, 0: 6044, 2: 4140, 1: 3500, 6: 768}
[SER] class weights: [0.7154202461242676, 1.2354285717010498, 1.0444444417953491, 0.7782577276229858, 0.6366313099861145, 0.677318274974823, 5.630208492279053, 3.0710227489471436]
[SER] Sanity loss (1 batch): 2.073026418685913
[SER] Starting training with HuggingFace Trainer‚Ä¶
n23g0002:4156417:4156417 [0] NCCL INFO Bootstrap : Using ib0:134.61.46.190<0>
n23g0002:4156417:4156417 [0] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation
n23g0002:4156417:4156417 [0] NCCL INFO cudaDriverVersion 12080
NCCL version 2.20.5+cuda12.4
n23g0002:4156417:4167670 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib0:134.61.46.190<0>
n23g0002:4156417:4167670 [0] NCCL INFO Using non-device net plugin version 0
n23g0002:4156417:4167670 [0] NCCL INFO Using network IB
n23g0002:4156417:4167670 [0] NCCL INFO DMA-BUF is available on GPU device 0
n23g0002:4156417:4167670 [0] NCCL INFO comm 0x557501db0c40 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId ad000 commId 0x653e6b392d854cc7 - Init START
n23g0002:4156417:4167670 [0] NCCL INFO comm 0x557501db0c40 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
n23g0002:4156417:4167670 [0] NCCL INFO Channel 00/32 :    0
n23g0002:4156417:4167670 [0] NCCL INFO Channel 01/32 :    0
n23g0002:4156417:4167670 [0] NCCL INFO Channel 02/32 :    0
n23g0002:4156417:4167670 [0] NCCL INFO Channel 03/32 :    0
n23g0002:4156417:4167670 [0] NCCL INFO Channel 04/32 :    0
n23g0002:4156417:4167670 [0] NCCL INFO Channel 05/32 :    0
n23g0002:4156417:4167670 [0] NCCL INFO Channel 06/32 :    0
n23g0002:4156417:4167670 [0] NCCL INFO Channel 07/32 :    0
n23g0002:4156417:4167670 [0] NCCL INFO Channel 08/32 :    0
n23g0002:4156417:4167670 [0] NCCL INFO Channel 09/32 :    0
n23g0002:4156417:4167670 [0] NCCL INFO Channel 10/32 :    0
n23g0002:4156417:4167670 [0] NCCL INFO Channel 11/32 :    0
n23g0002:4156417:4167670 [0] NCCL INFO Channel 12/32 :    0
n23g0002:4156417:4167670 [0] NCCL INFO Channel 13/32 :    0
n23g0002:4156417:4167670 [0] NCCL INFO Channel 14/32 :    0
n23g0002:4156417:4167670 [0] NCCL INFO Channel 15/32 :    0
n23g0002:4156417:4167670 [0] NCCL INFO Channel 16/32 :    0
n23g0002:4156417:4167670 [0] NCCL INFO Channel 17/32 :    0
n23g0002:4156417:4167670 [0] NCCL INFO Channel 18/32 :    0
n23g0002:4156417:4167670 [0] NCCL INFO Channel 19/32 :    0
n23g0002:4156417:4167670 [0] NCCL INFO Channel 20/32 :    0
n23g0002:4156417:4167670 [0] NCCL INFO Channel 21/32 :    0
n23g0002:4156417:4167670 [0] NCCL INFO Channel 22/32 :    0
n23g0002:4156417:4167670 [0] NCCL INFO Channel 23/32 :    0
n23g0002:4156417:4167670 [0] NCCL INFO Channel 24/32 :    0
n23g0002:4156417:4167670 [0] NCCL INFO Channel 25/32 :    0
n23g0002:4156417:4167670 [0] NCCL INFO Channel 26/32 :    0
n23g0002:4156417:4167670 [0] NCCL INFO Channel 27/32 :    0
n23g0002:4156417:4167670 [0] NCCL INFO Channel 28/32 :    0
n23g0002:4156417:4167670 [0] NCCL INFO Channel 29/32 :    0
n23g0002:4156417:4167670 [0] NCCL INFO Channel 30/32 :    0
n23g0002:4156417:4167670 [0] NCCL INFO Channel 31/32 :    0
n23g0002:4156417:4167670 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
n23g0002:4156417:4167670 [0] NCCL INFO P2P Chunksize set to 131072
n23g0002:4156417:4167670 [0] NCCL INFO Connected all rings
n23g0002:4156417:4167670 [0] NCCL INFO Connected all trees
n23g0002:4156417:4167670 [0] NCCL INFO 32 coll channels, 0 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
n23g0002:4156417:4167670 [0] NCCL INFO comm 0x557501db0c40 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId ad000 commId 0x653e6b392d854cc7 - Init COMPLETE
n23g0002:4156417:4167673 [0] NCCL INFO [Service thread] Connection closed by localRank 0
n23g0002:4156417:4168004 [0] NCCL INFO comm 0x557501db0c40 rank 0 nranks 1 cudaDev 0 busId ad000 - Abort COMPLETE
