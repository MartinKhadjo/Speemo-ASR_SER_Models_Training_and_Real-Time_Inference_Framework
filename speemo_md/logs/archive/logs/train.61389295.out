[DIST] MASTER_ADDR=n23g0017 MASTER_PORT=29500 NNODES=1 GPUS_PER_NODE=1
[PRE] Skipping all preprocessing (skip_preprocessing=on or all per-step toggles are 'on')
[TRAIN][ASR] Starting ASR phase ...
[Setup] Using device: cuda
[Setup] no_cuda flag set to: False
[ASR] Loading model + processor‚Ä¶
[ASR] Starting from pretrained: models/pretrained/en
trainable params: 589,824 || all params: 94,986,144 || trainable%: 0.6210
[ASR] Trainable parameters: 589824 / 94986144
üõ†Ô∏è  Debug collator output shapes: {'input_values': torch.Size([4, 75264]), 'attention_mask': torch.Size([4, 75264]), 'labels': torch.Size([4, 93])}
[ASR] Starting training with HuggingFace Trainer‚Ä¶
n23g0017:3522054:3522054 [0] NCCL INFO Bootstrap : Using ib0:134.61.46.213<0>
n23g0017:3522054:3522054 [0] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation
n23g0017:3522054:3522054 [0] NCCL INFO cudaDriverVersion 12080
NCCL version 2.20.5+cuda12.4
n23g0017:3522054:3522180 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib0:134.61.46.213<0>
n23g0017:3522054:3522180 [0] NCCL INFO Using non-device net plugin version 0
n23g0017:3522054:3522180 [0] NCCL INFO Using network IB
n23g0017:3522054:3522180 [0] NCCL INFO DMA-BUF is available on GPU device 0
n23g0017:3522054:3522180 [0] NCCL INFO comm 0x55e2eb7cc5d0 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 9d000 commId 0x29854ddfba8ebb78 - Init START
n23g0017:3522054:3522180 [0] NCCL INFO comm 0x55e2eb7cc5d0 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
n23g0017:3522054:3522180 [0] NCCL INFO Channel 00/32 :    0
n23g0017:3522054:3522180 [0] NCCL INFO Channel 01/32 :    0
n23g0017:3522054:3522180 [0] NCCL INFO Channel 02/32 :    0
n23g0017:3522054:3522180 [0] NCCL INFO Channel 03/32 :    0
n23g0017:3522054:3522180 [0] NCCL INFO Channel 04/32 :    0
n23g0017:3522054:3522180 [0] NCCL INFO Channel 05/32 :    0
n23g0017:3522054:3522180 [0] NCCL INFO Channel 06/32 :    0
n23g0017:3522054:3522180 [0] NCCL INFO Channel 07/32 :    0
n23g0017:3522054:3522180 [0] NCCL INFO Channel 08/32 :    0
n23g0017:3522054:3522180 [0] NCCL INFO Channel 09/32 :    0
n23g0017:3522054:3522180 [0] NCCL INFO Channel 10/32 :    0
n23g0017:3522054:3522180 [0] NCCL INFO Channel 11/32 :    0
n23g0017:3522054:3522180 [0] NCCL INFO Channel 12/32 :    0
n23g0017:3522054:3522180 [0] NCCL INFO Channel 13/32 :    0
n23g0017:3522054:3522180 [0] NCCL INFO Channel 14/32 :    0
n23g0017:3522054:3522180 [0] NCCL INFO Channel 15/32 :    0
n23g0017:3522054:3522180 [0] NCCL INFO Channel 16/32 :    0
n23g0017:3522054:3522180 [0] NCCL INFO Channel 17/32 :    0
n23g0017:3522054:3522180 [0] NCCL INFO Channel 18/32 :    0
n23g0017:3522054:3522180 [0] NCCL INFO Channel 19/32 :    0
n23g0017:3522054:3522180 [0] NCCL INFO Channel 20/32 :    0
n23g0017:3522054:3522180 [0] NCCL INFO Channel 21/32 :    0
n23g0017:3522054:3522180 [0] NCCL INFO Channel 22/32 :    0
n23g0017:3522054:3522180 [0] NCCL INFO Channel 23/32 :    0
n23g0017:3522054:3522180 [0] NCCL INFO Channel 24/32 :    0
n23g0017:3522054:3522180 [0] NCCL INFO Channel 25/32 :    0
n23g0017:3522054:3522180 [0] NCCL INFO Channel 26/32 :    0
n23g0017:3522054:3522180 [0] NCCL INFO Channel 27/32 :    0
n23g0017:3522054:3522180 [0] NCCL INFO Channel 28/32 :    0
n23g0017:3522054:3522180 [0] NCCL INFO Channel 29/32 :    0
n23g0017:3522054:3522180 [0] NCCL INFO Channel 30/32 :    0
n23g0017:3522054:3522180 [0] NCCL INFO Channel 31/32 :    0
n23g0017:3522054:3522180 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
n23g0017:3522054:3522180 [0] NCCL INFO P2P Chunksize set to 131072
n23g0017:3522054:3522180 [0] NCCL INFO Connected all rings
n23g0017:3522054:3522180 [0] NCCL INFO Connected all trees
n23g0017:3522054:3522180 [0] NCCL INFO 32 coll channels, 0 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
n23g0017:3522054:3522180 [0] NCCL INFO comm 0x55e2eb7cc5d0 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 9d000 commId 0x29854ddfba8ebb78 - Init COMPLETE
{'loss': 2.1461, 'grad_norm': 2.9825470447540283, 'learning_rate': 0.0, 'epoch': 0.0}
{'loss': 1.6782, 'grad_norm': 4.755218982696533, 'learning_rate': 2.4256064016004e-07, 'epoch': 0.03}
{'loss': 1.6982, 'grad_norm': 3.6805973052978516, 'learning_rate': 4.926231557889473e-07, 'epoch': 0.05}
{'loss': 1.6529, 'grad_norm': 2.3814797401428223, 'learning_rate': 7.401850462615655e-07, 'epoch': 0.08}
{'loss': 1.5788, 'grad_norm': 1.5959129333496094, 'learning_rate': 9.902475618904727e-07, 'epoch': 0.1}
{'loss': 1.5487, 'grad_norm': 3.2225542068481445, 'learning_rate': 1.2403100775193799e-06, 'epoch': 0.13}
{'loss': 1.5317, 'grad_norm': 5.023464202880859, 'learning_rate': 1.490372593148287e-06, 'epoch': 0.15}
{'loss': 1.5559, 'grad_norm': 3.935551643371582, 'learning_rate': 1.7404351087771944e-06, 'epoch': 0.18}
{'loss': 1.6391, 'grad_norm': 2.611626625061035, 'learning_rate': 1.9904976244061016e-06, 'epoch': 0.2}
{'loss': 1.5728, 'grad_norm': 2.290224313735962, 'learning_rate': 2.2405601400350087e-06, 'epoch': 0.23}
{'loss': 1.5443, 'grad_norm': 3.8426761627197266, 'learning_rate': 2.4906226556639163e-06, 'epoch': 0.25}
{'loss': 1.5683, 'grad_norm': 3.564668893814087, 'learning_rate': 2.7406851712928235e-06, 'epoch': 0.28}
{'loss': 1.4415, 'grad_norm': 2.9847335815429688, 'learning_rate': 2.9907476869217307e-06, 'epoch': 0.3}
{'loss': 1.416, 'grad_norm': 11.348883628845215, 'learning_rate': 3.240810202550638e-06, 'epoch': 0.33}
{'loss': 1.363, 'grad_norm': 2.8376290798187256, 'learning_rate': 3.4908727181795454e-06, 'epoch': 0.35}
{'loss': 1.3283, 'grad_norm': 2.7068376541137695, 'learning_rate': 3.7409352338084526e-06, 'epoch': 0.38}
{'loss': 1.3283, 'grad_norm': 2.285351276397705, 'learning_rate': 3.99099774943736e-06, 'epoch': 0.4}
{'loss': 1.1846, 'grad_norm': 5.3069610595703125, 'learning_rate': 4.241060265066267e-06, 'epoch': 0.43}
{'loss': 1.1943, 'grad_norm': 4.859079837799072, 'learning_rate': 4.491122780695174e-06, 'epoch': 0.45}
{'loss': 1.2537, 'grad_norm': 12.556230545043945, 'learning_rate': 4.741185296324081e-06, 'epoch': 0.48}
{'loss': 1.246, 'grad_norm': 2.3522071838378906, 'learning_rate': 4.991247811952989e-06, 'epoch': 0.5}
{'loss': 1.1458, 'grad_norm': 6.608933925628662, 'learning_rate': 5.2413103275818955e-06, 'epoch': 0.53}
{'loss': 1.1722, 'grad_norm': 8.017232894897461, 'learning_rate': 5.491372843210802e-06, 'epoch': 0.55}
{'loss': 1.1014, 'grad_norm': 5.504336357116699, 'learning_rate': 5.741435358839711e-06, 'epoch': 0.58}
{'loss': 1.1821, 'grad_norm': 3.6683359146118164, 'learning_rate': 5.983995998999751e-06, 'epoch': 0.6}
{'loss': 1.1267, 'grad_norm': 3.2084994316101074, 'learning_rate': 6.234058514628658e-06, 'epoch': 0.63}
{'loss': 1.1664, 'grad_norm': 3.0932552814483643, 'learning_rate': 6.4841210302575655e-06, 'epoch': 0.65}
{'loss': 1.1183, 'grad_norm': 5.534992218017578, 'learning_rate': 6.734183545886472e-06, 'epoch': 0.68}
{'loss': 1.1638, 'grad_norm': 3.8378078937530518, 'learning_rate': 6.98424606151538e-06, 'epoch': 0.7}
{'loss': 1.1282, 'grad_norm': 3.4485151767730713, 'learning_rate': 7.2343085771442866e-06, 'epoch': 0.73}
{'loss': 1.0667, 'grad_norm': 5.87466287612915, 'learning_rate': 7.484371092773194e-06, 'epoch': 0.75}
{'loss': 1.0766, 'grad_norm': 10.129746437072754, 'learning_rate': 7.734433608402101e-06, 'epoch': 0.78}
{'loss': 1.053, 'grad_norm': 2.2889416217803955, 'learning_rate': 7.984496124031008e-06, 'epoch': 0.8}
{'loss': 1.1297, 'grad_norm': 4.12205696105957, 'learning_rate': 8.234558639659916e-06, 'epoch': 0.83}
{'loss': 1.0912, 'grad_norm': 4.224928379058838, 'learning_rate': 8.484621155288823e-06, 'epoch': 0.85}
{'loss': 1.0172, 'grad_norm': 3.4680733680725098, 'learning_rate': 8.73468367091773e-06, 'epoch': 0.88}
{'loss': 1.0512, 'grad_norm': 4.292543411254883, 'learning_rate': 8.984746186546638e-06, 'epoch': 0.9}
{'loss': 1.0093, 'grad_norm': 4.688656806945801, 'learning_rate': 9.234808702175545e-06, 'epoch': 0.93}
{'loss': 1.0958, 'grad_norm': 3.5619335174560547, 'learning_rate': 9.484871217804451e-06, 'epoch': 0.95}
{'loss': 0.9397, 'grad_norm': 10.660649299621582, 'learning_rate': 9.73493373343336e-06, 'epoch': 0.98}
{'eval_loss': 0.8076485395431519, 'eval_wer': 0.40348354106743367, 'eval_runtime': 1546.255, 'eval_samples_per_second': 5.174, 'eval_steps_per_second': 5.174, 'epoch': 1.0}
{'loss': 0.9555, 'grad_norm': 4.240288734436035, 'learning_rate': 9.984996249062267e-06, 'epoch': 1.0}
{'loss': 1.0334, 'grad_norm': 3.911583423614502, 'learning_rate': 1e-05, 'epoch': 1.03}
{'loss': 0.867, 'grad_norm': 17.783491134643555, 'learning_rate': 1e-05, 'epoch': 1.05}
{'loss': 1.0092, 'grad_norm': 4.300201416015625, 'learning_rate': 1e-05, 'epoch': 1.08}
{'loss': 0.9986, 'grad_norm': 2.774202585220337, 'learning_rate': 1e-05, 'epoch': 1.1}
{'loss': 0.9503, 'grad_norm': 3.9087252616882324, 'learning_rate': 1e-05, 'epoch': 1.13}
{'loss': 1.0154, 'grad_norm': 7.833437919616699, 'learning_rate': 1e-05, 'epoch': 1.15}
{'loss': 0.9091, 'grad_norm': 2.9975454807281494, 'learning_rate': 1e-05, 'epoch': 1.18}
{'loss': 0.9566, 'grad_norm': 5.761847972869873, 'learning_rate': 1e-05, 'epoch': 1.2}
{'loss': 0.9659, 'grad_norm': 3.8153812885284424, 'learning_rate': 1e-05, 'epoch': 1.23}
{'loss': 0.8998, 'grad_norm': 12.3497314453125, 'learning_rate': 1e-05, 'epoch': 1.25}
{'loss': 0.9646, 'grad_norm': 18.136335372924805, 'learning_rate': 1e-05, 'epoch': 1.28}
{'loss': 0.8918, 'grad_norm': 3.4689507484436035, 'learning_rate': 1e-05, 'epoch': 1.3}
{'loss': 0.9851, 'grad_norm': 8.03482723236084, 'learning_rate': 1e-05, 'epoch': 1.33}
{'loss': 0.8786, 'grad_norm': 5.927891254425049, 'learning_rate': 1e-05, 'epoch': 1.35}
{'loss': 0.9396, 'grad_norm': 28.80967140197754, 'learning_rate': 1e-05, 'epoch': 1.38}
{'loss': 0.9662, 'grad_norm': 104.937744140625, 'learning_rate': 1e-05, 'epoch': 1.4}
{'loss': 0.9154, 'grad_norm': 5.045021057128906, 'learning_rate': 1e-05, 'epoch': 1.43}
{'loss': 0.9548, 'grad_norm': 3.94119930267334, 'learning_rate': 1e-05, 'epoch': 1.45}
{'loss': 0.9796, 'grad_norm': 3.0173444747924805, 'learning_rate': 1e-05, 'epoch': 1.48}
{'loss': 0.9169, 'grad_norm': 5.887847900390625, 'learning_rate': 1e-05, 'epoch': 1.5}
{'loss': 0.9408, 'grad_norm': 2.6916236877441406, 'learning_rate': 1e-05, 'epoch': 1.53}
{'loss': 0.857, 'grad_norm': 4.968419075012207, 'learning_rate': 1e-05, 'epoch': 1.55}
{'loss': 1.2631, 'grad_norm': 6.195257186889648, 'learning_rate': 1e-05, 'epoch': 1.58}
{'loss': 0.9274, 'grad_norm': 3.9116530418395996, 'learning_rate': 1e-05, 'epoch': 1.6}
{'loss': 0.8499, 'grad_norm': 7.31978178024292, 'learning_rate': 1e-05, 'epoch': 1.63}
{'loss': 0.9614, 'grad_norm': 7.497460842132568, 'learning_rate': 1e-05, 'epoch': 1.65}
{'loss': 0.956, 'grad_norm': 8.805717468261719, 'learning_rate': 1e-05, 'epoch': 1.68}
{'loss': 0.9032, 'grad_norm': 4.368006229400635, 'learning_rate': 1e-05, 'epoch': 1.7}
{'loss': 0.9905, 'grad_norm': 6.28475284576416, 'learning_rate': 1e-05, 'epoch': 1.73}
{'loss': 0.9329, 'grad_norm': 2.237218141555786, 'learning_rate': 1e-05, 'epoch': 1.75}
{'loss': 0.9776, 'grad_norm': 9.495841979980469, 'learning_rate': 1e-05, 'epoch': 1.78}
{'loss': 0.8727, 'grad_norm': 9.181235313415527, 'learning_rate': 1e-05, 'epoch': 1.8}
{'loss': 0.8967, 'grad_norm': 5.819039344787598, 'learning_rate': 1e-05, 'epoch': 1.83}
{'loss': 1.0018, 'grad_norm': 5.4545183181762695, 'learning_rate': 1e-05, 'epoch': 1.85}
{'loss': 0.8511, 'grad_norm': 7.668632984161377, 'learning_rate': 1e-05, 'epoch': 1.88}
{'loss': 1.0219, 'grad_norm': 3.31841778755188, 'learning_rate': 1e-05, 'epoch': 1.9}
{'loss': 0.9419, 'grad_norm': 3.6100056171417236, 'learning_rate': 1e-05, 'epoch': 1.93}
{'loss': 0.938, 'grad_norm': 7.322479248046875, 'learning_rate': 1e-05, 'epoch': 1.95}
{'loss': 0.8888, 'grad_norm': 12.601552963256836, 'learning_rate': 1e-05, 'epoch': 1.98}
{'eval_loss': 0.7349141836166382, 'eval_wer': 0.35700969425801643, 'eval_runtime': 1532.4518, 'eval_samples_per_second': 5.22, 'eval_steps_per_second': 5.22, 'epoch': 2.0}
{'loss': 0.9, 'grad_norm': 29.803205490112305, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.9107, 'grad_norm': 3.7601029872894287, 'learning_rate': 1e-05, 'epoch': 2.03}
{'loss': 0.8784, 'grad_norm': 6.072803497314453, 'learning_rate': 1e-05, 'epoch': 2.05}
{'loss': 0.8337, 'grad_norm': 6.424706935882568, 'learning_rate': 1e-05, 'epoch': 2.08}
{'loss': 0.8478, 'grad_norm': 7.2803144454956055, 'learning_rate': 1e-05, 'epoch': 2.1}
{'loss': 0.8812, 'grad_norm': 8.453300476074219, 'learning_rate': 1e-05, 'epoch': 2.13}
{'loss': 0.9191, 'grad_norm': 16.183679580688477, 'learning_rate': 1e-05, 'epoch': 2.15}
{'loss': 0.9141, 'grad_norm': 2.5295159816741943, 'learning_rate': 1e-05, 'epoch': 2.18}
{'loss': 0.8613, 'grad_norm': 13.62962532043457, 'learning_rate': 1e-05, 'epoch': 2.2}
{'loss': 0.8386, 'grad_norm': 8.422009468078613, 'learning_rate': 1e-05, 'epoch': 2.23}
{'loss': 0.8674, 'grad_norm': 2.2560317516326904, 'learning_rate': 1e-05, 'epoch': 2.25}
{'loss': 0.8792, 'grad_norm': 4.945773601531982, 'learning_rate': 1e-05, 'epoch': 2.28}
{'loss': 0.9014, 'grad_norm': 3.603142738342285, 'learning_rate': 1e-05, 'epoch': 2.3}
{'loss': 0.8684, 'grad_norm': 1.7536664009094238, 'learning_rate': 1e-05, 'epoch': 2.33}
{'loss': 0.9397, 'grad_norm': 10.403094291687012, 'learning_rate': 1e-05, 'epoch': 2.35}
{'loss': 0.8706, 'grad_norm': 6.105391025543213, 'learning_rate': 1e-05, 'epoch': 2.38}
{'loss': 0.8983, 'grad_norm': 10.685063362121582, 'learning_rate': 1e-05, 'epoch': 2.4}
{'loss': 0.964, 'grad_norm': 8.564258575439453, 'learning_rate': 1e-05, 'epoch': 2.43}
{'loss': 0.8556, 'grad_norm': 8.359393119812012, 'learning_rate': 1e-05, 'epoch': 2.45}
{'loss': 0.8241, 'grad_norm': 3.938964605331421, 'learning_rate': 1e-05, 'epoch': 2.48}
{'loss': 0.9334, 'grad_norm': 4.373220920562744, 'learning_rate': 1e-05, 'epoch': 2.5}
{'loss': 0.8859, 'grad_norm': 6.673357009887695, 'learning_rate': 1e-05, 'epoch': 2.53}
{'loss': 0.8905, 'grad_norm': 24.182750701904297, 'learning_rate': 1e-05, 'epoch': 2.55}
{'loss': 0.9115, 'grad_norm': 10.406646728515625, 'learning_rate': 1e-05, 'epoch': 2.58}
{'loss': 0.9188, 'grad_norm': 5.14341402053833, 'learning_rate': 1e-05, 'epoch': 2.6}
{'loss': 0.8896, 'grad_norm': 3.6018879413604736, 'learning_rate': 1e-05, 'epoch': 2.63}
{'loss': 0.9302, 'grad_norm': 3.70338773727417, 'learning_rate': 1e-05, 'epoch': 2.65}
{'loss': 0.8286, 'grad_norm': 3.8480327129364014, 'learning_rate': 1e-05, 'epoch': 2.68}
{'loss': 0.8701, 'grad_norm': 11.94513988494873, 'learning_rate': 1e-05, 'epoch': 2.7}
{'loss': 0.826, 'grad_norm': 7.278865337371826, 'learning_rate': 1e-05, 'epoch': 2.73}
{'loss': 0.9231, 'grad_norm': 2.9491186141967773, 'learning_rate': 1e-05, 'epoch': 2.75}
{'loss': 0.8897, 'grad_norm': 5.452823162078857, 'learning_rate': 1e-05, 'epoch': 2.78}
{'loss': 0.8474, 'grad_norm': 2.31735897064209, 'learning_rate': 1e-05, 'epoch': 2.8}
{'loss': 0.8483, 'grad_norm': 27.104164123535156, 'learning_rate': 1e-05, 'epoch': 2.83}
{'loss': 0.8809, 'grad_norm': 6.300384521484375, 'learning_rate': 1e-05, 'epoch': 2.85}
{'loss': 0.8888, 'grad_norm': 8.643012046813965, 'learning_rate': 1e-05, 'epoch': 2.88}
{'loss': 0.9823, 'grad_norm': 11.420337677001953, 'learning_rate': 1e-05, 'epoch': 2.9}
{'loss': 0.8228, 'grad_norm': 8.734042167663574, 'learning_rate': 1e-05, 'epoch': 2.93}
{'loss': 0.9366, 'grad_norm': 9.659646034240723, 'learning_rate': 1e-05, 'epoch': 2.95}
{'loss': 0.9614, 'grad_norm': 5.186944961547852, 'learning_rate': 1e-05, 'epoch': 2.98}
{'eval_loss': 0.6980555653572083, 'eval_wer': 0.3415361670395227, 'eval_runtime': 1522.9301, 'eval_samples_per_second': 5.253, 'eval_steps_per_second': 5.253, 'epoch': 3.0}
{'loss': 0.9047, 'grad_norm': 22.969167709350586, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.8004, 'grad_norm': 3.767167329788208, 'learning_rate': 1e-05, 'epoch': 3.03}
{'loss': 0.8266, 'grad_norm': 3.07584547996521, 'learning_rate': 1e-05, 'epoch': 3.05}
{'loss': 0.8184, 'grad_norm': 3.817329168319702, 'learning_rate': 1e-05, 'epoch': 3.08}
{'loss': 0.8704, 'grad_norm': 5.246702671051025, 'learning_rate': 1e-05, 'epoch': 3.1}
{'loss': 0.8902, 'grad_norm': 7.417078495025635, 'learning_rate': 1e-05, 'epoch': 3.13}
{'loss': 0.9469, 'grad_norm': 4.886355876922607, 'learning_rate': 1e-05, 'epoch': 3.15}
{'loss': 0.8971, 'grad_norm': 21.770572662353516, 'learning_rate': 1e-05, 'epoch': 3.18}
{'loss': 0.8843, 'grad_norm': 5.462986946105957, 'learning_rate': 1e-05, 'epoch': 3.2}
{'loss': 0.9042, 'grad_norm': 4.5136308670043945, 'learning_rate': 1e-05, 'epoch': 3.23}
{'loss': 0.8718, 'grad_norm': 7.854349136352539, 'learning_rate': 1e-05, 'epoch': 3.25}
{'loss': 0.9483, 'grad_norm': 7.169521808624268, 'learning_rate': 1e-05, 'epoch': 3.28}
{'loss': 0.8078, 'grad_norm': 10.096067428588867, 'learning_rate': 1e-05, 'epoch': 3.3}
{'loss': 0.7564, 'grad_norm': 11.150997161865234, 'learning_rate': 1e-05, 'epoch': 3.33}
{'loss': 0.862, 'grad_norm': 4.576751232147217, 'learning_rate': 1e-05, 'epoch': 3.35}
{'loss': 0.9148, 'grad_norm': 2.250598907470703, 'learning_rate': 1e-05, 'epoch': 3.38}
{'loss': 0.8842, 'grad_norm': 5.743730068206787, 'learning_rate': 1e-05, 'epoch': 3.4}
{'loss': 0.9043, 'grad_norm': 24.972482681274414, 'learning_rate': 1e-05, 'epoch': 3.43}
{'loss': 0.8454, 'grad_norm': 8.1560640335083, 'learning_rate': 1e-05, 'epoch': 3.45}
{'loss': 0.9099, 'grad_norm': 5.259487152099609, 'learning_rate': 1e-05, 'epoch': 3.48}
{'loss': 0.9005, 'grad_norm': 8.574039459228516, 'learning_rate': 1e-05, 'epoch': 3.5}
{'loss': 0.758, 'grad_norm': 5.6861958503723145, 'learning_rate': 1e-05, 'epoch': 3.53}
{'loss': 0.8599, 'grad_norm': 4.400865077972412, 'learning_rate': 1e-05, 'epoch': 3.55}
{'loss': 0.9478, 'grad_norm': 6.373908042907715, 'learning_rate': 1e-05, 'epoch': 3.58}
{'loss': 0.8122, 'grad_norm': 26.136247634887695, 'learning_rate': 1e-05, 'epoch': 3.6}
{'loss': 0.85, 'grad_norm': 7.202524662017822, 'learning_rate': 1e-05, 'epoch': 3.63}
{'loss': 0.9102, 'grad_norm': 11.684846878051758, 'learning_rate': 1e-05, 'epoch': 3.65}
{'loss': 0.7996, 'grad_norm': 3.4950015544891357, 'learning_rate': 1e-05, 'epoch': 3.68}
{'loss': 0.8295, 'grad_norm': 6.344917297363281, 'learning_rate': 1e-05, 'epoch': 3.7}
{'loss': 0.8573, 'grad_norm': 9.930868148803711, 'learning_rate': 1e-05, 'epoch': 3.73}
{'loss': 0.809, 'grad_norm': 7.047536373138428, 'learning_rate': 1e-05, 'epoch': 3.75}
{'loss': 0.9022, 'grad_norm': 3.1394717693328857, 'learning_rate': 1e-05, 'epoch': 3.78}
{'loss': 0.8238, 'grad_norm': 14.82589340209961, 'learning_rate': 1e-05, 'epoch': 3.8}
{'loss': 0.7868, 'grad_norm': 5.040980815887451, 'learning_rate': 1e-05, 'epoch': 3.83}
{'loss': 0.8461, 'grad_norm': 8.93468952178955, 'learning_rate': 1e-05, 'epoch': 3.85}
{'loss': 0.8624, 'grad_norm': 6.916131973266602, 'learning_rate': 1e-05, 'epoch': 3.88}
{'loss': 0.8428, 'grad_norm': 8.198407173156738, 'learning_rate': 1e-05, 'epoch': 3.9}
{'loss': 0.8466, 'grad_norm': 9.267224311828613, 'learning_rate': 1e-05, 'epoch': 3.93}
{'loss': 0.8689, 'grad_norm': 5.795090198516846, 'learning_rate': 1e-05, 'epoch': 3.95}
{'loss': 0.7936, 'grad_norm': 10.148588180541992, 'learning_rate': 1e-05, 'epoch': 3.98}
{'eval_loss': 0.6899345517158508, 'eval_wer': 0.3340124640460211, 'eval_runtime': 1523.3247, 'eval_samples_per_second': 5.252, 'eval_steps_per_second': 5.252, 'epoch': 4.0}
{'loss': 0.7704, 'grad_norm': 6.505032062530518, 'learning_rate': 1e-05, 'epoch': 4.0}
{'loss': 0.8248, 'grad_norm': 18.297714233398438, 'learning_rate': 1e-05, 'epoch': 4.03}
{'loss': 0.9265, 'grad_norm': 6.0633955001831055, 'learning_rate': 1e-05, 'epoch': 4.05}
{'loss': 0.8798, 'grad_norm': 4.787176132202148, 'learning_rate': 1e-05, 'epoch': 4.08}
{'loss': 0.8314, 'grad_norm': 4.139532566070557, 'learning_rate': 1e-05, 'epoch': 4.1}
{'loss': 0.8092, 'grad_norm': 4.383762836456299, 'learning_rate': 1e-05, 'epoch': 4.13}
{'loss': 0.7851, 'grad_norm': 10.618208885192871, 'learning_rate': 1e-05, 'epoch': 4.15}
{'loss': 0.8472, 'grad_norm': 4.687941074371338, 'learning_rate': 1e-05, 'epoch': 4.18}
{'loss': 0.8043, 'grad_norm': 10.608560562133789, 'learning_rate': 1e-05, 'epoch': 4.2}
{'loss': 0.7953, 'grad_norm': 3.4896533489227295, 'learning_rate': 1e-05, 'epoch': 4.23}
{'loss': 0.839, 'grad_norm': 3.9363853931427, 'learning_rate': 1e-05, 'epoch': 4.25}
{'loss': 0.8516, 'grad_norm': 4.660510063171387, 'learning_rate': 1e-05, 'epoch': 4.28}
{'loss': 0.8036, 'grad_norm': 7.425356864929199, 'learning_rate': 1e-05, 'epoch': 4.3}
{'loss': 0.8611, 'grad_norm': 5.125162124633789, 'learning_rate': 1e-05, 'epoch': 4.33}
{'loss': 0.8663, 'grad_norm': 7.347959518432617, 'learning_rate': 1e-05, 'epoch': 4.35}
{'loss': 0.8493, 'grad_norm': 8.89326286315918, 'learning_rate': 1e-05, 'epoch': 4.38}
{'loss': 0.792, 'grad_norm': 7.4007887840271, 'learning_rate': 1e-05, 'epoch': 4.4}
{'loss': 0.9254, 'grad_norm': 2.1231372356414795, 'learning_rate': 1e-05, 'epoch': 4.43}
{'loss': 0.8824, 'grad_norm': 6.148603916168213, 'learning_rate': 1e-05, 'epoch': 4.45}
{'loss': 0.8272, 'grad_norm': 7.4589619636535645, 'learning_rate': 1e-05, 'epoch': 4.48}
{'loss': 0.761, 'grad_norm': 6.462450981140137, 'learning_rate': 1e-05, 'epoch': 4.5}
{'loss': 0.9172, 'grad_norm': 8.996243476867676, 'learning_rate': 1e-05, 'epoch': 4.53}
{'loss': 0.8515, 'grad_norm': 12.22333812713623, 'learning_rate': 1e-05, 'epoch': 4.55}
{'loss': 0.8911, 'grad_norm': 15.992827415466309, 'learning_rate': 1e-05, 'epoch': 4.58}
{'loss': 0.8116, 'grad_norm': 9.948150634765625, 'learning_rate': 1e-05, 'epoch': 4.6}
{'loss': 0.8177, 'grad_norm': 4.191490650177002, 'learning_rate': 1e-05, 'epoch': 4.63}
{'loss': 0.803, 'grad_norm': 2.5423684120178223, 'learning_rate': 1e-05, 'epoch': 4.65}
{'loss': 0.7785, 'grad_norm': 11.10493278503418, 'learning_rate': 1e-05, 'epoch': 4.68}
{'loss': 0.8383, 'grad_norm': 7.374678134918213, 'learning_rate': 1e-05, 'epoch': 4.7}
{'loss': 0.8325, 'grad_norm': 9.479531288146973, 'learning_rate': 1e-05, 'epoch': 4.73}
{'loss': 0.7731, 'grad_norm': 5.926760196685791, 'learning_rate': 1e-05, 'epoch': 4.75}
{'loss': 0.8239, 'grad_norm': 5.880090713500977, 'learning_rate': 1e-05, 'epoch': 4.78}
{'loss': 0.8146, 'grad_norm': 11.629195213317871, 'learning_rate': 1e-05, 'epoch': 4.8}
{'loss': 0.8152, 'grad_norm': 6.159312725067139, 'learning_rate': 1e-05, 'epoch': 4.83}
{'loss': 0.8133, 'grad_norm': 5.219278812408447, 'learning_rate': 1e-05, 'epoch': 4.85}
{'loss': 0.8925, 'grad_norm': 2.8463706970214844, 'learning_rate': 1e-05, 'epoch': 4.88}
{'loss': 0.8279, 'grad_norm': 5.476505279541016, 'learning_rate': 1e-05, 'epoch': 4.9}
{'loss': 0.8911, 'grad_norm': 2.239743232727051, 'learning_rate': 1e-05, 'epoch': 4.93}
{'loss': 0.857, 'grad_norm': 6.055695056915283, 'learning_rate': 1e-05, 'epoch': 4.95}
{'loss': 0.8117, 'grad_norm': 3.532139778137207, 'learning_rate': 1e-05, 'epoch': 4.98}
{'eval_loss': 0.6779417991638184, 'eval_wer': 0.3285394694790668, 'eval_runtime': 1531.1363, 'eval_samples_per_second': 5.225, 'eval_steps_per_second': 5.225, 'epoch': 5.0}
{'loss': 0.8466, 'grad_norm': 7.325494766235352, 'learning_rate': 1e-05, 'epoch': 5.0}
{'loss': 0.8189, 'grad_norm': 9.003767013549805, 'learning_rate': 1e-05, 'epoch': 5.03}
{'loss': 0.9157, 'grad_norm': 8.284603118896484, 'learning_rate': 1e-05, 'epoch': 5.05}
{'loss': 0.7575, 'grad_norm': 7.89891242980957, 'learning_rate': 1e-05, 'epoch': 5.08}
{'loss': 0.7562, 'grad_norm': 3.694711446762085, 'learning_rate': 1e-05, 'epoch': 5.1}
{'loss': 0.8558, 'grad_norm': 6.226562023162842, 'learning_rate': 1e-05, 'epoch': 5.13}
{'loss': 0.8205, 'grad_norm': 6.643824577331543, 'learning_rate': 1e-05, 'epoch': 5.15}
{'loss': 0.877, 'grad_norm': 6.836577892303467, 'learning_rate': 1e-05, 'epoch': 5.18}
{'loss': 0.8468, 'grad_norm': 4.55650520324707, 'learning_rate': 1e-05, 'epoch': 5.2}
{'loss': 0.8066, 'grad_norm': 2.0931358337402344, 'learning_rate': 1e-05, 'epoch': 5.23}
{'loss': 0.8691, 'grad_norm': 17.753511428833008, 'learning_rate': 1e-05, 'epoch': 5.25}
{'loss': 0.8746, 'grad_norm': 9.087265014648438, 'learning_rate': 1e-05, 'epoch': 5.28}
{'loss': 0.7736, 'grad_norm': 5.421907424926758, 'learning_rate': 1e-05, 'epoch': 5.3}
{'loss': 0.85, 'grad_norm': 9.82066822052002, 'learning_rate': 1e-05, 'epoch': 5.33}
{'loss': 0.8057, 'grad_norm': 6.8071818351745605, 'learning_rate': 1e-05, 'epoch': 5.35}
{'loss': 0.7648, 'grad_norm': 3.7600667476654053, 'learning_rate': 1e-05, 'epoch': 5.38}
{'loss': 0.7762, 'grad_norm': 6.050307750701904, 'learning_rate': 1e-05, 'epoch': 5.4}
{'loss': 0.8775, 'grad_norm': 8.209394454956055, 'learning_rate': 1e-05, 'epoch': 5.43}
{'loss': 0.7905, 'grad_norm': 8.360298156738281, 'learning_rate': 1e-05, 'epoch': 5.45}
{'loss': 0.8068, 'grad_norm': 9.208783149719238, 'learning_rate': 1e-05, 'epoch': 5.48}
{'loss': 0.9226, 'grad_norm': 6.35434103012085, 'learning_rate': 1e-05, 'epoch': 5.5}
{'loss': 0.7741, 'grad_norm': 44.54052734375, 'learning_rate': 1e-05, 'epoch': 5.53}
{'loss': 0.7891, 'grad_norm': 8.000129699707031, 'learning_rate': 1e-05, 'epoch': 5.55}
{'loss': 0.7477, 'grad_norm': 4.792282581329346, 'learning_rate': 1e-05, 'epoch': 5.58}
{'loss': 0.7373, 'grad_norm': 11.756281852722168, 'learning_rate': 1e-05, 'epoch': 5.6}
{'loss': 0.7188, 'grad_norm': 5.963352203369141, 'learning_rate': 1e-05, 'epoch': 5.63}
{'loss': 0.882, 'grad_norm': 6.514285564422607, 'learning_rate': 1e-05, 'epoch': 5.65}
{'loss': 0.7291, 'grad_norm': 8.497920989990234, 'learning_rate': 1e-05, 'epoch': 5.68}
{'loss': 0.8442, 'grad_norm': 8.033249855041504, 'learning_rate': 1e-05, 'epoch': 5.7}
{'loss': 0.8213, 'grad_norm': 8.277728080749512, 'learning_rate': 1e-05, 'epoch': 5.73}
{'loss': 0.9783, 'grad_norm': 6.484860897064209, 'learning_rate': 1e-05, 'epoch': 5.75}
{'loss': 0.8577, 'grad_norm': 6.258637428283691, 'learning_rate': 1e-05, 'epoch': 5.78}
{'loss': 0.8634, 'grad_norm': 104.24897766113281, 'learning_rate': 1e-05, 'epoch': 5.8}
{'loss': 0.7672, 'grad_norm': 3.7336816787719727, 'learning_rate': 1e-05, 'epoch': 5.83}
{'loss': 0.9, 'grad_norm': 9.10012435913086, 'learning_rate': 1e-05, 'epoch': 5.85}
{'loss': 0.8133, 'grad_norm': 9.479357719421387, 'learning_rate': 1e-05, 'epoch': 5.88}
{'loss': 0.787, 'grad_norm': 6.114387512207031, 'learning_rate': 1e-05, 'epoch': 5.9}
{'loss': 0.8746, 'grad_norm': 8.775789260864258, 'learning_rate': 1e-05, 'epoch': 5.93}
{'loss': 0.7852, 'grad_norm': 10.779071807861328, 'learning_rate': 1e-05, 'epoch': 5.95}
{'loss': 0.7871, 'grad_norm': 7.637759208679199, 'learning_rate': 1e-05, 'epoch': 5.98}
{'eval_loss': 0.6694983839988708, 'eval_wer': 0.32587621178225207, 'eval_runtime': 1535.2526, 'eval_samples_per_second': 5.211, 'eval_steps_per_second': 5.211, 'epoch': 6.0}
{'loss': 0.781, 'grad_norm': 3.4886152744293213, 'learning_rate': 1e-05, 'epoch': 6.0}
{'loss': 0.821, 'grad_norm': 10.588462829589844, 'learning_rate': 1e-05, 'epoch': 6.03}
{'loss': 0.8229, 'grad_norm': 9.82584285736084, 'learning_rate': 1e-05, 'epoch': 6.05}
{'loss': 0.8149, 'grad_norm': 5.570016860961914, 'learning_rate': 1e-05, 'epoch': 6.08}
{'loss': 0.8087, 'grad_norm': 6.913758277893066, 'learning_rate': 1e-05, 'epoch': 6.1}
{'loss': 0.8242, 'grad_norm': 1.999251127243042, 'learning_rate': 1e-05, 'epoch': 6.13}
{'loss': 0.7505, 'grad_norm': 19.521921157836914, 'learning_rate': 1e-05, 'epoch': 6.15}
{'loss': 0.848, 'grad_norm': 8.020097732543945, 'learning_rate': 1e-05, 'epoch': 6.18}
{'loss': 0.881, 'grad_norm': 6.968020915985107, 'learning_rate': 1e-05, 'epoch': 6.2}
{'loss': 0.7696, 'grad_norm': 5.378087520599365, 'learning_rate': 1e-05, 'epoch': 6.23}
{'loss': 0.7534, 'grad_norm': 8.463010787963867, 'learning_rate': 1e-05, 'epoch': 6.25}
{'loss': 0.8765, 'grad_norm': 4.955852508544922, 'learning_rate': 1e-05, 'epoch': 6.28}
{'loss': 0.7896, 'grad_norm': 21.23603057861328, 'learning_rate': 1e-05, 'epoch': 6.3}
{'loss': 0.8416, 'grad_norm': 21.01866912841797, 'learning_rate': 1e-05, 'epoch': 6.33}
{'loss': 0.8369, 'grad_norm': 5.577583312988281, 'learning_rate': 1e-05, 'epoch': 6.35}
{'loss': 0.792, 'grad_norm': 8.024296760559082, 'learning_rate': 1e-05, 'epoch': 6.38}
{'loss': 0.8192, 'grad_norm': 4.359531402587891, 'learning_rate': 1e-05, 'epoch': 6.4}
{'loss': 0.8103, 'grad_norm': 8.564717292785645, 'learning_rate': 1e-05, 'epoch': 6.43}
{'loss': 0.7931, 'grad_norm': 15.140380859375, 'learning_rate': 1e-05, 'epoch': 6.45}
{'loss': 0.7487, 'grad_norm': 6.373995780944824, 'learning_rate': 1e-05, 'epoch': 6.48}
{'loss': 0.7199, 'grad_norm': 28.74928092956543, 'learning_rate': 1e-05, 'epoch': 6.5}
{'loss': 0.8177, 'grad_norm': 8.782469749450684, 'learning_rate': 1e-05, 'epoch': 6.53}
{'loss': 0.8272, 'grad_norm': 26.483436584472656, 'learning_rate': 1e-05, 'epoch': 6.55}
{'loss': 0.7623, 'grad_norm': 46.691734313964844, 'learning_rate': 1e-05, 'epoch': 6.58}
{'loss': 0.7572, 'grad_norm': 4.7515645027160645, 'learning_rate': 1e-05, 'epoch': 6.6}
{'loss': 0.7482, 'grad_norm': 6.683061599731445, 'learning_rate': 1e-05, 'epoch': 6.63}
{'loss': 0.8339, 'grad_norm': 8.595182418823242, 'learning_rate': 1e-05, 'epoch': 6.65}
{'loss': 0.8326, 'grad_norm': 3.5966739654541016, 'learning_rate': 1e-05, 'epoch': 6.68}
{'loss': 0.7612, 'grad_norm': 4.483942985534668, 'learning_rate': 1e-05, 'epoch': 6.7}
{'loss': 0.748, 'grad_norm': 5.37198543548584, 'learning_rate': 1e-05, 'epoch': 6.73}
{'loss': 0.8044, 'grad_norm': 6.149434566497803, 'learning_rate': 1e-05, 'epoch': 6.75}
{'loss': 0.7846, 'grad_norm': 11.838634490966797, 'learning_rate': 1e-05, 'epoch': 6.78}
{'loss': 0.8251, 'grad_norm': 7.378118515014648, 'learning_rate': 1e-05, 'epoch': 6.8}
{'loss': 0.7579, 'grad_norm': 5.185117244720459, 'learning_rate': 1e-05, 'epoch': 6.83}
{'loss': 0.7948, 'grad_norm': 7.259834289550781, 'learning_rate': 1e-05, 'epoch': 6.85}
{'loss': 0.9967, 'grad_norm': 6.466377258300781, 'learning_rate': 1e-05, 'epoch': 6.88}
{'loss': 0.7819, 'grad_norm': 5.317561626434326, 'learning_rate': 1e-05, 'epoch': 6.9}
{'loss': 0.8118, 'grad_norm': 11.438703536987305, 'learning_rate': 1e-05, 'epoch': 6.93}
{'loss': 0.8508, 'grad_norm': 6.862860202789307, 'learning_rate': 1e-05, 'epoch': 6.95}
{'loss': 0.8273, 'grad_norm': 7.052579402923584, 'learning_rate': 1e-05, 'epoch': 6.98}
{'eval_loss': 0.6606485247612, 'eval_wer': 0.3235724938745073, 'eval_runtime': 1541.9297, 'eval_samples_per_second': 5.188, 'eval_steps_per_second': 5.188, 'epoch': 7.0}
{'loss': 0.8785, 'grad_norm': 3.4565539360046387, 'learning_rate': 1e-05, 'epoch': 7.0}
{'loss': 0.7043, 'grad_norm': 13.869022369384766, 'learning_rate': 1e-05, 'epoch': 7.03}
{'loss': 0.7864, 'grad_norm': 5.494914531707764, 'learning_rate': 1e-05, 'epoch': 7.05}
{'loss': 0.8143, 'grad_norm': 2.734670639038086, 'learning_rate': 1e-05, 'epoch': 7.08}
{'loss': 0.8655, 'grad_norm': 7.0427632331848145, 'learning_rate': 1e-05, 'epoch': 7.1}
{'loss': 0.8109, 'grad_norm': 4.656350612640381, 'learning_rate': 1e-05, 'epoch': 7.13}
{'loss': 0.8446, 'grad_norm': 8.347199440002441, 'learning_rate': 1e-05, 'epoch': 7.15}
{'loss': 0.7779, 'grad_norm': inf, 'learning_rate': 1e-05, 'epoch': 7.18}
{'loss': 0.8162, 'grad_norm': 3.180330276489258, 'learning_rate': 1e-05, 'epoch': 7.2}
{'loss': 0.7727, 'grad_norm': 4.103745460510254, 'learning_rate': 1e-05, 'epoch': 7.23}
{'loss': 0.7685, 'grad_norm': 7.180490970611572, 'learning_rate': 1e-05, 'epoch': 7.25}
{'loss': 0.8023, 'grad_norm': 5.808171272277832, 'learning_rate': 1e-05, 'epoch': 7.28}
{'loss': 0.7716, 'grad_norm': 23.728313446044922, 'learning_rate': 1e-05, 'epoch': 7.3}
{'loss': 0.8138, 'grad_norm': 9.619221687316895, 'learning_rate': 1e-05, 'epoch': 7.33}
{'loss': 0.8446, 'grad_norm': 6.463379859924316, 'learning_rate': 1e-05, 'epoch': 7.35}
{'loss': 0.7136, 'grad_norm': 5.586499214172363, 'learning_rate': 1e-05, 'epoch': 7.38}
{'loss': 0.8391, 'grad_norm': 5.4461259841918945, 'learning_rate': 1e-05, 'epoch': 7.4}
{'loss': 0.8581, 'grad_norm': 6.301866054534912, 'learning_rate': 1e-05, 'epoch': 7.43}
{'loss': 0.7624, 'grad_norm': 3.407762050628662, 'learning_rate': 1e-05, 'epoch': 7.45}
{'loss': 0.7479, 'grad_norm': 4.852602958679199, 'learning_rate': 1e-05, 'epoch': 7.48}
{'loss': 0.83, 'grad_norm': 5.1804938316345215, 'learning_rate': 1e-05, 'epoch': 7.5}
{'loss': 0.7461, 'grad_norm': 7.854973316192627, 'learning_rate': 1e-05, 'epoch': 7.53}
{'loss': 0.8277, 'grad_norm': 9.008085250854492, 'learning_rate': 1e-05, 'epoch': 7.55}
{'loss': 0.7998, 'grad_norm': 11.948343276977539, 'learning_rate': 1e-05, 'epoch': 7.58}
{'loss': 0.771, 'grad_norm': 7.022050380706787, 'learning_rate': 1e-05, 'epoch': 7.6}
{'loss': 0.7464, 'grad_norm': 8.00491714477539, 'learning_rate': 1e-05, 'epoch': 7.63}
{'loss': 0.7403, 'grad_norm': 7.397806167602539, 'learning_rate': 1e-05, 'epoch': 7.65}
{'loss': 0.7986, 'grad_norm': 13.473302841186523, 'learning_rate': 1e-05, 'epoch': 7.68}
{'loss': 0.8278, 'grad_norm': 8.945212364196777, 'learning_rate': 1e-05, 'epoch': 7.7}
{'loss': 0.7618, 'grad_norm': 6.29385232925415, 'learning_rate': 1e-05, 'epoch': 7.73}
{'loss': 0.7613, 'grad_norm': 8.5733060836792, 'learning_rate': 1e-05, 'epoch': 7.75}
{'loss': 0.8382, 'grad_norm': 3.8392438888549805, 'learning_rate': 1e-05, 'epoch': 7.78}
{'loss': 0.8446, 'grad_norm': 4.567451477050781, 'learning_rate': 1e-05, 'epoch': 7.8}
{'loss': 0.8638, 'grad_norm': 7.30805778503418, 'learning_rate': 1e-05, 'epoch': 7.83}
{'loss': 0.8036, 'grad_norm': 7.612547397613525, 'learning_rate': 1e-05, 'epoch': 7.85}
{'loss': 0.8361, 'grad_norm': 4.304435729980469, 'learning_rate': 1e-05, 'epoch': 7.88}
{'loss': 0.8062, 'grad_norm': 10.039786338806152, 'learning_rate': 1e-05, 'epoch': 7.9}
{'loss': 0.8142, 'grad_norm': 4.811247825622559, 'learning_rate': 1e-05, 'epoch': 7.93}
{'loss': 0.8093, 'grad_norm': 7.998593330383301, 'learning_rate': 1e-05, 'epoch': 7.95}
{'loss': 0.7637, 'grad_norm': 8.35715389251709, 'learning_rate': 1e-05, 'epoch': 7.98}
{'eval_loss': 0.6531323194503784, 'eval_wer': 0.32206775327580695, 'eval_runtime': 1533.9911, 'eval_samples_per_second': 5.215, 'eval_steps_per_second': 5.215, 'epoch': 8.0}
{'loss': 0.863, 'grad_norm': 7.782740116119385, 'learning_rate': 1e-05, 'epoch': 8.0}
{'loss': 0.7768, 'grad_norm': 6.571743488311768, 'learning_rate': 1e-05, 'epoch': 8.03}
{'loss': 0.7867, 'grad_norm': 2.172741174697876, 'learning_rate': 1e-05, 'epoch': 8.05}
{'loss': 0.7459, 'grad_norm': 26.39316749572754, 'learning_rate': 1e-05, 'epoch': 8.08}
{'loss': 0.7589, 'grad_norm': 8.210811614990234, 'learning_rate': 1e-05, 'epoch': 8.1}
{'loss': 0.7652, 'grad_norm': 7.249337196350098, 'learning_rate': 1e-05, 'epoch': 8.13}
{'loss': 0.8247, 'grad_norm': 4.741847038269043, 'learning_rate': 1e-05, 'epoch': 8.15}
{'loss': 0.8426, 'grad_norm': 9.11689281463623, 'learning_rate': 1e-05, 'epoch': 8.18}
{'loss': 0.7525, 'grad_norm': 5.647452354431152, 'learning_rate': 1e-05, 'epoch': 8.2}
{'loss': 0.7306, 'grad_norm': 13.174721717834473, 'learning_rate': 1e-05, 'epoch': 8.23}
{'loss': 0.8114, 'grad_norm': 2.5394115447998047, 'learning_rate': 1e-05, 'epoch': 8.25}
{'loss': 0.772, 'grad_norm': 8.3090238571167, 'learning_rate': 1e-05, 'epoch': 8.28}
{'loss': 0.8379, 'grad_norm': 7.555059432983398, 'learning_rate': 1e-05, 'epoch': 8.3}
{'loss': 0.7773, 'grad_norm': 2.6433815956115723, 'learning_rate': 1e-05, 'epoch': 8.33}
{'loss': 0.7393, 'grad_norm': 8.025959014892578, 'learning_rate': 1e-05, 'epoch': 8.35}
{'loss': 0.8358, 'grad_norm': 6.4986796379089355, 'learning_rate': 1e-05, 'epoch': 8.38}
{'loss': 0.8165, 'grad_norm': 12.954710006713867, 'learning_rate': 1e-05, 'epoch': 8.4}
{'loss': 0.7843, 'grad_norm': 10.072636604309082, 'learning_rate': 1e-05, 'epoch': 8.43}
{'loss': 0.8182, 'grad_norm': 13.265233039855957, 'learning_rate': 1e-05, 'epoch': 8.45}
{'loss': 0.8128, 'grad_norm': 8.117448806762695, 'learning_rate': 1e-05, 'epoch': 8.48}
{'loss': 0.7574, 'grad_norm': 6.5702314376831055, 'learning_rate': 1e-05, 'epoch': 8.5}
{'loss': 0.7618, 'grad_norm': 28.28297996520996, 'learning_rate': 1e-05, 'epoch': 8.53}
{'loss': 0.8232, 'grad_norm': 9.044692039489746, 'learning_rate': 1e-05, 'epoch': 8.55}
{'loss': 0.7454, 'grad_norm': 3.555054187774658, 'learning_rate': 1e-05, 'epoch': 8.58}
{'loss': 0.7803, 'grad_norm': 19.726970672607422, 'learning_rate': 1e-05, 'epoch': 8.6}
{'loss': 0.8122, 'grad_norm': 5.825517654418945, 'learning_rate': 1e-05, 'epoch': 8.63}
{'loss': 0.8009, 'grad_norm': 6.4225287437438965, 'learning_rate': 1e-05, 'epoch': 8.65}
{'loss': 0.7525, 'grad_norm': 8.434076309204102, 'learning_rate': 1e-05, 'epoch': 8.68}
{'loss': 0.7496, 'grad_norm': 5.848184108734131, 'learning_rate': 1e-05, 'epoch': 8.7}
{'loss': 0.7877, 'grad_norm': 7.777026176452637, 'learning_rate': 1e-05, 'epoch': 8.73}
{'loss': 0.7878, 'grad_norm': 8.293259620666504, 'learning_rate': 1e-05, 'epoch': 8.75}
{'loss': 0.8158, 'grad_norm': 4.941122055053711, 'learning_rate': 1e-05, 'epoch': 8.78}
{'loss': 0.8572, 'grad_norm': 7.278607368469238, 'learning_rate': 1e-05, 'epoch': 8.8}
{'loss': 0.8089, 'grad_norm': 7.937007427215576, 'learning_rate': 1e-05, 'epoch': 8.83}
{'loss': 0.8215, 'grad_norm': 12.306612014770508, 'learning_rate': 1e-05, 'epoch': 8.85}
{'loss': 0.8488, 'grad_norm': 8.212569236755371, 'learning_rate': 1e-05, 'epoch': 8.88}
{'loss': 0.8117, 'grad_norm': 7.961389541625977, 'learning_rate': 1e-05, 'epoch': 8.9}
{'loss': 0.8338, 'grad_norm': 2.614496946334839, 'learning_rate': 1e-05, 'epoch': 8.93}
{'loss': 0.7482, 'grad_norm': 4.055536270141602, 'learning_rate': 1e-05, 'epoch': 8.95}
{'loss': 0.7556, 'grad_norm': 4.630050182342529, 'learning_rate': 1e-05, 'epoch': 8.98}
{'eval_loss': 0.6501575112342834, 'eval_wer': 0.3197640353680622, 'eval_runtime': 1531.4408, 'eval_samples_per_second': 5.224, 'eval_steps_per_second': 5.224, 'epoch': 9.0}
{'loss': 0.7407, 'grad_norm': 11.964476585388184, 'learning_rate': 1e-05, 'epoch': 9.0}
{'loss': 0.7606, 'grad_norm': 6.556164741516113, 'learning_rate': 1e-05, 'epoch': 9.03}
{'loss': 0.7671, 'grad_norm': 6.9401164054870605, 'learning_rate': 1e-05, 'epoch': 9.05}
{'loss': 0.8116, 'grad_norm': 7.308189392089844, 'learning_rate': 1e-05, 'epoch': 9.08}
{'loss': 0.7884, 'grad_norm': 5.415844917297363, 'learning_rate': 1e-05, 'epoch': 9.1}
{'loss': 0.7708, 'grad_norm': 28.80897331237793, 'learning_rate': 1e-05, 'epoch': 9.13}
{'loss': 0.7434, 'grad_norm': 6.34160852432251, 'learning_rate': 1e-05, 'epoch': 9.15}
{'loss': 0.8762, 'grad_norm': 3.3234670162200928, 'learning_rate': 1e-05, 'epoch': 9.18}
{'loss': 0.7068, 'grad_norm': 7.016359806060791, 'learning_rate': 1e-05, 'epoch': 9.2}
{'loss': 0.6965, 'grad_norm': 4.273651123046875, 'learning_rate': 1e-05, 'epoch': 9.23}
{'loss': 0.7576, 'grad_norm': 5.258399963378906, 'learning_rate': 1e-05, 'epoch': 9.25}
{'loss': 0.7481, 'grad_norm': 5.730300426483154, 'learning_rate': 1e-05, 'epoch': 9.28}
{'loss': 0.7625, 'grad_norm': 15.023014068603516, 'learning_rate': 1e-05, 'epoch': 9.3}
{'loss': 0.7982, 'grad_norm': 6.382922649383545, 'learning_rate': 1e-05, 'epoch': 9.33}
{'loss': 0.8557, 'grad_norm': 13.282136917114258, 'learning_rate': 1e-05, 'epoch': 9.35}
{'loss': 0.7323, 'grad_norm': 5.135583877563477, 'learning_rate': 1e-05, 'epoch': 9.38}
{'loss': 0.7742, 'grad_norm': 9.882087707519531, 'learning_rate': 1e-05, 'epoch': 9.4}
{'loss': 0.7485, 'grad_norm': 4.159306526184082, 'learning_rate': 1e-05, 'epoch': 9.43}
{'loss': 0.7647, 'grad_norm': 69.24315643310547, 'learning_rate': 1e-05, 'epoch': 9.45}
{'loss': 0.7531, 'grad_norm': 5.1735358238220215, 'learning_rate': 1e-05, 'epoch': 9.48}
{'loss': 0.7418, 'grad_norm': 9.547750473022461, 'learning_rate': 1e-05, 'epoch': 9.5}
{'loss': 0.7837, 'grad_norm': 4.3581647872924805, 'learning_rate': 1e-05, 'epoch': 9.53}
{'loss': 0.8343, 'grad_norm': 13.80752944946289, 'learning_rate': 1e-05, 'epoch': 9.55}
{'loss': 0.7868, 'grad_norm': 3.4873790740966797, 'learning_rate': 1e-05, 'epoch': 9.58}
{'loss': 0.7542, 'grad_norm': 6.494719982147217, 'learning_rate': 1e-05, 'epoch': 9.6}
{'loss': 0.7923, 'grad_norm': 6.890563011169434, 'learning_rate': 1e-05, 'epoch': 9.63}
{'loss': 0.7537, 'grad_norm': 21.23115348815918, 'learning_rate': 1e-05, 'epoch': 9.65}
{'loss': 0.7931, 'grad_norm': 7.932255744934082, 'learning_rate': 1e-05, 'epoch': 9.68}
{'loss': 0.7915, 'grad_norm': 3.559993267059326, 'learning_rate': 1e-05, 'epoch': 9.7}
{'loss': 0.8324, 'grad_norm': 14.8367338180542, 'learning_rate': 1e-05, 'epoch': 9.73}
{'loss': 0.8143, 'grad_norm': 6.133200645446777, 'learning_rate': 1e-05, 'epoch': 9.75}
{'loss': 0.7798, 'grad_norm': 7.8155107498168945, 'learning_rate': 1e-05, 'epoch': 9.78}
{'loss': 0.7686, 'grad_norm': 6.723422050476074, 'learning_rate': 1e-05, 'epoch': 9.8}
{'loss': 0.7904, 'grad_norm': 5.282759189605713, 'learning_rate': 1e-05, 'epoch': 9.83}
{'loss': 0.8284, 'grad_norm': 10.655096054077148, 'learning_rate': 1e-05, 'epoch': 9.85}
{'loss': 0.7922, 'grad_norm': 11.386564254760742, 'learning_rate': 1e-05, 'epoch': 9.88}
{'loss': 0.781, 'grad_norm': 12.401636123657227, 'learning_rate': 1e-05, 'epoch': 9.9}
{'loss': 0.7748, 'grad_norm': 9.807464599609375, 'learning_rate': 1e-05, 'epoch': 9.93}
{'loss': 0.7758, 'grad_norm': 30.034515380859375, 'learning_rate': 1e-05, 'epoch': 9.95}
{'loss': 0.778, 'grad_norm': 5.85830545425415, 'learning_rate': 1e-05, 'epoch': 9.98}
{'eval_loss': 0.6518522500991821, 'eval_wer': 0.3185655694044956, 'eval_runtime': 1536.6291, 'eval_samples_per_second': 5.206, 'eval_steps_per_second': 5.206, 'epoch': 10.0}
{'train_runtime': 20168.8984, 'train_samples_per_second': 15.862, 'train_steps_per_second': 1.983, 'train_loss': 0.880009235898147, 'epoch': 10.0}
[ASR][Trainer Eval] {'eval_loss': 0.6518522500991821, 'eval_wer': 0.3185655694044956, 'eval_runtime': 1537.1508, 'eval_samples_per_second': 5.204, 'eval_steps_per_second': 5.204, 'epoch': 10.0}
[SER] Skipped (phase != 'all'/'ser').
n23g0017:3522054:3522183 [0] NCCL INFO [Service thread] Connection closed by localRank 0
n23g0017:3522054:3904849 [0] NCCL INFO comm 0x55e2eb7cc5d0 rank 0 nranks 1 cudaDev 0 busId 9d000 - Abort COMPLETE
[TRAIN][SER] Starting SER phase ...
[Setup] Using device: cuda
[Setup] no_cuda flag set to: False
[ASR] Skipped (phase != 'all'/'asr').
[SER] Loading model + extractor‚Ä¶
[SER] Starting from pretrained: models/pretrained/en
trainable params: 1,327,104 || all params: 96,295,560 || trainable%: 1.3782
[SER] Trainable parameters: 1327104 / 96295560
[SER] truncating to 102719 frames (~6.42s)
[SER] class counts: {4: 6792, 7: 1408, 3: 5556, 5: 6384, 0: 6044, 2: 4140, 1: 3500, 6: 768}
[SER] class weights: [0.7154202461242676, 1.2354285717010498, 1.0444444417953491, 0.7782577276229858, 0.6366313099861145, 0.677318274974823, 5.630208492279053, 3.0710227489471436]
[SER] Sanity loss (1 batch): 2.0899171829223633
[SER] Starting training with HuggingFace Trainer‚Ä¶
n23g0017:3904999:3904999 [0] NCCL INFO Bootstrap : Using ib0:134.61.46.213<0>
n23g0017:3904999:3904999 [0] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation
n23g0017:3904999:3904999 [0] NCCL INFO cudaDriverVersion 12080
NCCL version 2.20.5+cuda12.4
n23g0017:3904999:3941344 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib0:134.61.46.213<0>
n23g0017:3904999:3941344 [0] NCCL INFO Using non-device net plugin version 0
n23g0017:3904999:3941344 [0] NCCL INFO Using network IB
n23g0017:3904999:3941344 [0] NCCL INFO DMA-BUF is available on GPU device 0
n23g0017:3904999:3941344 [0] NCCL INFO comm 0x55a99dc382c0 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 9d000 commId 0x524512c099875368 - Init START
n23g0017:3904999:3941344 [0] NCCL INFO comm 0x55a99dc382c0 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
n23g0017:3904999:3941344 [0] NCCL INFO Channel 00/32 :    0
n23g0017:3904999:3941344 [0] NCCL INFO Channel 01/32 :    0
n23g0017:3904999:3941344 [0] NCCL INFO Channel 02/32 :    0
n23g0017:3904999:3941344 [0] NCCL INFO Channel 03/32 :    0
n23g0017:3904999:3941344 [0] NCCL INFO Channel 04/32 :    0
n23g0017:3904999:3941344 [0] NCCL INFO Channel 05/32 :    0
n23g0017:3904999:3941344 [0] NCCL INFO Channel 06/32 :    0
n23g0017:3904999:3941344 [0] NCCL INFO Channel 07/32 :    0
n23g0017:3904999:3941344 [0] NCCL INFO Channel 08/32 :    0
n23g0017:3904999:3941344 [0] NCCL INFO Channel 09/32 :    0
n23g0017:3904999:3941344 [0] NCCL INFO Channel 10/32 :    0
n23g0017:3904999:3941344 [0] NCCL INFO Channel 11/32 :    0
n23g0017:3904999:3941344 [0] NCCL INFO Channel 12/32 :    0
n23g0017:3904999:3941344 [0] NCCL INFO Channel 13/32 :    0
n23g0017:3904999:3941344 [0] NCCL INFO Channel 14/32 :    0
n23g0017:3904999:3941344 [0] NCCL INFO Channel 15/32 :    0
n23g0017:3904999:3941344 [0] NCCL INFO Channel 16/32 :    0
n23g0017:3904999:3941344 [0] NCCL INFO Channel 17/32 :    0
n23g0017:3904999:3941344 [0] NCCL INFO Channel 18/32 :    0
n23g0017:3904999:3941344 [0] NCCL INFO Channel 19/32 :    0
n23g0017:3904999:3941344 [0] NCCL INFO Channel 20/32 :    0
n23g0017:3904999:3941344 [0] NCCL INFO Channel 21/32 :    0
n23g0017:3904999:3941344 [0] NCCL INFO Channel 22/32 :    0
n23g0017:3904999:3941344 [0] NCCL INFO Channel 23/32 :    0
n23g0017:3904999:3941344 [0] NCCL INFO Channel 24/32 :    0
n23g0017:3904999:3941344 [0] NCCL INFO Channel 25/32 :    0
n23g0017:3904999:3941344 [0] NCCL INFO Channel 26/32 :    0
n23g0017:3904999:3941344 [0] NCCL INFO Channel 27/32 :    0
n23g0017:3904999:3941344 [0] NCCL INFO Channel 28/32 :    0
n23g0017:3904999:3941344 [0] NCCL INFO Channel 29/32 :    0
n23g0017:3904999:3941344 [0] NCCL INFO Channel 30/32 :    0
n23g0017:3904999:3941344 [0] NCCL INFO Channel 31/32 :    0
n23g0017:3904999:3941344 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
n23g0017:3904999:3941344 [0] NCCL INFO P2P Chunksize set to 131072
n23g0017:3904999:3941344 [0] NCCL INFO Connected all rings
n23g0017:3904999:3941344 [0] NCCL INFO Connected all trees
n23g0017:3904999:3941344 [0] NCCL INFO 32 coll channels, 0 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
n23g0017:3904999:3941344 [0] NCCL INFO comm 0x55a99dc382c0 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 9d000 commId 0x524512c099875368 - Init COMPLETE
n23g0017:3904999:3941347 [0] NCCL INFO [Service thread] Connection closed by localRank 0
n23g0017:3904999:3941492 [0] NCCL INFO comm 0x55a99dc382c0 rank 0 nranks 1 cudaDev 0 busId 9d000 - Abort COMPLETE
