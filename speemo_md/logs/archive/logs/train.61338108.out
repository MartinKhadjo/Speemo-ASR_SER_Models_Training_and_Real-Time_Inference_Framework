[DIST] MASTER_ADDR=n23g0002 MASTER_PORT=29500 NNODES=1 GPUS_PER_NODE=1
[PRE] Skipping all preprocessing (skip_preprocessing=on or all per-step toggles are 'on')
[TRAIN][ASR] Starting ASR phase ...
[Setup] Using device: cuda
[Setup] no_cuda flag set to: False
[ASR] Loading model + processor‚Ä¶
[ASR] Starting from pretrained: models/pretrained/en
trainable params: 589,824 || all params: 94,986,144 || trainable%: 0.6210
[ASR] Trainable parameters: 589824 / 94986144
üõ†Ô∏è  Debug collator output shapes: {'input_values': torch.Size([4, 75264]), 'attention_mask': torch.Size([4, 75264]), 'labels': torch.Size([4, 93])}
[ASR] Starting training with HuggingFace Trainer‚Ä¶
n23g0002:3522750:3522750 [0] NCCL INFO Bootstrap : Using ib0:134.61.46.190<0>
n23g0002:3522750:3522750 [0] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation
n23g0002:3522750:3522750 [0] NCCL INFO cudaDriverVersion 12080
NCCL version 2.20.5+cuda12.4
n23g0002:3522750:3522834 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib0:134.61.46.190<0>
n23g0002:3522750:3522834 [0] NCCL INFO Using non-device net plugin version 0
n23g0002:3522750:3522834 [0] NCCL INFO Using network IB
n23g0002:3522750:3522834 [0] NCCL INFO DMA-BUF is available on GPU device 0
n23g0002:3522750:3522834 [0] NCCL INFO comm 0x55fa829e6fc0 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId ad000 commId 0x9c386108c43af7c9 - Init START
n23g0002:3522750:3522834 [0] NCCL INFO comm 0x55fa829e6fc0 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
n23g0002:3522750:3522834 [0] NCCL INFO Channel 00/32 :    0
n23g0002:3522750:3522834 [0] NCCL INFO Channel 01/32 :    0
n23g0002:3522750:3522834 [0] NCCL INFO Channel 02/32 :    0
n23g0002:3522750:3522834 [0] NCCL INFO Channel 03/32 :    0
n23g0002:3522750:3522834 [0] NCCL INFO Channel 04/32 :    0
n23g0002:3522750:3522834 [0] NCCL INFO Channel 05/32 :    0
n23g0002:3522750:3522834 [0] NCCL INFO Channel 06/32 :    0
n23g0002:3522750:3522834 [0] NCCL INFO Channel 07/32 :    0
n23g0002:3522750:3522834 [0] NCCL INFO Channel 08/32 :    0
n23g0002:3522750:3522834 [0] NCCL INFO Channel 09/32 :    0
n23g0002:3522750:3522834 [0] NCCL INFO Channel 10/32 :    0
n23g0002:3522750:3522834 [0] NCCL INFO Channel 11/32 :    0
n23g0002:3522750:3522834 [0] NCCL INFO Channel 12/32 :    0
n23g0002:3522750:3522834 [0] NCCL INFO Channel 13/32 :    0
n23g0002:3522750:3522834 [0] NCCL INFO Channel 14/32 :    0
n23g0002:3522750:3522834 [0] NCCL INFO Channel 15/32 :    0
n23g0002:3522750:3522834 [0] NCCL INFO Channel 16/32 :    0
n23g0002:3522750:3522834 [0] NCCL INFO Channel 17/32 :    0
n23g0002:3522750:3522834 [0] NCCL INFO Channel 18/32 :    0
n23g0002:3522750:3522834 [0] NCCL INFO Channel 19/32 :    0
n23g0002:3522750:3522834 [0] NCCL INFO Channel 20/32 :    0
n23g0002:3522750:3522834 [0] NCCL INFO Channel 21/32 :    0
n23g0002:3522750:3522834 [0] NCCL INFO Channel 22/32 :    0
n23g0002:3522750:3522834 [0] NCCL INFO Channel 23/32 :    0
n23g0002:3522750:3522834 [0] NCCL INFO Channel 24/32 :    0
n23g0002:3522750:3522834 [0] NCCL INFO Channel 25/32 :    0
n23g0002:3522750:3522834 [0] NCCL INFO Channel 26/32 :    0
n23g0002:3522750:3522834 [0] NCCL INFO Channel 27/32 :    0
n23g0002:3522750:3522834 [0] NCCL INFO Channel 28/32 :    0
n23g0002:3522750:3522834 [0] NCCL INFO Channel 29/32 :    0
n23g0002:3522750:3522834 [0] NCCL INFO Channel 30/32 :    0
n23g0002:3522750:3522834 [0] NCCL INFO Channel 31/32 :    0
n23g0002:3522750:3522834 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
n23g0002:3522750:3522834 [0] NCCL INFO P2P Chunksize set to 131072
n23g0002:3522750:3522834 [0] NCCL INFO Connected all rings
n23g0002:3522750:3522834 [0] NCCL INFO Connected all trees
n23g0002:3522750:3522834 [0] NCCL INFO 32 coll channels, 0 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
n23g0002:3522750:3522834 [0] NCCL INFO comm 0x55fa829e6fc0 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId ad000 commId 0x9c386108c43af7c9 - Init COMPLETE
{'loss': 2.1461, 'grad_norm': 3.091655969619751, 'learning_rate': 0.0, 'epoch': 0.0}
{'loss': 1.6775, 'grad_norm': 4.344682693481445, 'learning_rate': 1.2125e-06, 'epoch': 0.03}
{'loss': 1.6881, 'grad_norm': 3.6780734062194824, 'learning_rate': 2.4500000000000003e-06, 'epoch': 0.05}
{'loss': 1.6144, 'grad_norm': 2.5080699920654297, 'learning_rate': 3.7e-06, 'epoch': 0.08}
{'loss': 1.4856, 'grad_norm': 2.177372932434082, 'learning_rate': 4.95e-06, 'epoch': 0.1}
{'loss': 1.3789, 'grad_norm': 2.2345798015594482, 'learning_rate': 6.200000000000001e-06, 'epoch': 0.13}
{'loss': 1.3094, 'grad_norm': 4.658982276916504, 'learning_rate': 7.450000000000001e-06, 'epoch': 0.15}
{'loss': 1.2959, 'grad_norm': 31.07847785949707, 'learning_rate': 8.700000000000001e-06, 'epoch': 0.18}
{'loss': 1.3256, 'grad_norm': 2.3513004779815674, 'learning_rate': 9.950000000000001e-06, 'epoch': 0.2}
{'loss': 1.2707, 'grad_norm': 2.445061445236206, 'learning_rate': 1e-05, 'epoch': 0.23}
{'loss': 1.2369, 'grad_norm': 6.170666694641113, 'learning_rate': 1e-05, 'epoch': 0.25}
{'loss': 1.2665, 'grad_norm': 5.630692481994629, 'learning_rate': 1e-05, 'epoch': 0.28}
{'loss': 1.1606, 'grad_norm': 5.697385311126709, 'learning_rate': 1e-05, 'epoch': 0.3}
{'loss': 1.1686, 'grad_norm': 5.5685882568359375, 'learning_rate': 1e-05, 'epoch': 0.33}
{'loss': 1.1337, 'grad_norm': 3.8063721656799316, 'learning_rate': 1e-05, 'epoch': 0.35}
{'loss': 1.0988, 'grad_norm': 3.3897974491119385, 'learning_rate': 1e-05, 'epoch': 0.38}
{'loss': 1.1028, 'grad_norm': 2.596597671508789, 'learning_rate': 1e-05, 'epoch': 0.4}
{'loss': 0.9714, 'grad_norm': 9.21833324432373, 'learning_rate': 1e-05, 'epoch': 0.43}
{'loss': 0.994, 'grad_norm': 5.748284816741943, 'learning_rate': 1e-05, 'epoch': 0.45}
{'loss': 1.0526, 'grad_norm': 5.894806861877441, 'learning_rate': 1e-05, 'epoch': 0.48}
{'loss': 1.0683, 'grad_norm': 2.252042770385742, 'learning_rate': 1e-05, 'epoch': 0.5}
{'loss': 0.951, 'grad_norm': 7.988333702087402, 'learning_rate': 1e-05, 'epoch': 0.53}
{'loss': 0.9993, 'grad_norm': 2.5354461669921875, 'learning_rate': 1e-05, 'epoch': 0.55}
{'loss': 0.9449, 'grad_norm': 6.47923469543457, 'learning_rate': 1e-05, 'epoch': 0.58}
{'loss': 1.0208, 'grad_norm': 5.688943386077881, 'learning_rate': 1e-05, 'epoch': 0.6}
{'loss': 0.9795, 'grad_norm': 3.129241466522217, 'learning_rate': 1e-05, 'epoch': 0.63}
{'loss': 1.0246, 'grad_norm': 3.2718505859375, 'learning_rate': 1e-05, 'epoch': 0.65}
{'loss': 1.0043, 'grad_norm': 6.233375072479248, 'learning_rate': 1e-05, 'epoch': 0.68}
{'loss': 1.0356, 'grad_norm': 7.863800048828125, 'learning_rate': 1e-05, 'epoch': 0.7}
{'loss': 1.0296, 'grad_norm': 3.7707138061523438, 'learning_rate': 1e-05, 'epoch': 0.73}
{'loss': 0.9693, 'grad_norm': 8.197272300720215, 'learning_rate': 1e-05, 'epoch': 0.75}
{'loss': 0.9713, 'grad_norm': 6.270444393157959, 'learning_rate': 1e-05, 'epoch': 0.78}
{'loss': 0.9594, 'grad_norm': 3.1692168712615967, 'learning_rate': 1e-05, 'epoch': 0.8}
{'loss': 1.0518, 'grad_norm': 5.189448833465576, 'learning_rate': 1e-05, 'epoch': 0.83}
{'loss': 1.0103, 'grad_norm': 4.002972602844238, 'learning_rate': 1e-05, 'epoch': 0.85}
{'loss': 0.9433, 'grad_norm': 4.500410079956055, 'learning_rate': 1e-05, 'epoch': 0.88}
{'loss': 0.9862, 'grad_norm': 6.396145820617676, 'learning_rate': 1e-05, 'epoch': 0.9}
{'loss': 0.9391, 'grad_norm': 3.5402700901031494, 'learning_rate': 1e-05, 'epoch': 0.93}
{'loss': 1.0311, 'grad_norm': 3.6003360748291016, 'learning_rate': 1e-05, 'epoch': 0.95}
{'loss': 0.8818, 'grad_norm': 13.98208236694336, 'learning_rate': 1e-05, 'epoch': 0.98}
{'eval_loss': 0.7587180137634277, 'eval_wer': 0.37972728241184617, 'eval_runtime': 1511.23, 'eval_samples_per_second': 5.294, 'eval_steps_per_second': 5.294, 'epoch': 1.0}
{'loss': 0.9084, 'grad_norm': 4.008682727813721, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 0.9703, 'grad_norm': 5.82153844833374, 'learning_rate': 1e-05, 'epoch': 1.03}
{'loss': 0.8182, 'grad_norm': 7.286570072174072, 'learning_rate': 1e-05, 'epoch': 1.05}
{'loss': 0.9622, 'grad_norm': 4.479415416717529, 'learning_rate': 1e-05, 'epoch': 1.08}
{'loss': 0.9469, 'grad_norm': 2.2082743644714355, 'learning_rate': 1e-05, 'epoch': 1.1}
{'loss': 0.9056, 'grad_norm': 4.332066535949707, 'learning_rate': 1e-05, 'epoch': 1.13}
{'loss': 0.9628, 'grad_norm': 6.066220760345459, 'learning_rate': 1e-05, 'epoch': 1.15}
{'loss': 0.871, 'grad_norm': 3.10959529876709, 'learning_rate': 1e-05, 'epoch': 1.18}
{'loss': 0.9143, 'grad_norm': 7.875391483306885, 'learning_rate': 1e-05, 'epoch': 1.2}
{'loss': 0.9271, 'grad_norm': 4.264708042144775, 'learning_rate': 1e-05, 'epoch': 1.23}
{'loss': 0.8702, 'grad_norm': 22.5722599029541, 'learning_rate': 1e-05, 'epoch': 1.25}
{'loss': 0.9236, 'grad_norm': 15.606061935424805, 'learning_rate': 1e-05, 'epoch': 1.28}
{'loss': 0.8558, 'grad_norm': 4.051851272583008, 'learning_rate': 1e-05, 'epoch': 1.3}
{'loss': 0.948, 'grad_norm': 6.766199588775635, 'learning_rate': 1e-05, 'epoch': 1.33}
{'loss': 0.8418, 'grad_norm': 3.6059932708740234, 'learning_rate': 1e-05, 'epoch': 1.35}
{'loss': 0.9084, 'grad_norm': 24.926074981689453, 'learning_rate': 1e-05, 'epoch': 1.38}
{'loss': 0.9368, 'grad_norm': 24.82041358947754, 'learning_rate': 1e-05, 'epoch': 1.4}
{'loss': 0.8813, 'grad_norm': 2.3482606410980225, 'learning_rate': 1e-05, 'epoch': 1.43}
{'loss': 0.9238, 'grad_norm': 5.344692230224609, 'learning_rate': 1e-05, 'epoch': 1.45}
{'loss': 0.9511, 'grad_norm': 3.344463586807251, 'learning_rate': 1e-05, 'epoch': 1.48}
{'loss': 0.8907, 'grad_norm': 7.8640055656433105, 'learning_rate': 1e-05, 'epoch': 1.5}
{'loss': 0.9107, 'grad_norm': 3.086611032485962, 'learning_rate': 1e-05, 'epoch': 1.53}
{'loss': 0.8269, 'grad_norm': 6.462836742401123, 'learning_rate': 1e-05, 'epoch': 1.55}
{'loss': 1.2361, 'grad_norm': 6.852678298950195, 'learning_rate': 1e-05, 'epoch': 1.58}
{'loss': 0.9027, 'grad_norm': 3.3257408142089844, 'learning_rate': 1e-05, 'epoch': 1.6}
{'loss': 0.8203, 'grad_norm': 5.74015474319458, 'learning_rate': 1e-05, 'epoch': 1.63}
{'loss': 0.9383, 'grad_norm': 11.009856224060059, 'learning_rate': 1e-05, 'epoch': 1.65}
{'loss': 0.9293, 'grad_norm': 9.027746200561523, 'learning_rate': 1e-05, 'epoch': 1.68}
{'loss': 0.8774, 'grad_norm': 8.123526573181152, 'learning_rate': 1e-05, 'epoch': 1.7}
{'loss': 0.9639, 'grad_norm': 5.004188537597656, 'learning_rate': 1e-05, 'epoch': 1.73}
{'loss': 0.9087, 'grad_norm': 3.2648496627807617, 'learning_rate': 1e-05, 'epoch': 1.75}
{'loss': 0.9481, 'grad_norm': 9.5396728515625, 'learning_rate': 1e-05, 'epoch': 1.78}
{'loss': 0.8482, 'grad_norm': 10.538714408874512, 'learning_rate': 1e-05, 'epoch': 1.8}
{'loss': 0.8744, 'grad_norm': 11.133420944213867, 'learning_rate': 1e-05, 'epoch': 1.83}
{'loss': 0.9811, 'grad_norm': 7.428272724151611, 'learning_rate': 1e-05, 'epoch': 1.85}
{'loss': 0.821, 'grad_norm': 6.468670845031738, 'learning_rate': 1e-05, 'epoch': 1.88}
{'loss': 1.0028, 'grad_norm': 3.3410565853118896, 'learning_rate': 1e-05, 'epoch': 1.9}
{'loss': 0.9194, 'grad_norm': 4.314653396606445, 'learning_rate': 1e-05, 'epoch': 1.93}
{'loss': 0.9152, 'grad_norm': 9.82615852355957, 'learning_rate': 1e-05, 'epoch': 1.95}
{'loss': 0.8638, 'grad_norm': 13.445265769958496, 'learning_rate': 1e-05, 'epoch': 1.98}
{'eval_loss': 0.7203278541564941, 'eval_wer': 0.3490066048790881, 'eval_runtime': 1495.9548, 'eval_samples_per_second': 5.348, 'eval_steps_per_second': 5.348, 'epoch': 2.0}
{'train_runtime': 3951.0227, 'train_samples_per_second': 16.194, 'train_steps_per_second': 2.024, 'train_loss': 1.0188558997735884, 'epoch': 2.0}
[ASR][Trainer Eval] {'eval_loss': 0.7203278541564941, 'eval_wer': 0.3490066048790881, 'eval_runtime': 1514.1397, 'eval_samples_per_second': 5.284, 'eval_steps_per_second': 5.284, 'epoch': 2.0}
[SER] Skipped (phase != 'all'/'ser').
n23g0002:3522750:3522864 [0] NCCL INFO [Service thread] Connection closed by localRank 0
n23g0002:3522750:3610257 [0] NCCL INFO comm 0x55fa829e6fc0 rank 0 nranks 1 cudaDev 0 busId ad000 - Abort COMPLETE
[TRAIN][SER] Starting SER phase ...
[Setup] Using device: cuda
[Setup] no_cuda flag set to: False
[ASR] Skipped (phase != 'all'/'asr').
[SER] Loading model + extractor‚Ä¶
[SER] Starting from pretrained: models/pretrained/en
trainable params: 9,248 || all params: 94,977,704 || trainable%: 0.0097
[SER] Trainable parameters: 9248 / 94977704
[SER] truncating to 102719 frames (~6.42s)
[SER] class counts: {4: 6792, 7: 1408, 3: 5556, 5: 6384, 0: 6044, 2: 4140, 1: 3500, 6: 768}
[SER] class weights: [0.7154202461242676, 1.2354285717010498, 1.0444444417953491, 0.7782577276229858, 0.6366313099861145, 0.677318274974823, 5.630208492279053, 3.0710227489471436]
[SER] Sanity loss (1 batch): 2.0523760318756104
[SER] Starting training with HuggingFace Trainer‚Ä¶
n23g0002:3610401:3610401 [0] NCCL INFO Bootstrap : Using ib0:134.61.46.190<0>
n23g0002:3610401:3610401 [0] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation
n23g0002:3610401:3610401 [0] NCCL INFO cudaDriverVersion 12080
NCCL version 2.20.5+cuda12.4
n23g0002:3610401:3622986 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib0:134.61.46.190<0>
n23g0002:3610401:3622986 [0] NCCL INFO Using non-device net plugin version 0
n23g0002:3610401:3622986 [0] NCCL INFO Using network IB
n23g0002:3610401:3622986 [0] NCCL INFO DMA-BUF is available on GPU device 0
n23g0002:3610401:3622986 [0] NCCL INFO comm 0x55cf6a577820 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId ad000 commId 0xeb84c645ed5338ca - Init START
n23g0002:3610401:3622986 [0] NCCL INFO comm 0x55cf6a577820 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
n23g0002:3610401:3622986 [0] NCCL INFO Channel 00/32 :    0
n23g0002:3610401:3622986 [0] NCCL INFO Channel 01/32 :    0
n23g0002:3610401:3622986 [0] NCCL INFO Channel 02/32 :    0
n23g0002:3610401:3622986 [0] NCCL INFO Channel 03/32 :    0
n23g0002:3610401:3622986 [0] NCCL INFO Channel 04/32 :    0
n23g0002:3610401:3622986 [0] NCCL INFO Channel 05/32 :    0
n23g0002:3610401:3622986 [0] NCCL INFO Channel 06/32 :    0
n23g0002:3610401:3622986 [0] NCCL INFO Channel 07/32 :    0
n23g0002:3610401:3622986 [0] NCCL INFO Channel 08/32 :    0
n23g0002:3610401:3622986 [0] NCCL INFO Channel 09/32 :    0
n23g0002:3610401:3622986 [0] NCCL INFO Channel 10/32 :    0
n23g0002:3610401:3622986 [0] NCCL INFO Channel 11/32 :    0
n23g0002:3610401:3622986 [0] NCCL INFO Channel 12/32 :    0
n23g0002:3610401:3622986 [0] NCCL INFO Channel 13/32 :    0
n23g0002:3610401:3622986 [0] NCCL INFO Channel 14/32 :    0
n23g0002:3610401:3622986 [0] NCCL INFO Channel 15/32 :    0
n23g0002:3610401:3622986 [0] NCCL INFO Channel 16/32 :    0
n23g0002:3610401:3622986 [0] NCCL INFO Channel 17/32 :    0
n23g0002:3610401:3622986 [0] NCCL INFO Channel 18/32 :    0
n23g0002:3610401:3622986 [0] NCCL INFO Channel 19/32 :    0
n23g0002:3610401:3622986 [0] NCCL INFO Channel 20/32 :    0
n23g0002:3610401:3622986 [0] NCCL INFO Channel 21/32 :    0
n23g0002:3610401:3622986 [0] NCCL INFO Channel 22/32 :    0
n23g0002:3610401:3622986 [0] NCCL INFO Channel 23/32 :    0
n23g0002:3610401:3622986 [0] NCCL INFO Channel 24/32 :    0
n23g0002:3610401:3622986 [0] NCCL INFO Channel 25/32 :    0
n23g0002:3610401:3622986 [0] NCCL INFO Channel 26/32 :    0
n23g0002:3610401:3622986 [0] NCCL INFO Channel 27/32 :    0
n23g0002:3610401:3622986 [0] NCCL INFO Channel 28/32 :    0
n23g0002:3610401:3622986 [0] NCCL INFO Channel 29/32 :    0
n23g0002:3610401:3622986 [0] NCCL INFO Channel 30/32 :    0
n23g0002:3610401:3622986 [0] NCCL INFO Channel 31/32 :    0
n23g0002:3610401:3622986 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
n23g0002:3610401:3622986 [0] NCCL INFO P2P Chunksize set to 131072
n23g0002:3610401:3622986 [0] NCCL INFO Connected all rings
n23g0002:3610401:3622986 [0] NCCL INFO Connected all trees
n23g0002:3610401:3622986 [0] NCCL INFO 32 coll channels, 0 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
n23g0002:3610401:3622986 [0] NCCL INFO comm 0x55cf6a577820 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId ad000 commId 0xeb84c645ed5338ca - Init COMPLETE
{'warn_nonfinite_logits': 1.0, 'epoch': 0}
{'warn_nonfinite_logits': 1.0, 'epoch': 0}
{'warn_nonfinite_logits': 1.0, 'epoch': 0}
{'warn_nonfinite_logits': 1.0, 'epoch': 0}
{'loss': 2.0794, 'grad_norm': nan, 'learning_rate': 9.713541666666668e-06, 'epoch': 0.06}
{'loss': 2.0794, 'grad_norm': nan, 'learning_rate': 9.424189814814816e-06, 'epoch': 0.12}
{'loss': 2.0794, 'grad_norm': nan, 'learning_rate': 9.134837962962964e-06, 'epoch': 0.17}
{'loss': 2.0794, 'grad_norm': nan, 'learning_rate': 8.845486111111112e-06, 'epoch': 0.23}
{'loss': 2.0794, 'grad_norm': nan, 'learning_rate': 8.55613425925926e-06, 'epoch': 0.29}
{'loss': 2.0794, 'grad_norm': nan, 'learning_rate': 8.266782407407407e-06, 'epoch': 0.35}
{'loss': 2.0794, 'grad_norm': nan, 'learning_rate': 7.977430555555557e-06, 'epoch': 0.41}
{'loss': 2.0794, 'grad_norm': nan, 'learning_rate': 7.688078703703704e-06, 'epoch': 0.46}
{'loss': 2.0794, 'grad_norm': nan, 'learning_rate': 7.398726851851853e-06, 'epoch': 0.52}
{'loss': 2.0794, 'grad_norm': nan, 'learning_rate': 7.109375000000001e-06, 'epoch': 0.58}
{'loss': 2.0794, 'grad_norm': nan, 'learning_rate': 6.820023148148148e-06, 'epoch': 0.64}
{'loss': 2.0794, 'grad_norm': nan, 'learning_rate': 6.530671296296297e-06, 'epoch': 0.69}
{'loss': 2.0794, 'grad_norm': nan, 'learning_rate': 6.241319444444445e-06, 'epoch': 0.75}
{'loss': 2.0794, 'grad_norm': nan, 'learning_rate': 5.951967592592594e-06, 'epoch': 0.81}
{'loss': 2.0794, 'grad_norm': nan, 'learning_rate': 5.662615740740741e-06, 'epoch': 0.87}
{'loss': 2.0794, 'grad_norm': nan, 'learning_rate': 5.373263888888889e-06, 'epoch': 0.93}
{'loss': 2.0794, 'grad_norm': nan, 'learning_rate': 5.0839120370370374e-06, 'epoch': 0.98}
{'eval_loss': 2.0794413089752197, 'eval_accuracy': 0.17031070195627157, 'eval_f1': 0.04956928985157954, 'eval_runtime': 59.8178, 'eval_samples_per_second': 116.22, 'eval_steps_per_second': 116.22, 'epoch': 1.0}
{'loss': 2.0794, 'grad_norm': nan, 'learning_rate': 4.794560185185186e-06, 'epoch': 1.04}
{'loss': 2.0794, 'grad_norm': nan, 'learning_rate': 4.505208333333334e-06, 'epoch': 1.1}
{'loss': 2.0794, 'grad_norm': nan, 'learning_rate': 4.215856481481482e-06, 'epoch': 1.16}
{'loss': 2.0794, 'grad_norm': nan, 'learning_rate': 3.92650462962963e-06, 'epoch': 1.22}
{'loss': 2.0794, 'grad_norm': nan, 'learning_rate': 3.637152777777778e-06, 'epoch': 1.27}
{'loss': 2.0794, 'grad_norm': nan, 'learning_rate': 3.3478009259259263e-06, 'epoch': 1.33}
{'loss': 2.0794, 'grad_norm': nan, 'learning_rate': 3.058449074074074e-06, 'epoch': 1.39}
{'loss': 2.0794, 'grad_norm': nan, 'learning_rate': 2.7690972222222222e-06, 'epoch': 1.45}
{'loss': 2.0794, 'grad_norm': nan, 'learning_rate': 2.4797453703703704e-06, 'epoch': 1.5}
{'loss': 2.0794, 'grad_norm': nan, 'learning_rate': 2.1903935185185186e-06, 'epoch': 1.56}
{'loss': 2.0794, 'grad_norm': nan, 'learning_rate': 1.9010416666666666e-06, 'epoch': 1.62}
{'loss': 2.0794, 'grad_norm': nan, 'learning_rate': 1.611689814814815e-06, 'epoch': 1.68}
{'loss': 2.0794, 'grad_norm': nan, 'learning_rate': 1.3223379629629633e-06, 'epoch': 1.74}
{'loss': 2.0794, 'grad_norm': nan, 'learning_rate': 1.032986111111111e-06, 'epoch': 1.79}
{'loss': 2.0794, 'grad_norm': nan, 'learning_rate': 7.436342592592594e-07, 'epoch': 1.85}
{'loss': 2.0794, 'grad_norm': nan, 'learning_rate': 4.5428240740740745e-07, 'epoch': 1.91}
{'loss': 2.0794, 'grad_norm': nan, 'learning_rate': 1.6493055555555558e-07, 'epoch': 1.97}
{'eval_loss': 2.0794413089752197, 'eval_accuracy': 0.17031070195627157, 'eval_f1': 0.04956928985157954, 'eval_runtime': 53.836, 'eval_samples_per_second': 129.133, 'eval_steps_per_second': 129.133, 'epoch': 2.0}
{'train_runtime': 288.8968, 'train_samples_per_second': 191.349, 'train_steps_per_second': 11.963, 'train_loss': 2.079449741928666, 'epoch': 2.0}
[SER][Trainer Eval] {'eval_loss': 2.0794413089752197, 'eval_accuracy': 0.17031070195627157, 'eval_f1': 0.04956928985157954, 'eval_runtime': 47.2743, 'eval_samples_per_second': 147.057, 'eval_steps_per_second': 147.057, 'epoch': 2.0}
n23g0002:3610401:3622989 [0] NCCL INFO [Service thread] Connection closed by localRank 0
n23g0002:3610401:3628174 [0] NCCL INFO comm 0x55cf6a577820 rank 0 nranks 1 cudaDev 0 busId ad000 - Abort COMPLETE
